{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SMeFV5OsjCW"
      },
      "source": [
        "# The Transformer\n",
        "In this lab scenario, you will implement *causal attention* for a transformer decoder model.\n",
        "The transformer architecture was introduced in the [Attention Is All You Need](https://arxiv.org/abs/1706.03762) paper, and has dominated the field of language modeling.  \n",
        "Here we will go through different parts of the transformer architecture and explain each of them briefly.\n",
        "\n",
        "The whole notebook works fine on Colab CPU (~5min).\n",
        "On the other hand, it's instantaneous on GPU (except for downloading the weights, which can take most of the time anyway).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDvzsLpSsjCW"
      },
      "source": [
        "## Transformer Overview\n",
        "\n",
        "Transformer decoder models (such as LLaMa 3.1 and Mistral) are popular text-processing models.   \n",
        "\n",
        "One can distinguish two versions of such models: **base** and **instruction-tuned**. The base models are usually trained on predicting the continuation of a given text (for each prefix they output a probability distribution over the next text fragment). In contrast, the instruction-tuned ones are base models that were additionally fine-tuned to follow instructions (often with a form of reinforcement learning from human feedback to generated text ([RLHF](https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback)))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM6J3vJhsjCW"
      },
      "source": [
        "### Tokenizer\n",
        "\n",
        "The text is presented to the transformer as a sequence of **tokens**.  \n",
        "Tokens are integers used to represent pieces of text.  \n",
        "To be more precise: to convert text to tokens, we first prepare a dictionary of common text fragments.   \n",
        "We usually want to have all possible letters in this dictionary, so that all texts can be tokenized.   \n",
        "We then assign to each text piece from the dictionary an integer and use the dictionary to convert text into a sequence of tokens (integers).  \n",
        "The class that converts text into tokens is called a tokenizer.  \n",
        "\n",
        "In this lab scenario, we will use the OpenLLaMAv2 tokenizer and the HuggingFace library to tokenize text.   \n",
        "HuggingFace contains a vast collection of transformer model weights and implementations along with training and inference code.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XbhhbGQri3qp"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers==4.57.2  # This is the version this notebook was prepared for."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0Bsmn2wWyUUo"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "from functools import partial\n",
        "from pprint import pp\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
        "from transformers.masking_utils import create_causal_mask\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Suppress a useless warning from HuggingFace.\n",
        "warnings.filterwarnings(\"ignore\", message=\"(?s:.)*authentication is recommended but still optional to access public models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339,
          "referenced_widgets": [
            "b997d1da64f94790b4ceac0081b0f7df",
            "554560da4635429693f7c0f323466413",
            "0fd90bd6b4674f0091589e749327d1a9",
            "7ff3b1a9c4dd48ae961e8f2e3779e5fa",
            "9eedc5fc73994614bd1f33b15485132a",
            "301a0594bd00498792db9866cf6c4be2",
            "80f2c20c5e9b45f8a10893408c0afd12",
            "8176623bb9714dad9c7dbb3f7c749021",
            "4f1cb77cb5c245339677c8493b52f2bf",
            "ee5bc78f07dc4b0194cc1fb1ee75eb70",
            "fa3458f836dd48f9ab28ea60dbc820c6",
            "86d80db7f1cb4d17b9a410a82aa365dc",
            "41a5ec7d4d2e4df9821a34ef778f35f1",
            "fa667a7d0b4249fc9b797294da89b917",
            "37109bd9ad58438a8f63a4b0b7814350",
            "ff8f0e58baba4ae1bc087143a7793c1a",
            "1b83d30af76040b8bc4c8c469ef53dbf",
            "e967e6d8a53d4ab797d66abaa492cc8a",
            "ac06c3a6dc0543ddb74b61732d125528",
            "08b116f2500744b8ac64105267fa32da",
            "6ec76fe1192a45d1a8f6eb77c9edc84b",
            "e5cc68ad5de246bc93ca6da304ad5ff7",
            "13ff008fc2bb4b74a67cc932c01da8a8",
            "d64766f053e44004b15567312af959ff",
            "79750cec2766417aa967255106727561",
            "064a88d5699f4498af9d4c09afd929b9",
            "0bd687c4d1cc44328b1866cb80a1e5c2",
            "75c0091b593d40cdadd98342c4c19122",
            "6fe1a62351e34c259f78261b72e6d3f7",
            "30e8a60e1c74411790a89c10be419054",
            "d716a1aacb4143f385c99704ae70e355",
            "6019d3aff971466aa30983732a915e6c",
            "88d29ac588c44a89a009bd78ec7166e4"
          ]
        },
        "id": "NbUYzMugsjCX",
        "outputId": "9c17f6f5-13ec-4e22-daed-cc5cd1210e19"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/593 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b997d1da64f94790b4ceac0081b0f7df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/512k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86d80db7f1cb4d17b9a410a82aa365dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/330 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13ff008fc2bb4b74a67cc932c01da8a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [1, 660, 325, 371, 1938, 1880, 347, 389, 477, 8206, 753],\n",
            " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "['<s>',\n",
            " 'This',\n",
            " 'is',\n",
            " 'an',\n",
            " 'example',\n",
            " 'text',\n",
            " 'that',\n",
            " 'we',\n",
            " 'will',\n",
            " 'token',\n",
            " 'ize']\n"
          ]
        }
      ],
      "source": [
        "tokenizer = LlamaTokenizer.from_pretrained(\"openlm-research/open_llama_3b_v2\", legacy=False)\n",
        "\n",
        "text = \"This is an example text that we will tokenize\"\n",
        "tokens_mask = tokenizer(text)\n",
        "pp(tokens_mask)\n",
        "\n",
        "detokenized = tokenizer.batch_decode(tokens_mask[\"input_ids\"])\n",
        "pp(detokenized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnkzqaZssjCY"
      },
      "source": [
        "After tokenization the the HuggingFace tokenizer returns a sequence of tokens (`input_ids`) and information on whether the model should look at the ith element of the input (`attention_mask`).  \n",
        "The other part is useful when we want to tokenize several sequences into one batch of elements of the same length. Then the attention mask can be used to hide the padding from the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN5jyhaAsjCZ",
        "outputId": "0a80282b-5c33-46b7-94f1-8a63ea19ca3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[   1,  660,  325,  371, 1938, 1880,  347,  389,  477, 8206,  753],\n",
            "        [   1, 8479,    2,    2,    2,    2,    2,    2,    2,    2,    2]]),\n",
            " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
            "['<s> This is an example text that we will tokenize',\n",
            " '<s> Hello</s></s></s></s></s></s></s></s></s>']\n"
          ]
        }
      ],
      "source": [
        "text = [\"This is an example text that we will tokenize\", \"Hello\"]\n",
        "\n",
        "# We set the padding token to be the same as the end-of-sequence token (EOS).\n",
        "# The EOS token (</s> in this case) can mark the end of the sequence in training and can be used by a model to indicate it finishes its response.\n",
        "# The BOS token (here <s>) can be used to mark the beginning of the input.\n",
        "# Details vary between different models and implementations.\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "tokens_mask = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=False)\n",
        "pp(tokens_mask)\n",
        "\n",
        "detokenized = tokenizer.batch_decode(tokens_mask[\"input_ids\"])\n",
        "pp(detokenized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ac-0ziMsjCZ"
      },
      "source": [
        "### Embedding\n",
        "The input to the model is a batch of integer (token) sequences of shape `(batch, seq_len)` where:\n",
        "* `batch` is the size of the batch;\n",
        "* `seq_len` is the length of the longest input sequence inside the batch (the attention mask is used to mask the padding).\n",
        "\n",
        "The first layer of the model replaces each integer with an embedding vector of length `hidden_size`.  \n",
        "(Inside the model, there is a matrix of trainable parameters, randomly initialized, of shape `(num_dictionary_elements, hidden_size)`).  \n",
        "\n",
        "After the embedding step, we pass a tensor of shape `(batch, seq_len, hidden_size)` through the remaining layers of the model.\n",
        "In decoder-only models, the sequence length does not change."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0qpsi1lsjCZ"
      },
      "source": [
        "### Transformer layer\n",
        "The internal parts of the transformer are grouped into transformer layers.  \n",
        "Usually, each layer consists of: layer norm, attention, layer norm, and a feed-forward layer.  \n",
        "To be more precise the computation progresses roughly as presented below:\n",
        "```python\n",
        "def transformer_layer(x):\n",
        " x = attention(layer_norm_attn(x)) + x\n",
        " x = feed_forward(layer_norm_ff(x)) + x\n",
        " return x\n",
        "```\n",
        "Here:  \n",
        "* **feed_forward** is an MLP (typically just two layers: linear-activation-linear) that acts on each token independently, in the same way. That is, it treats the sequence-length dimension like the batch dimension, and operates on the `hidden_size` dimension of an input of shape `(batch, seq_len, hidden_size)`.\n",
        "* **layer_norm** – in LLaMa models replaced by [RMSNorm](https://pytorch.org/docs/stable/generated/torch.nn.modules.normalization.RMSNorm.html) (which are like LayerNorm, but without centering, i.e. without subtracting the mean). Similarly as `feed_forward` it operates only on the `hidden_size` dimension, treating other dimensions as a batch.\n",
        "* **attention** – causal multi-head attention that you will implement in further parts of this notebook.\n",
        "\n",
        "Let $t^{(1)}$ be an input tensor of shape `(batch, seq_len, hidden_size)`.\n",
        "Attention will output a tensor $t^{(2)}$ of the same shape with the following property:\n",
        "calculation of $t^{(2)}[b,s,h]$ depends only on values from $t^{(2)}[b,s',h']$ such that  `s' <= s`. In other words, calculation is done independently per batch entry and dependency is *causal* (the past can influence the future but the future cannot influence the past of the sequence)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf4Nv-uVsjCa"
      },
      "source": [
        "### LM head\n",
        "In the end, a linear projection is used to create weights for each element of the input dictionary.\n",
        "To be more precise we take a tensor of shape `(batch, seq_len, hidden_dim)` and use norm + a linear projection from `hidden_dim` to `vocab_size`, in order to change it into tensor of shape `(batch, seq_len, vocab_size)`.  \n",
        "Then we apply softmax over the last dimension (`vocab_size`) to get a probability distribution, for each element of the sequence.\n",
        "The training loss will be cross entropy over next-token prediction.  \n",
        "That is, for a tokenized input sequence $x$, the $i$-th output of the model (which only depends on $x[0], \\dots, x[i]$), should be $x[i+1]$.\n",
        "In other words, the ground-truth output is the input sequence shifted by one (with EOS added at the end)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dea7kXYmsjCa"
      },
      "source": [
        "### Example\n",
        "Below we show the steps described above using OpenLLaMAv2 3B.\n",
        "\n",
        "For full details, see: https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/modeling_llama.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShxFREWlsjCa",
        "outputId": "89415002-5216-4919-8237-ec379f1cd79a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    1, 29500, 29536,   835, 29500, 29574,   419, 29500],\n",
            "        [    1, 29500, 29536, 29589, 29574, 29554,     2,     2]]),\n",
            " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 0, 0]])}\n"
          ]
        }
      ],
      "source": [
        "## Tokenize the input.\n",
        "tokenizer = LlamaTokenizer.from_pretrained(\"openlm-research/open_llama_3b_v2\", legacy=False)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "text = [\"2 + 7 = \", \"2+7=\"]\n",
        "\n",
        "tokens_mask = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
        "tokens = tokens_mask[\"input_ids\"]\n",
        "attention_mask = tokens_mask[\"attention_mask\"]\n",
        "pp(tokens_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "f0629c141da949cdbd8b1b4f06db5a2a",
            "c6869ae9880e4773b3d87ce91d266839",
            "475f0ae8899a435c8daca8069dd78af9",
            "5a3e5bd3ebff44169b1261af2a945564",
            "6a0ac2278e144b2e9df383cb53b860a2",
            "163c8c5af8bd45f5a7246eebe9850568",
            "9ffa2c7b84074778b6a7a43bc94e4eaa",
            "dd3878fc7512416891c1cc48c12de0c2",
            "2735c039535446fdafbb31316c8b63b7",
            "bd33eb781a8542efb0fb3144cd667886",
            "38c8359d111346fe9d98a16764cafc9c",
            "f856dfab1d064c7086f20337d0fc9685",
            "913d2f0811a545b09b42f268b3cd3f7c",
            "7153dc40d7c1486eb75220fc2f69b621",
            "8728750834fe480baa4b25e7a8f76791",
            "c1f27c965c7d48c89f0102b54d9a0382",
            "819f8428333343cfb587ab1edb9caafb",
            "206224bed3414f00868fb770dcd421a5",
            "2b8767ffa5bc46f6b32e7cd9e5f2cdf3",
            "daa67adbd4d349ed8195648ae5d76b4f",
            "43139773fae74be28a2e98172a179825",
            "34564d1d939340a98a24c41a3f1cd84f",
            "d6179dd1c0c24933adf2e2617ed980bd",
            "3f157d7121174ff7b0e419e69dcdce33",
            "a526b7ef1bd04a959598c5638aaebad8",
            "ff153250d1c94c708a33c5d9406b5d0c",
            "3689fa3e3e5c4596b6e015a828d7a937",
            "56d129a0a73d4512a1d053c94f3cf9f4",
            "9b6f0b7f4f16498d8c7c77166c01e49c",
            "1a804c9fed8949dca6b73f01a1dc4bf9",
            "25643e2c32d04a5f888f96588a7aeaa5",
            "100e5ea4d575498c8c7b1be26bf1bf00",
            "9176ed03f6e6445f82b1bf33d85c06da"
          ]
        },
        "id": "Gs7MxcEvsjCa",
        "outputId": "954c9321-ef07-4908-993a-4af17c91f754"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0629c141da949cdbd8b1b4f06db5a2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/6.85G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f856dfab1d064c7086f20337d0fc9685"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6179dd1c0c24933adf2e2617ed980bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.852947200000001\n"
          ]
        }
      ],
      "source": [
        "## Load the model from HuggingFace.\n",
        "device = (\n",
        "    torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "\n",
        "# Downloads ~6.8GB in bfloat16 (2 bytes per parameter).\n",
        "model = LlamaForCausalLM.from_pretrained(\n",
        "    \"openlm-research/open_llama_3b_v2\", dtype=torch.bfloat16, device_map=device\n",
        ")\n",
        "model.eval()\n",
        "print(sum(p.numel() for p in model.parameters()) * 2 / 1000 / 1000 / 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbxluG6-sjCb",
        "outputId": "31f1e7ac-cd6a-4b74-8fad-add84cf7358b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(32000, 3200, padding_idx=0)\n",
            "tokens.shape=torch.Size([2, 8])\n",
            "embedded_tokens.shape=torch.Size([2, 8, 3200])\n"
          ]
        }
      ],
      "source": [
        "## Embed the tokenizer input.\n",
        "print(model.model.embed_tokens)\n",
        "with torch.no_grad():\n",
        "    embedded_tokens = model.model.embed_tokens(tokens.to(device))\n",
        "print(f\"{tokens.shape=}\\n{embedded_tokens.shape=}\")\n",
        "batch, seq_len, hidden_size = embedded_tokens.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CqNRwX5y9TAb"
      },
      "outputs": [],
      "source": [
        "## Take the positions of each token [0, 1, 2, ...]\n",
        "position_ids = torch.arange(seq_len, device=embedded_tokens.device)[None, ...]\n",
        "\n",
        "# Embed them as (cos, sin, ...) rotations.\n",
        "# In Llama, instead of concatenating these to the embedded input tokens,\n",
        "# they will be applied to keys and queries inside each attention layer.\n",
        "# ( RoPE: https://arxiv.org/pdf/2104.09864 )\n",
        "# (The first tensor here is only used for its .device and .dtype).\n",
        "with torch.no_grad():\n",
        "    position_embeddings = model.model.rotary_emb(torch.zeros_like(embedded_tokens), position_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF9cPSHwBD9Q",
        "outputId": "ea07960a-63eb-4f73-9280-7a1d2d04979b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ True, False, False, False, False, False, False, False],\n",
            "          [ True,  True, False, False, False, False, False, False],\n",
            "          [ True,  True,  True, False, False, False, False, False],\n",
            "          [ True,  True,  True,  True, False, False, False, False],\n",
            "          [ True,  True,  True,  True,  True, False, False, False],\n",
            "          [ True,  True,  True,  True,  True,  True, False, False],\n",
            "          [ True,  True,  True,  True,  True,  True,  True, False],\n",
            "          [ True,  True,  True,  True,  True,  True,  True,  True]]],\n",
            "\n",
            "\n",
            "        [[[ True, False, False, False, False, False, False, False],\n",
            "          [ True,  True, False, False, False, False, False, False],\n",
            "          [ True,  True,  True, False, False, False, False, False],\n",
            "          [ True,  True,  True,  True, False, False, False, False],\n",
            "          [ True,  True,  True,  True,  True, False, False, False],\n",
            "          [ True,  True,  True,  True,  True,  True, False, False],\n",
            "          [ True,  True,  True,  True,  True,  True, False, False],\n",
            "          [ True,  True,  True,  True,  True,  True, False, False]]]])\n"
          ]
        }
      ],
      "source": [
        "# Compute the causal mask\n",
        "# (including information about the attention_mask from padding).\n",
        "causal_mask = create_causal_mask(\n",
        "    config=model.config,\n",
        "    input_embeds=embedded_tokens,\n",
        "    attention_mask=attention_mask,\n",
        "    position_ids=position_ids,\n",
        "    past_key_values=None,\n",
        "    cache_position=position_ids.squeeze(),\n",
        ")\n",
        "print(causal_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DU9i_Uw3sjCb",
        "outputId": "df8f1d37-e89f-4ea9-847f-d35a5258ecfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26/26 [00:10<00:00,  2.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape=torch.Size([2, 8, 32000])\n",
            "tensor([29567,    13])\n",
            "['9', '\\n']\n"
          ]
        }
      ],
      "source": [
        "## Go through the layers of the model.\n",
        "x = embedded_tokens\n",
        "\n",
        "with torch.no_grad():\n",
        "    for layer in tqdm(model.model.layers):\n",
        "        x = layer(\n",
        "            x,\n",
        "            attention_mask=causal_mask,\n",
        "            position_ids=position_ids,\n",
        "            past_key_values=None,  # can be used to continue generation\n",
        "            use_cache=False,\n",
        "            cache_position=position_ids.squeeze(),\n",
        "            position_embeddings=position_embeddings,\n",
        "        )\n",
        "\n",
        "    x = model.model.norm(x)\n",
        "    x = model.lm_head(x)\n",
        "    x = torch.nn.functional.softmax(x, dim=-1)\n",
        "    print(f\"{x.shape=}\")\n",
        "    next_token = torch.argmax(x[:, -1], dim=-1)\n",
        "    print(next_token)\n",
        "    print([tokenizer.decode(t) for t in next_token])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5stJOy0sjCb",
        "outputId": "83389676-3d11-4f79-d5c0-bab219ade774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s> The largest animal on earth is the blue whale. This giant creature',\n",
            " '<s> The largest animal on earth is not the elephant, the rhinoc',\n",
            " '<s> The largest animal on earth is the blue whale. Blue whales',\n",
            " '<s> The largest animal on earth is the blue whale. It is also']\n"
          ]
        }
      ],
      "source": [
        "# Using HuggingFace generate().\n",
        "with torch.no_grad():\n",
        "    text = \"The largest animal on earth is\"\n",
        "    tokens_mask = tokenizer(text, return_tensors=\"pt\")\n",
        "    output = model.generate(\n",
        "        inputs=tokens_mask[\"input_ids\"].to(device),\n",
        "        max_new_tokens=8,\n",
        "        num_beams=1,\n",
        "        num_return_sequences=4,\n",
        "        do_sample=True, # sample from the distribution created by softmax\n",
        "        temperature=0.7, # divide pre softmax score by this value\n",
        "        top_p=0.9 # cut out improbable tokens from sampling\n",
        "    )\n",
        "    pp(tokenizer.batch_decode(output))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH4maqpOdHKS"
      },
      "source": [
        "## Tools for implementing attention\n",
        "\n",
        "#### `einsum`\n",
        "[torch.einsum](https://docs.pytorch.org/docs/stable/generated/torch.einsum.html) is a useful tool for computing various forms of *contractions*, that is, expressions like $\\sum_i A_{\\dots,i,\\dots} B_{\\dots,i,\\dots}$.\n",
        "For example:\n",
        "* `torch.einsum(\"ij,jk->ik\", A, B)` is matrix multiplication.\n",
        "* `torch.einsum('bij,bjk->bik', As, Bs)` is batched matrix multiplication.\n",
        "\n",
        "In general, you go over every tuple (b,i,j,k,…) of all occuring letters, multiply the specified left and specified right element and accumulate that into the specified target element.\n",
        "In other words, you sum over dimension that don't appear in output.\n",
        "\n",
        "#### `where`\n",
        "Use [torch.where(B,X,Y)](https://docs.pytorch.org/docs/stable/generated/torch.where.html) to implement an expression like $\\begin{cases}\n",
        "    X_{i,j} & \\text{if }B_{i,j}\\\\\n",
        "    Y_{i,j} & \\text{otherwise}\n",
        "\\end{cases}$\n",
        "\n",
        "#### `tril`\n",
        "[torch.tril(A, diagonal=d)](https://docs.pytorch.org/docs/stable/generated/torch.tril.html) returns the lower-diagonal part of a matrix (not necessarily square), obtained be zeroing-out everything strictly above the main diagonal.\n",
        "If $d \\neq 0$ is given, everything above the diagonal `main + d` is zeroed out."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zyvy9AU_sjCb"
      },
      "source": [
        "## Causal Attention Implementation\n",
        "Your task is to finish the implementation of the attention mechanism below. In case of problems, you can refer to the original implementation that can be found [here](https://github.com/huggingface/transformers/blob/7f95372c6267d3163fd2aa74aeff9d84ddb6cc35/src/transformers/models/llama/modeling_llama.py#L258).\n",
        "\n",
        "To be more precise, you are given query,key,value tensors (with positional encoding already applied), each of shape:\n",
        ">`(batch, seq_len, num_heads, head_size)`  \n",
        "\n",
        "Your task is to compute for each head a scaled dot product between each query and each key that is either at the same position as the query or precedes the query in the sequence.\n",
        "That is, calculate a tensor `a` of shape:\n",
        "> `(batch, num_heads, seq_len, seq_len)`\n",
        "\n",
        "where  \n",
        "$$\n",
        "    a[b, h, q, k]=\n",
        "\\begin{cases}\n",
        "    \\sum_{d}{\\mathrm{query}[b, q, h, d] \\cdot \\mathrm{key}[b, k, h, d]} / \\sqrt{\\mathrm{head\\_size}}, & \\text{if }k \\leq q\\\\\n",
        "     -\\mathrm{large\\_number},              & \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "Then you should calculate the softmax over the last dimension of `a` creating `p`.  \n",
        "\n",
        "$$p = \\mathrm{SoftMax}(a)$$\n",
        "Then you should calculate\n",
        "$$ out [b, q, h, d] = \\sum_{k}{ p [b, h, q, k] \\cdot \\mathrm{value} [b, k, h, d] } $$\n",
        "\n",
        "That is, for each query you should gather the `value`s using the probability distribution defined by `p`.  \n",
        "In the end, you should reshape `out` to\n",
        "> `(batch, seq_len, num_heads * head_size)`\n",
        "\n",
        "and apply a linear projection `output_projection`.  \n",
        "\n",
        "To compute the attention mask, use `tril` on `torch.ones((?, ?), device=x.device, dtype=torch.bool)`.\n",
        "For simplicity, you may assume that the number of queries is equal to the number of keys.  \n",
        "This is not always true: for example, when we run `generate()` from HuggingFace transformers library, it caches previous keys and values and create queries only for the new token(s)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "H8WKIblFsjCb"
      },
      "outputs": [],
      "source": [
        "def attention_forward(\n",
        "    query: Tensor, key: Tensor, value: Tensor, output_projection: torch.nn.Linear,\n",
        ") -> Tensor:\n",
        "    batch, q_seq_len, num_heads, head_dim = query.shape\n",
        "    batch, k_seq_len, num_heads, head_dim = key.shape\n",
        "\n",
        "    assert value.shape == key.shape\n",
        "\n",
        "    assert q_seq_len <= k_seq_len\n",
        "    assert query.shape[0] == key.shape[0]\n",
        "    assert query.shape[2:] == key.shape[2:]\n",
        "    print(\"shape: \", query.shape, key.shape, value.shape)\n",
        "    # we have Batch = 1, seqLen = 8, numHeads = 32, and headSize = 100\n",
        "    # therefore, for each token ina  sentence, for each of 32 heads, we will have vectors of size 100 for queries, keys, and values\n",
        "    # TODO {\n",
        "\n",
        "    # Dot products of every query with every key # WE DO A MATMUL OF Q x K^T, and normalize it by sqrt(head_dim)\n",
        "    # currently,  the tensor of shape B x seq x nhead x headS needs to be reshaped, into being B x nHead x seq x headSize, and with this, we can iterate over heads,\n",
        "\n",
        "\n",
        "    query = query.permute(0, 2, 1, 3)\n",
        "    key = key.permute(0, 2, 3, 1)\n",
        "    aWeights = torch.matmul(query, key) / (head_dim ** 0.5)\n",
        "    print(\"A wieghts: : \", aWeights.shape) # now this makes sense, of shape B x nHead x seq x seq, so 1 x 32 x 8 x 8\n",
        "\n",
        "\n",
        "    # we first create a matrix of ones, and then, use tril to make it a mask beneath the main diagonal\n",
        "\n",
        "    mask = torch.ones((q_seq_len, k_seq_len), device=query.device, dtype=torch.bool)\n",
        "    mask = torch.tril(mask,0)\n",
        "    print(mask)\n",
        "    # Causality: set upper diagonal part to -infty.\n",
        "\n",
        "\t# Softmax for each query (over keys).\n",
        "\n",
        "\t# Collect the values for each query, as sum over keys/values weighted by attention.\n",
        "\n",
        "    # Reshape and apply the output projection.\n",
        "\n",
        "    # TODO }\n",
        "    assert out.shape == (batch, q_seq_len, num_heads * head_dim)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsxhAVLNsjCb"
      },
      "source": [
        "### Integration with OpenLLaMA\n",
        "The code below integrates your solution from above into OpenLLaMA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pMdJ87CAsjCb"
      },
      "outputs": [],
      "source": [
        "# Copied from https://github.com/huggingface/transformers/blob/7f95372c6267d3163fd2aa74aeff9d84ddb6cc35/src/transformers/models/llama/modeling_llama.py\n",
        "def rotate_half(x: Tensor) -> Tensor:\n",
        "    \"\"\"Turns concat(x1, x2, dim=-1) into concat(-x2, x1, dim=-1).\"\"\"\n",
        "    x1 = x[..., : x.shape[-1] // 2]\n",
        "    x2 = x[..., x.shape[-1] // 2 :]\n",
        "    return torch.cat((-x2, x1), dim=-1)\n",
        "\n",
        "\n",
        "# Copied from  https://github.com/huggingface/transformers/blob/7f95372c6267d3163fd2aa74aeff9d84ddb6cc35/src/transformers/models/llama/modeling_llama.py\n",
        "def apply_rotary_pos_emb(q: Tensor, k: Tensor, cos: Tensor, sin: Tensor) -> tuple[Tensor, Tensor]:\n",
        "    \"\"\"Applies Rotary Position Embedding (RoPE) to the query and key tensors.\n",
        "\n",
        "    Args:\n",
        "        q: The query tensor, shape (batch_size, heads, seq_len, head_dim).\n",
        "        k: The key tensor, shape (batch_size, heads, seq_len, head_dim).\n",
        "        cos: The cosine part of the rotary embedding, shape (batch_size, seq_len, head_dim).\n",
        "        sin: The sine part of the rotary embedding, shape (batch_size, seq_len, head_dim).\n",
        "    Returns: (q, k) tuple after rotation.\n",
        "\n",
        "    \"\"\"\n",
        "    cos = cos.unsqueeze(1)  # Add the 'heads' dimension (1 but broadcastable to the actual number).\n",
        "    sin = sin.unsqueeze(1)\n",
        "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
        "    k_embed = (k * cos) + (rotate_half(k) * sin)\n",
        "    return q_embed, k_embed\n",
        "\n",
        "\n",
        "# modified version of https://github.com/huggingface/transformers/blob/7f95372c6267d3163fd2aa74aeff9d84ddb6cc35/src/transformers/models/llama/modeling_llama.py\n",
        "def custom_attention_forward(\n",
        "    self,\n",
        "    hidden_states: Tensor,\n",
        "    position_embeddings: tuple[Tensor, Tensor],\n",
        "    attention_mask: Tensor | None = None,\n",
        "    position_ids: Tensor | None = None,\n",
        "    past_key_values=None,\n",
        "    use_cache: bool = False,\n",
        "    cache_position: torch.LongTensor | None = None,\n",
        "    **kwargs,\n",
        "):\n",
        "    x = hidden_states\n",
        "    bsz, q_len, _ = x.shape\n",
        "\n",
        "    query_states = self.q_proj(x)\n",
        "    key_states = self.k_proj(x)\n",
        "    value_states = self.v_proj(x)\n",
        "\n",
        "    # Split last dim into num_heads & head_dim; then swap seq_len and num_head dims.\n",
        "    query_states = query_states.view(bsz, q_len, -1, self.head_dim).transpose(1, 2)\n",
        "    key_states = key_states.view(bsz, q_len, -1, self.head_dim).transpose(1, 2)\n",
        "    value_states = value_states.view(bsz, q_len, -1, self.head_dim).transpose(1, 2)\n",
        "\n",
        "    # Apply RoPE.\n",
        "    cos, sin = position_embeddings\n",
        "    query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin)\n",
        "\n",
        "    # Use KV-cache.\n",
        "    if past_key_values is not None:\n",
        "        # sin and cos are specific to RoPE models; cache_position needed for the static cache\n",
        "        cache_kwargs = {\"sin\": sin, \"cos\": cos, \"cache_position\": cache_position}\n",
        "        key_states, value_states = past_key_values.update(\n",
        "            key_states, value_states, self.layer_idx, cache_kwargs\n",
        "        )\n",
        "\n",
        "    # Swap back num_head and seq_len dims.\n",
        "    query_states = query_states.transpose(1, 2)\n",
        "    key_states = key_states.transpose(1, 2)\n",
        "    value_states = value_states.transpose(1, 2)\n",
        "\n",
        "    attn_output = attention_forward(\n",
        "        query=query_states,\n",
        "        key=key_states,\n",
        "        value=value_states,\n",
        "        output_projection=self.o_proj,\n",
        "    )\n",
        "\n",
        "    return attn_output, None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a3BEs6usjCc"
      },
      "source": [
        "### Testing\n",
        "You can briefly test your solution below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "yj3mVnnVsjCc",
        "outputId": "ebd6982f-c864-4626-d18a-4edf1bc0ccf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape:  torch.Size([1, 8, 32, 100]) torch.Size([1, 8, 32, 100]) torch.Size([1, 8, 32, 100])\n",
            "A wieghts: :  torch.Size([1, 32, 8, 8])\n",
            "tensor([[ True, False, False, False, False, False, False, False],\n",
            "        [ True,  True, False, False, False, False, False, False],\n",
            "        [ True,  True,  True, False, False, False, False, False],\n",
            "        [ True,  True,  True,  True, False, False, False, False],\n",
            "        [ True,  True,  True,  True,  True, False, False, False],\n",
            "        [ True,  True,  True,  True,  True,  True, False, False],\n",
            "        [ True,  True,  True,  True,  True,  True,  True, False],\n",
            "        [ True,  True,  True,  True,  True,  True,  True,  True]])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'out' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1152060311.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mnext_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;34m\"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         ```\"\"\"\n\u001b[0;32m--> 459\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    460\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                 \u001b[0;31m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, cache_position, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             hidden_states = decoder_layer(\n\u001b[0m\u001b[1;32m    396\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         hidden_states, _ = self.self_attn(\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1741340682.py\u001b[0m in \u001b[0;36mcustom_attention_forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, position_ids, past_key_values, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     attn_output = attention_forward(\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2509743924.py\u001b[0m in \u001b[0;36mattention_forward\u001b[0;34m(query, key, value, output_projection)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# TODO }\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
          ]
        }
      ],
      "source": [
        "for l in model.model.layers:\n",
        "    l.self_attn.forward = partial(custom_attention_forward, self=l.self_attn)\n",
        "\n",
        "text = [\"2 + 7 = \"]\n",
        "\n",
        "tokens_mask = tokenizer(text, return_tensors=\"pt\")\n",
        "tokens = tokens_mask[\"input_ids\"]\n",
        "attention_mask = tokens_mask[\"attention_mask\"]\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_ids=tokens.to(device))\n",
        "    next_token = torch.argmax(output.logits[0, -1])\n",
        "    print(next_token)\n",
        "    decoded = tokenizer.decode(next_token)\n",
        "    print(f\"Model answer: {decoded}\")\n",
        "    assert decoded == \"9\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkour94wsjCc"
      },
      "outputs": [],
      "source": [
        "## If you have implemented the attention that can handle token-by-token generation you can check your solution using the code below.\n",
        "\n",
        "text = \"Solve x + 3 = 7\"\n",
        "tokens_mask = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model.generate(\n",
        "        inputs=tokens_mask[\"input_ids\"].to(device),\n",
        "        max_new_tokens=8,\n",
        "        num_beams=1,\n",
        "        do_sample=False,\n",
        "    )\n",
        "\n",
        "    print(tokenizer.batch_decode(output))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b997d1da64f94790b4ceac0081b0f7df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_554560da4635429693f7c0f323466413",
              "IPY_MODEL_0fd90bd6b4674f0091589e749327d1a9",
              "IPY_MODEL_7ff3b1a9c4dd48ae961e8f2e3779e5fa"
            ],
            "layout": "IPY_MODEL_9eedc5fc73994614bd1f33b15485132a"
          }
        },
        "554560da4635429693f7c0f323466413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_301a0594bd00498792db9866cf6c4be2",
            "placeholder": "​",
            "style": "IPY_MODEL_80f2c20c5e9b45f8a10893408c0afd12",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0fd90bd6b4674f0091589e749327d1a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8176623bb9714dad9c7dbb3f7c749021",
            "max": 593,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f1cb77cb5c245339677c8493b52f2bf",
            "value": 593
          }
        },
        "7ff3b1a9c4dd48ae961e8f2e3779e5fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee5bc78f07dc4b0194cc1fb1ee75eb70",
            "placeholder": "​",
            "style": "IPY_MODEL_fa3458f836dd48f9ab28ea60dbc820c6",
            "value": " 593/593 [00:00&lt;00:00, 23.7kB/s]"
          }
        },
        "9eedc5fc73994614bd1f33b15485132a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "301a0594bd00498792db9866cf6c4be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80f2c20c5e9b45f8a10893408c0afd12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8176623bb9714dad9c7dbb3f7c749021": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f1cb77cb5c245339677c8493b52f2bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee5bc78f07dc4b0194cc1fb1ee75eb70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa3458f836dd48f9ab28ea60dbc820c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86d80db7f1cb4d17b9a410a82aa365dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41a5ec7d4d2e4df9821a34ef778f35f1",
              "IPY_MODEL_fa667a7d0b4249fc9b797294da89b917",
              "IPY_MODEL_37109bd9ad58438a8f63a4b0b7814350"
            ],
            "layout": "IPY_MODEL_ff8f0e58baba4ae1bc087143a7793c1a"
          }
        },
        "41a5ec7d4d2e4df9821a34ef778f35f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b83d30af76040b8bc4c8c469ef53dbf",
            "placeholder": "​",
            "style": "IPY_MODEL_e967e6d8a53d4ab797d66abaa492cc8a",
            "value": "tokenizer.model: 100%"
          }
        },
        "fa667a7d0b4249fc9b797294da89b917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac06c3a6dc0543ddb74b61732d125528",
            "max": 511574,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08b116f2500744b8ac64105267fa32da",
            "value": 511574
          }
        },
        "37109bd9ad58438a8f63a4b0b7814350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ec76fe1192a45d1a8f6eb77c9edc84b",
            "placeholder": "​",
            "style": "IPY_MODEL_e5cc68ad5de246bc93ca6da304ad5ff7",
            "value": " 512k/512k [00:00&lt;00:00, 832kB/s]"
          }
        },
        "ff8f0e58baba4ae1bc087143a7793c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b83d30af76040b8bc4c8c469ef53dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e967e6d8a53d4ab797d66abaa492cc8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac06c3a6dc0543ddb74b61732d125528": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08b116f2500744b8ac64105267fa32da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ec76fe1192a45d1a8f6eb77c9edc84b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5cc68ad5de246bc93ca6da304ad5ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13ff008fc2bb4b74a67cc932c01da8a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d64766f053e44004b15567312af959ff",
              "IPY_MODEL_79750cec2766417aa967255106727561",
              "IPY_MODEL_064a88d5699f4498af9d4c09afd929b9"
            ],
            "layout": "IPY_MODEL_0bd687c4d1cc44328b1866cb80a1e5c2"
          }
        },
        "d64766f053e44004b15567312af959ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75c0091b593d40cdadd98342c4c19122",
            "placeholder": "​",
            "style": "IPY_MODEL_6fe1a62351e34c259f78261b72e6d3f7",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "79750cec2766417aa967255106727561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30e8a60e1c74411790a89c10be419054",
            "max": 330,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d716a1aacb4143f385c99704ae70e355",
            "value": 330
          }
        },
        "064a88d5699f4498af9d4c09afd929b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6019d3aff971466aa30983732a915e6c",
            "placeholder": "​",
            "style": "IPY_MODEL_88d29ac588c44a89a009bd78ec7166e4",
            "value": " 330/330 [00:00&lt;00:00, 41.0kB/s]"
          }
        },
        "0bd687c4d1cc44328b1866cb80a1e5c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c0091b593d40cdadd98342c4c19122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fe1a62351e34c259f78261b72e6d3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30e8a60e1c74411790a89c10be419054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d716a1aacb4143f385c99704ae70e355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6019d3aff971466aa30983732a915e6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d29ac588c44a89a009bd78ec7166e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0629c141da949cdbd8b1b4f06db5a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6869ae9880e4773b3d87ce91d266839",
              "IPY_MODEL_475f0ae8899a435c8daca8069dd78af9",
              "IPY_MODEL_5a3e5bd3ebff44169b1261af2a945564"
            ],
            "layout": "IPY_MODEL_6a0ac2278e144b2e9df383cb53b860a2"
          }
        },
        "c6869ae9880e4773b3d87ce91d266839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_163c8c5af8bd45f5a7246eebe9850568",
            "placeholder": "​",
            "style": "IPY_MODEL_9ffa2c7b84074778b6a7a43bc94e4eaa",
            "value": "config.json: 100%"
          }
        },
        "475f0ae8899a435c8daca8069dd78af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd3878fc7512416891c1cc48c12de0c2",
            "max": 506,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2735c039535446fdafbb31316c8b63b7",
            "value": 506
          }
        },
        "5a3e5bd3ebff44169b1261af2a945564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd33eb781a8542efb0fb3144cd667886",
            "placeholder": "​",
            "style": "IPY_MODEL_38c8359d111346fe9d98a16764cafc9c",
            "value": " 506/506 [00:00&lt;00:00, 48.1kB/s]"
          }
        },
        "6a0ac2278e144b2e9df383cb53b860a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "163c8c5af8bd45f5a7246eebe9850568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ffa2c7b84074778b6a7a43bc94e4eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd3878fc7512416891c1cc48c12de0c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2735c039535446fdafbb31316c8b63b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd33eb781a8542efb0fb3144cd667886": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38c8359d111346fe9d98a16764cafc9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f856dfab1d064c7086f20337d0fc9685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_913d2f0811a545b09b42f268b3cd3f7c",
              "IPY_MODEL_7153dc40d7c1486eb75220fc2f69b621",
              "IPY_MODEL_8728750834fe480baa4b25e7a8f76791"
            ],
            "layout": "IPY_MODEL_c1f27c965c7d48c89f0102b54d9a0382"
          }
        },
        "913d2f0811a545b09b42f268b3cd3f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_819f8428333343cfb587ab1edb9caafb",
            "placeholder": "​",
            "style": "IPY_MODEL_206224bed3414f00868fb770dcd421a5",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "7153dc40d7c1486eb75220fc2f69b621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b8767ffa5bc46f6b32e7cd9e5f2cdf3",
            "max": 6853038093,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_daa67adbd4d349ed8195648ae5d76b4f",
            "value": 6853038093
          }
        },
        "8728750834fe480baa4b25e7a8f76791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43139773fae74be28a2e98172a179825",
            "placeholder": "​",
            "style": "IPY_MODEL_34564d1d939340a98a24c41a3f1cd84f",
            "value": " 6.85G/6.85G [01:38&lt;00:00, 226MB/s]"
          }
        },
        "c1f27c965c7d48c89f0102b54d9a0382": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "819f8428333343cfb587ab1edb9caafb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "206224bed3414f00868fb770dcd421a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b8767ffa5bc46f6b32e7cd9e5f2cdf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daa67adbd4d349ed8195648ae5d76b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43139773fae74be28a2e98172a179825": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34564d1d939340a98a24c41a3f1cd84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6179dd1c0c24933adf2e2617ed980bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f157d7121174ff7b0e419e69dcdce33",
              "IPY_MODEL_a526b7ef1bd04a959598c5638aaebad8",
              "IPY_MODEL_ff153250d1c94c708a33c5d9406b5d0c"
            ],
            "layout": "IPY_MODEL_3689fa3e3e5c4596b6e015a828d7a937"
          }
        },
        "3f157d7121174ff7b0e419e69dcdce33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56d129a0a73d4512a1d053c94f3cf9f4",
            "placeholder": "​",
            "style": "IPY_MODEL_9b6f0b7f4f16498d8c7c77166c01e49c",
            "value": "generation_config.json: 100%"
          }
        },
        "a526b7ef1bd04a959598c5638aaebad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a804c9fed8949dca6b73f01a1dc4bf9",
            "max": 137,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25643e2c32d04a5f888f96588a7aeaa5",
            "value": 137
          }
        },
        "ff153250d1c94c708a33c5d9406b5d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_100e5ea4d575498c8c7b1be26bf1bf00",
            "placeholder": "​",
            "style": "IPY_MODEL_9176ed03f6e6445f82b1bf33d85c06da",
            "value": " 137/137 [00:00&lt;00:00, 8.61kB/s]"
          }
        },
        "3689fa3e3e5c4596b6e015a828d7a937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56d129a0a73d4512a1d053c94f3cf9f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b6f0b7f4f16498d8c7c77166c01e49c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a804c9fed8949dca6b73f01a1dc4bf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25643e2c32d04a5f888f96588a7aeaa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "100e5ea4d575498c8c7b1be26bf1bf00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9176ed03f6e6445f82b1bf33d85c06da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}