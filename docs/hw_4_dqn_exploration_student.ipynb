{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exploration strategies for DQN algorithm\n",
        "\n",
        "In this assignment we are interested in exploration strategies that can be combined with Q-learning.\n",
        "Q-learning is an off-policy algorithm, which means that the data for the algorithm can be collected by a different policy (called behavioural policy) that the one the algorithm learns.\n",
        "\n",
        "Here we come across a classical trade-off in reinforcement learning, called exploration-exploitation trade-off. On the one hand, our behavioural policy should try out new state-action pairs to gain knowledge about their returns. On the other hand, when our estimate of returns is good enough, we would like to follow the state-action pairs with the highest estimated returns.\n",
        "\n",
        "We will be operating on DQN [(Mnih 2014)](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf) algorithm and analyzing epsilon-greedy strategy, boltzmann and max-boltzmann strategy and combination of epsilon-greedy and boltzmann.\n",
        "We evaluate performance of DQN variants on the Lunar Lander environment.\n",
        "\n",
        "We provide an implementation of the DQN algorithm with random exploration strategy.\n",
        "Your goal is to implement the exploration variants by overriding appropriate methods of the provided class.\n"
      ],
      "metadata": {
        "id": "OCcuj7kCPowC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grading\n",
        "\n",
        "To obtain the points for the assignment You need to provide the implementation of exploration techniques AND report with plots and conclusions.\n",
        "Measuring sensitivity means that You should at least examine one reasonably lower and one reasonably greater value of the considered hyperparameter (or the pair of hyperparameters).\n",
        "\n",
        "\n",
        "1. Implement epsilon-greedy strategy and investigate hyperparameter sensitivity (1 point).\n",
        "2. Implement epsilon-greedy strategy with epsilon annealing and investigate hyperparameter sensitivity (1 point).\n",
        "3. Implement boltzmann strategy and investigate hyperparameter sensitivity (1 point).\n",
        "4. Implement boltzmann strategy with temperature annealing and investigate hyperparameter sensitivity (1 point).\n",
        "5. Implement max-boltzmann strategy and investigate hyperparameter sensitivity (1 point).\n",
        "6. Implement max-boltzmann strategy with temperature annealing and investigate hyperparameter sensitivity (1 point).\n",
        "7. Implement combination of epsilon-greedy with epsilon annealing and boltzmann strategy and investigate hyperparameter sensitivity (1 point)\n",
        "8. (*) Bonus: propose another reasonable approach to combine epsilon-greedy with epsilon annealing strategy and boltzmann strategy and/or another reasonable strategy of temperature annealing for the boltzmann strategy (2 points).\n",
        "9. Compare methods, present plots and conclusions in a clear manner (3 points).\n",
        "\n",
        "You can obtain max 10 points, bonus points increase Your score, if You lose points in some other tasks."
      ],
      "metadata": {
        "id": "MdeRz_jnUBmO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we import necessary libraries."
      ],
      "metadata": {
        "id": "WugRYf0FYsxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install swig\n",
        "!pip install gymnasium[box2d]"
      ],
      "metadata": {
        "id": "P3Ynynd4GGKO",
        "outputId": "2f0e418e-6ea1-4eef-8c88-4ebd822a20f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "swig is already the newest version (4.0.2-1ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.12/dist-packages (1.2.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Requirement already satisfied: box2d==2.3.10 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.3.10)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (4.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "KKd6_LiXdh3D"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we set hyperparameters of the training, set seeds for reproducibility and set weights initialization.\n",
        "Although for debugging it might be useful to operate on a smaller number of training_steps, seeds etc., in the final evaluation DO NOT CHANGE these parameters."
      ],
      "metadata": {
        "id": "kgtGd69HY7PB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class parse_args:\n",
        "  def __init__(self):\n",
        "    self.n_seeds = 6\n",
        "    self.n_evaluate_episodes = 5\n",
        "    self.n_training_steps = 100000 # orignially 100000\n",
        "    self.buffer_size = 10000\n",
        "    self.init_steps = 10000\n",
        "    self.target_update_freq = 50\n",
        "    self.eval_freq = 1000\n",
        "    self.gym_id = \"LunarLander-v3\"\n",
        "    env = gym.make(self.gym_id)\n",
        "    self.state_dim = env.observation_space.shape[0]\n",
        "    self.batch_size = 128\n",
        "    self.hidden_dim = 128\n",
        "    self.action_dim = env.action_space.n\n",
        "    self.discount = 0.99\n",
        "    self.lr = 7e-4\n",
        "    self.cuda = True\n",
        "    self.device = torch.device(\"cuda\" if torch.cuda.is_available() and self.cuda else \"cpu\")\n",
        "\n",
        "args = parse_args()\n",
        "first_half_training_args = parse_args()\n",
        "first_half_training_args.n_training_steps = first_half_training_args.n_training_steps // 2\n",
        "second_half_training_args = parse_args()\n",
        "second_half_training_args.n_training_steps = second_half_training_args.n_training_steps // 2\n",
        "second_half_training_args.init_steps = 1"
      ],
      "metadata": {
        "id": "AbD6x1GJFgqr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "  np.random.seed(seed)\n",
        "\n",
        "def weight_init(model):\n",
        "  torch.nn.init.orthogonal_(model.weight.data)\n",
        "  model.bias.data.fill_(0.0)"
      ],
      "metadata": {
        "id": "wJ4x_6u9fQXA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we implement the replay buffer.\n",
        "It has two methods: add one transition to the buffer and sample batch of transitions from the buffer."
      ],
      "metadata": {
        "id": "4nk9OsHCaPZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer:\n",
        "  def __init__(self, args):\n",
        "    self.states = np.zeros((args.buffer_size, args.n_seeds, args.state_dim), dtype = np.float32)\n",
        "    self.actions = np.zeros((args.buffer_size, args.n_seeds), dtype = np.int64)\n",
        "    self.rewards = np.zeros((args.buffer_size, args.n_seeds), dtype = np.float32)\n",
        "    self.next_states = np.zeros((args.buffer_size, args.n_seeds, args.state_dim), dtype = np.float32)\n",
        "    self.terminals = np.zeros((args.buffer_size, args.n_seeds), dtype = np.int64)\n",
        "    self.idx = 0\n",
        "    self.current_size = 0\n",
        "    self.args = args\n",
        "\n",
        "  def add(self, state, action, reward, next_state, terminal):\n",
        "    if self.current_size < self.args.buffer_size:\n",
        "      self.current_size += 1\n",
        "    self.states[self.idx, :, :] = state\n",
        "    self.actions[self.idx, :] = action\n",
        "    self.rewards[self.idx, :] = reward\n",
        "    self.next_states[self.idx, :, :] = next_state\n",
        "    self.terminals[self.idx, :] = terminal\n",
        "    self.idx = (self.idx + 1) % self.args.buffer_size\n",
        "\n",
        "  def sample(self):\n",
        "    sample_idxs = np.random.permutation(self.current_size)[:self.args.batch_size]\n",
        "    states = torch.from_numpy(self.states[sample_idxs]).to(self.args.device)\n",
        "    actions = torch.from_numpy(self.actions[sample_idxs]).to(self.args.device)\n",
        "    rewards = torch.from_numpy(self.rewards[sample_idxs]).to(self.args.device)\n",
        "    next_states = torch.from_numpy(self.next_states[sample_idxs]).to(self.args.device)\n",
        "    terminals = torch.from_numpy(self.terminals[sample_idxs]).to(self.args.device)\n",
        "\n",
        "    return states, actions, rewards, next_states, terminals\n"
      ],
      "metadata": {
        "id": "8kswZi26I9_t"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we implement a simple Q network architecture with three layers and ReLU activations."
      ],
      "metadata": {
        "id": "WI1MmteualVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QNetwork(torch.nn.Module):\n",
        "  def __init__(self, args):\n",
        "    super(QNetwork, self).__init__()\n",
        "    self.layer_1 = torch.nn.Linear(args.state_dim, args.hidden_dim)\n",
        "    self.layer_2 = torch.nn.Linear(args.hidden_dim, args.hidden_dim)\n",
        "    self.layer_3 = torch.nn.Linear(args.hidden_dim, args.action_dim)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "\n",
        "    self.layer_1.apply(weight_init)\n",
        "    self.layer_2.apply(weight_init)\n",
        "    self.layer_3.apply(weight_init)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu(self.layer_1(x))\n",
        "    x = self.relu(self.layer_2(x))\n",
        "    x = self.layer_3(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "jXq66twrc2Mh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we provide code for DQN with random exploration."
      ],
      "metadata": {
        "id": "NB2SjjLldglT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "myEn1aKdaURQ"
      },
      "outputs": [],
      "source": [
        "TRAIN_SEED = 0\n",
        "EVAL_SEED = 1\n",
        "\n",
        "class DQN:\n",
        "  def __init__(self, args):\n",
        "    self.args = args\n",
        "    self.discount = self.args.discount\n",
        "    self.reset()\n",
        "    self.annealing = False\n",
        "\n",
        "  # Copying parameters of other DQN class by reference (for half epsion-greedy, half boltzmann task)\n",
        "  def copy_reference(self, other):\n",
        "    self.buffer = other.buffer\n",
        "    self.q_net = other.q_net\n",
        "    self.q_target = other.q_target\n",
        "    self.optimizer = other.optimizer\n",
        "\n",
        "  # Annealing of epsilon and/or temperature\n",
        "  def anneal(self, step):\n",
        "    pass\n",
        "\n",
        "  # Greedy action\n",
        "  def get_greedy_action(self, states):\n",
        "    with torch.no_grad():\n",
        "      action = torch.argmax(self.q_net(states), dim = -1).detach().cpu().numpy()\n",
        "      return action\n",
        "\n",
        "  # Exploration action choice\n",
        "  def explore(self, states):\n",
        "    # Random action choice\n",
        "    action = np.random.randint(self.args.action_dim, size = self.args.n_seeds)\n",
        "    return action\n",
        "\n",
        "  # Update of the main critic\n",
        "  def update(self):\n",
        "    states, actions, rewards, next_states, terminals = self.buffer.sample()\n",
        "    with torch.no_grad():\n",
        "      q_next_states = torch.max(self.q_target(next_states), dim = -1)[0]\n",
        "    ones_tensor = torch.ones_like(terminals).to(self.args.device)\n",
        "    targets = rewards + (ones_tensor - terminals) * self.discount * q_next_states\n",
        "\n",
        "    self.optimizer.zero_grad()\n",
        "    q_values = self.q_net(states).gather(-1, actions.unsqueeze(-1)).squeeze(-1)\n",
        "    loss = torch.mean((q_values - targets) ** 2)\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "\n",
        "  # Update of the targer critic\n",
        "  def update_target(self):\n",
        "    self.q_target.load_state_dict(self.q_net.state_dict())\n",
        "\n",
        "  # Evaluation of the performance on test environments.\n",
        "  def evaluate(self):\n",
        "    eval_results = np.zeros(self.args.n_seeds)\n",
        "    with torch.no_grad():\n",
        "      eval_env = gym.make_vec(self.args.gym_id, num_envs = self.args.n_seeds, vectorization_mode=\"sync\")\n",
        "      eval_env.reset(seed = EVAL_SEED)\n",
        "      for _ in range(self.args.n_evaluate_episodes):\n",
        "        state, info = eval_env.reset()\n",
        "        episode_reward = np.zeros(self.args.n_seeds)\n",
        "        mask = np.ones(self.args.n_seeds)\n",
        "        while np.sum(mask) > 0:\n",
        "          action = self.get_greedy_action(torch.tensor(state).to(self.args.device))\n",
        "          next_state, reward, terminal, truncated, _ = eval_env.step(action)\n",
        "          episode_reward += mask * reward\n",
        "          state = next_state\n",
        "          mask *= (np.ones(self.args.n_seeds) - terminal) * (np.ones(self.args.n_seeds) - truncated)\n",
        "        eval_results += episode_reward / self.args.n_evaluate_episodes\n",
        "    return np.mean(eval_results), np.std(eval_results)\n",
        "\n",
        "\n",
        "  # Resetting the algorithm\n",
        "  def reset(self):\n",
        "    self.buffer = ReplayBuffer(self.args)\n",
        "    self.q_net = QNetwork(self.args).to(self.args.device) # main critic\n",
        "    self.optimizer = torch.optim.Adam(self.q_net.parameters(), lr = self.args.lr, eps = 1e-5)\n",
        "    self.q_target = QNetwork(self.args).to(self.args.device) # target critic\n",
        "    self.update_target()\n",
        "\n",
        "  # Training loop\n",
        "  def train(self):\n",
        "    eval_results_means = np.array([])\n",
        "    eval_results_stds = np.array([])\n",
        "    train_env = gym.make_vec(self.args.gym_id, num_envs = self.args.n_seeds, vectorization_mode=\"sync\")\n",
        "    state, info = train_env.reset(seed = TRAIN_SEED)\n",
        "    mask = np.ones(self.args.n_seeds)\n",
        "    for step in range(self.args.n_training_steps):\n",
        "      action = self.explore(torch.tensor(state).unsqueeze(0).to(self.args.device))\n",
        "      if self.annealing:\n",
        "        self.anneal(step)\n",
        "      next_state, reward, terminal, truncated, _ = train_env.step(action)\n",
        "      self.buffer.add(state, action, reward, next_state, terminal)\n",
        "      state = next_state\n",
        "      if step % self.args.eval_freq == 0:\n",
        "          print(f\"Training step: {step}\")\n",
        "          eval_mean, eval_std = self.evaluate()\n",
        "          print(f\"Eval mean: {eval_mean}; eval_std: {eval_std}\")\n",
        "          eval_results_means = np.append(eval_results_means, eval_mean)\n",
        "          eval_results_stds = np.append(eval_results_stds, eval_std)\n",
        "      if step >= self.args.init_steps:\n",
        "        self.update()\n",
        "        if step % self.args.target_update_freq == 0:\n",
        "          self.update_target()\n",
        "      mask *= (np.ones(self.args.n_seeds) - terminal) * (np.ones(self.args.n_seeds) - truncated)\n",
        "      if np.sum(mask) == 0:\n",
        "        state, info = train_env.reset()\n",
        "        mask = np.ones(self.args.n_seeds)\n",
        "\n",
        "    return eval_results_means, eval_results_stds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we implement functions for plotting."
      ],
      "metadata": {
        "id": "2JDGKsz8chmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth(data, weigth = 0.9):\n",
        "  smooth_data = np.copy(data)\n",
        "  for index in range(1, len(data)):\n",
        "    smooth_data[index] = smooth_data[index - 1] * weigth + data[index] * (1.0 - weigth)\n",
        "\n",
        "  return smooth_data\n",
        "\n",
        "def plot_smooth(args, result_means, result_stds):\n",
        "  smooth_result_means = smooth(result_means)\n",
        "  smooth_result_stds = smooth(result_stds)\n",
        "  print(smooth_result_means)\n",
        "  print(smooth_result_stds)\n",
        "  xs = np.arange(len(result_means)) * args.eval_freq\n",
        "  print(xs)\n",
        "  plt.plot(xs, smooth_result_means, color = \"blue\")\n",
        "  plt.fill_between(xs, smooth_result_means - smooth_result_stds, smooth_result_means + smooth_result_stds, alpha = 0.2, label = \"smoothed_rewards\")\n",
        "  plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
        "  plt.show()\n",
        "  plt.clf()\n",
        "\n",
        "def plot_smooth_many(args, result_means_list, result_stds_list, names_list, colours_list):\n",
        "  plt.figure(figsize=(12.8, 9.6))\n",
        "  for result_means, result_stds, name, colour in zip(result_means_list, result_stds_list, names_list, colours_list):\n",
        "    smooth_result_means = smooth(result_means)\n",
        "    smooth_result_stds = smooth(result_stds)\n",
        "    print(smooth_result_means)\n",
        "    print(smooth_result_stds)\n",
        "    xs = np.arange(len(result_means)) * args.eval_freq\n",
        "    print(xs)\n",
        "    plt.plot(xs, smooth_result_means, color = colour)\n",
        "    plt.fill_between(xs, smooth_result_means - smooth_result_stds, smooth_result_means + smooth_result_stds, alpha = 0.2, color = colour, label = f\"smoothed_rewards_{name}\")\n",
        "    plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
        "  plt.show()\n",
        "  plt.clf()\n",
        "\n",
        "def plot_results(result_mean, result_std):\n",
        "  plot_smooth(args, result_mean, result_std)\n",
        "\n",
        "def plot_results_many(result_means_list, result_stds_list, name_list, colours_list):\n",
        "  plot_smooth_many(args, result_means_list, result_stds_list, name_list, colours_list)"
      ],
      "metadata": {
        "id": "P_zLGVqHpvQz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we provide code for training across different random seeds."
      ],
      "metadata": {
        "id": "hoiLn1y1cshT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_dqn(dqn):\n",
        "  set_seed(TRAIN_SEED)\n",
        "  dqn.reset()\n",
        "  result_mean, result_std = dqn.train()\n",
        "  print(result_mean)\n",
        "  return result_mean, result_std\n"
      ],
      "metadata": {
        "id": "XLG6xzJ-o7oN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dqn = DQN(args)\n",
        "result_means_dqn, result_stds_dqn = train_dqn(dqn)\n",
        "plot_results(result_means_dqn, result_stds_dqn)"
      ],
      "metadata": {
        "id": "R2PyyNFdq50-",
        "outputId": "322b7f37-ad7a-487e-8e80-15a804ab201d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training step: 0\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 1000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 2000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 3000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 4000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 5000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 6000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 7000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 8000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 9000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 10000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 11000\n",
            "Eval mean: -92.09635353225616; eval_std: 7.427149523591686\n",
            "Training step: 12000\n",
            "Eval mean: -139.72535441078307; eval_std: 13.111407545817277\n",
            "Training step: 13000\n",
            "Eval mean: -156.57203515448404; eval_std: 12.28387573614405\n",
            "Training step: 14000\n",
            "Eval mean: -175.94877050760792; eval_std: 16.398050405635022\n",
            "Training step: 15000\n",
            "Eval mean: -205.06963345201322; eval_std: 6.871300559291905\n",
            "Training step: 16000\n",
            "Eval mean: -208.95670551463294; eval_std: 31.192847539442678\n",
            "Training step: 17000\n",
            "Eval mean: -183.3771004045324; eval_std: 18.889041708542244\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2355416663.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult_means_dqn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_stds_dqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_means_dqn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_stds_dqn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-503547981.py\u001b[0m in \u001b[0;36mtrain_dqn\u001b[0;34m(dqn)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_SEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mresult_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4186968863.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m           \u001b[0meval_results_stds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_results_stds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_update_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4186968863.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_values\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;31m# Update of the targer critic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Optimizer.step#{self.__class__.__name__}.step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m                 \u001b[0;31m# call optimizer step pre hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 for pre_hook in chain(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunctionSubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RecordFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fallthrough_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                 )\n\u001b[0;32m-> 1084\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m     def _dispatch_in_python(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the goal is to implement the epsilon-gredy strategy. With probability epsilon we choose uniformly a random action and with probability 1-epsilon we take the action with the highest Q-value according to the main critic."
      ],
      "metadata": {
        "id": "8BHzDjEUfYn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "class EpsilonGreedyDQN(DQN):\n",
        "  def __init__(self, args):\n",
        "    super(EpsilonGreedyDQN, self).__init__(args)\n",
        "    self.epsilon = 0.1 # investigate sensitivity\n",
        "\n",
        "  def explore(self, states):\n",
        "    action = None\n",
        "    # TODO\n",
        "    ran = random.random()\n",
        "    #print(\"random: \", ran)\n",
        "    if ran < self.epsilon:\n",
        "    # probably do the first step as epsilon chance\n",
        "      action = np.random.randint(self.args.action_dim, size = self.args.n_seeds)\n",
        "      #print(action)\n",
        "      #(\"Random! \")\n",
        "    else:\n",
        "      #(\"Random bez epsilon\")\n",
        "      # do a argmax over qvalues\n",
        "      action = self.get_greedy_action(states).squeeze()\n",
        "\n",
        "      #print(\"Actions: \", action)\n",
        "    ####################################\n",
        "    ####################################\n",
        "    return action"
      ],
      "metadata": {
        "id": "v6lj71xe7c77"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon_greedy_dqn = EpsilonGreedyDQN(args)\n",
        "result_means_epsilon_greedy_dqn, result_stds_epsilon_greedy_dqn = train_dqn(epsilon_greedy_dqn)\n",
        "plot_results(result_means_epsilon_greedy_dqn, result_stds_epsilon_greedy_dqn)"
      ],
      "metadata": {
        "id": "JefbwjjR9AU-",
        "outputId": "4e0f46d9-5fc2-4a32-e91a-0784b0a92f43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training step: 0\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 1000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 2000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 3000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 4000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 5000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 6000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 7000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 8000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 9000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 10000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 11000\n",
            "Eval mean: 35.81245656745532; eval_std: 39.27409007267402\n",
            "Training step: 12000\n",
            "Eval mean: -37.23668211665172; eval_std: 61.852175173715445\n",
            "Training step: 13000\n",
            "Eval mean: -61.05009391575578; eval_std: 24.079116829029438\n",
            "Training step: 14000\n",
            "Eval mean: -40.205268014804574; eval_std: 14.003846421394847\n",
            "Training step: 15000\n",
            "Eval mean: -112.92667407641073; eval_std: 35.673501762492\n",
            "Training step: 16000\n",
            "Eval mean: -230.50470903765108; eval_std: 55.47560728177318\n",
            "Training step: 17000\n",
            "Eval mean: -142.63471775355796; eval_std: 32.19233218360176\n",
            "Training step: 18000\n",
            "Eval mean: -237.30252735282411; eval_std: 25.891595199538244\n",
            "Training step: 19000\n",
            "Eval mean: -178.7839869553554; eval_std: 7.975567015458477\n",
            "Training step: 20000\n",
            "Eval mean: -68.11158064654974; eval_std: 42.024579063331416\n",
            "Training step: 21000\n",
            "Eval mean: -33.03059744525775; eval_std: 4.770461595675372\n",
            "Training step: 22000\n",
            "Eval mean: -71.32981622310889; eval_std: 11.5956503459218\n",
            "Training step: 23000\n",
            "Eval mean: -100.22078594212444; eval_std: 13.376643654991279\n",
            "Training step: 24000\n",
            "Eval mean: -85.54471922458121; eval_std: 20.993080115431482\n",
            "Training step: 25000\n",
            "Eval mean: -66.56066416585865; eval_std: 5.672940339694197\n",
            "Training step: 26000\n",
            "Eval mean: -78.0092769533605; eval_std: 9.201153935598498\n",
            "Training step: 27000\n",
            "Eval mean: -76.95788850735252; eval_std: 15.902455139628279\n",
            "Training step: 28000\n",
            "Eval mean: -50.1265408471913; eval_std: 5.6616588112314545\n",
            "Training step: 29000\n",
            "Eval mean: -32.16595269931944; eval_std: 6.459383072060739\n",
            "Training step: 30000\n",
            "Eval mean: -21.245356863285924; eval_std: 9.634643568111983\n",
            "Training step: 31000\n",
            "Eval mean: -16.196612909464147; eval_std: 8.995028863938108\n",
            "Training step: 32000\n",
            "Eval mean: -28.52372192041813; eval_std: 8.213145329399199\n",
            "Training step: 33000\n",
            "Eval mean: -55.257873345944354; eval_std: 15.547120781397831\n",
            "Training step: 34000\n",
            "Eval mean: -74.56509267707793; eval_std: 29.180635088343138\n",
            "Training step: 35000\n",
            "Eval mean: -68.22882065974574; eval_std: 18.25351098413942\n",
            "Training step: 36000\n",
            "Eval mean: -199.2715383973497; eval_std: 37.52381995934568\n",
            "Training step: 37000\n",
            "Eval mean: -92.01160498364165; eval_std: 10.422267192982742\n",
            "Training step: 38000\n",
            "Eval mean: -19.750597651077683; eval_std: 24.853416208777737\n",
            "Training step: 39000\n",
            "Eval mean: -25.98045841009784; eval_std: 6.874931812437712\n",
            "Training step: 40000\n",
            "Eval mean: -27.024243916505572; eval_std: 7.198847774984058\n",
            "Training step: 41000\n",
            "Eval mean: -26.722391733335055; eval_std: 4.924064262887918\n",
            "Training step: 42000\n",
            "Eval mean: -42.88614143653492; eval_std: 20.913232477634487\n",
            "Training step: 43000\n",
            "Eval mean: -46.2588707134581; eval_std: 86.76566572189446\n",
            "Training step: 44000\n",
            "Eval mean: -47.459649193190835; eval_std: 18.523560520340727\n",
            "Training step: 45000\n",
            "Eval mean: -46.329756301647144; eval_std: 20.486067245344888\n",
            "Training step: 46000\n",
            "Eval mean: -108.87979702543275; eval_std: 47.32000676873983\n",
            "Training step: 47000\n",
            "Eval mean: -33.1982717193741; eval_std: 28.491558996315987\n",
            "Training step: 48000\n",
            "Eval mean: -54.03406308796165; eval_std: 17.222719195414\n",
            "Training step: 49000\n",
            "Eval mean: -114.64950453552632; eval_std: 84.34447854604942\n",
            "Training step: 50000\n",
            "Eval mean: -44.56167188458276; eval_std: 29.517688189222227\n",
            "Training step: 51000\n",
            "Eval mean: -69.6426667763074; eval_std: 29.810163660955727\n",
            "Training step: 52000\n",
            "Eval mean: -23.704332353698945; eval_std: 47.503059431990124\n",
            "Training step: 53000\n",
            "Eval mean: 0.8821106908404074; eval_std: 10.579068168388504\n",
            "Training step: 54000\n",
            "Eval mean: -6.098381869794178; eval_std: 9.145104932558063\n",
            "Training step: 55000\n",
            "Eval mean: -18.525872899942698; eval_std: 12.30870901737992\n",
            "Training step: 56000\n",
            "Eval mean: -32.689893193946894; eval_std: 13.143470150922862\n",
            "Training step: 57000\n",
            "Eval mean: 108.63859267966411; eval_std: 37.2005599407597\n",
            "Training step: 58000\n",
            "Eval mean: 121.60354141506367; eval_std: 67.22829594714703\n",
            "Training step: 59000\n",
            "Eval mean: 57.85676060108062; eval_std: 73.37914898699185\n",
            "Training step: 60000\n",
            "Eval mean: -17.507671066150348; eval_std: 11.88659050000296\n",
            "Training step: 61000\n",
            "Eval mean: 31.16629792616085; eval_std: 55.93715702787204\n",
            "Training step: 62000\n",
            "Eval mean: 112.08473897970505; eval_std: 55.52778959896107\n",
            "Training step: 63000\n",
            "Eval mean: 211.69594262848696; eval_std: 18.347333461265162\n",
            "Training step: 64000\n",
            "Eval mean: 253.43406662052703; eval_std: 9.950888235722289\n",
            "Training step: 65000\n",
            "Eval mean: 245.30639513909975; eval_std: 26.744008762565695\n",
            "Training step: 66000\n",
            "Eval mean: 220.69623172561407; eval_std: 46.394864476602535\n",
            "Training step: 67000\n",
            "Eval mean: 185.81978886155676; eval_std: 28.93309087234048\n",
            "Training step: 68000\n",
            "Eval mean: 232.62009546540688; eval_std: 29.57830565450827\n",
            "Training step: 69000\n",
            "Eval mean: 229.70916777158595; eval_std: 37.61122115572504\n",
            "Training step: 70000\n",
            "Eval mean: 251.4322773296417; eval_std: 24.0716774734594\n",
            "Training step: 71000\n",
            "Eval mean: 158.0789547101767; eval_std: 87.82041727549813\n",
            "Training step: 72000\n",
            "Eval mean: 242.63787662805007; eval_std: 23.85205907184526\n",
            "Training step: 73000\n",
            "Eval mean: 217.5117172682599; eval_std: 50.55244276941835\n",
            "Training step: 74000\n",
            "Eval mean: 223.95880559006153; eval_std: 21.0991262042345\n",
            "Training step: 75000\n",
            "Eval mean: 246.59418730769275; eval_std: 20.59313094999952\n",
            "Training step: 76000\n",
            "Eval mean: 123.28100004483265; eval_std: 61.091659411802546\n",
            "Training step: 77000\n",
            "Eval mean: 239.85640976031047; eval_std: 28.12843658260638\n",
            "Training step: 78000\n",
            "Eval mean: 221.58457208652393; eval_std: 46.00617293703892\n",
            "Training step: 79000\n",
            "Eval mean: 244.79160137242016; eval_std: 26.055051490603134\n",
            "Training step: 80000\n",
            "Eval mean: 233.53458757327147; eval_std: 21.843255178654644\n",
            "Training step: 81000\n",
            "Eval mean: 110.4386986493094; eval_std: 97.5717012169416\n",
            "Training step: 82000\n",
            "Eval mean: 247.59365575472248; eval_std: 23.91848070109345\n",
            "Training step: 83000\n",
            "Eval mean: 248.62484213866549; eval_std: 14.173950725034455\n",
            "Training step: 84000\n",
            "Eval mean: 255.90702818570597; eval_std: 10.510154578233953\n",
            "Training step: 85000\n",
            "Eval mean: 272.0891263960121; eval_std: 10.837809422695402\n",
            "Training step: 86000\n",
            "Eval mean: 260.842801603649; eval_std: 14.204355498182856\n",
            "Training step: 87000\n",
            "Eval mean: 237.80453909309162; eval_std: 11.798589847700345\n",
            "Training step: 88000\n",
            "Eval mean: 262.49828541598345; eval_std: 14.796611156312245\n",
            "Training step: 89000\n",
            "Eval mean: 245.4197535965025; eval_std: 16.99916497348525\n",
            "Training step: 90000\n",
            "Eval mean: 193.83078439853762; eval_std: 40.966490141583165\n",
            "Training step: 91000\n",
            "Eval mean: 260.64291134468; eval_std: 17.33040147207507\n",
            "Training step: 92000\n",
            "Eval mean: 233.7783048244327; eval_std: 28.702762800711024\n",
            "Training step: 93000\n",
            "Eval mean: 248.01009549538526; eval_std: 14.837234351908439\n",
            "Training step: 94000\n",
            "Eval mean: 275.1040900117179; eval_std: 11.093549715517677\n",
            "Training step: 95000\n",
            "Eval mean: 231.74126251593484; eval_std: 46.02239983855931\n",
            "Training step: 96000\n",
            "Eval mean: 202.60265502988486; eval_std: 72.51914708945961\n",
            "Training step: 97000\n",
            "Eval mean: 271.0796962004452; eval_std: 13.061734170768041\n",
            "Training step: 98000\n",
            "Eval mean: 270.98109561755535; eval_std: 12.581677092547235\n",
            "Training step: 99000\n",
            "Eval mean: 270.0351573319642; eval_std: 3.7401388401608564\n",
            "[-639.69034775 -639.69034775 -639.69034775 -639.69034775 -639.69034775\n",
            " -639.69034775 -639.69034775 -639.69034775 -639.69034775 -639.69034775\n",
            " -639.69034775   35.81245657  -37.23668212  -61.05009392  -40.20526801\n",
            " -112.92667408 -230.50470904 -142.63471775 -237.30252735 -178.78398696\n",
            "  -68.11158065  -33.03059745  -71.32981622 -100.22078594  -85.54471922\n",
            "  -66.56066417  -78.00927695  -76.95788851  -50.12654085  -32.1659527\n",
            "  -21.24535686  -16.19661291  -28.52372192  -55.25787335  -74.56509268\n",
            "  -68.22882066 -199.2715384   -92.01160498  -19.75059765  -25.98045841\n",
            "  -27.02424392  -26.72239173  -42.88614144  -46.25887071  -47.45964919\n",
            "  -46.3297563  -108.87979703  -33.19827172  -54.03406309 -114.64950454\n",
            "  -44.56167188  -69.64266678  -23.70433235    0.88211069   -6.09838187\n",
            "  -18.5258729   -32.68989319  108.63859268  121.60354142   57.8567606\n",
            "  -17.50767107   31.16629793  112.08473898  211.69594263  253.43406662\n",
            "  245.30639514  220.69623173  185.81978886  232.62009547  229.70916777\n",
            "  251.43227733  158.07895471  242.63787663  217.51171727  223.95880559\n",
            "  246.59418731  123.28100004  239.85640976  221.58457209  244.79160137\n",
            "  233.53458757  110.43869865  247.59365575  248.62484214  255.90702819\n",
            "  272.0891264   260.8428016   237.80453909  262.49828542  245.4197536\n",
            "  193.8307844   260.64291134  233.77830482  248.0100955   275.10409001\n",
            "  231.74126252  202.60265503  271.0796962   270.98109562  270.03515733]\n",
            "[-639.69034775 -639.69034775 -639.69034775 -639.69034775 -639.69034775\n",
            " -639.69034775 -639.69034775 -639.69034775 -639.69034775 -639.69034775\n",
            " -639.69034775 -572.14006732 -518.6497288  -472.88976531 -429.62131558\n",
            " -397.95185143 -381.20713719 -357.34989525 -345.34515846 -328.68904131\n",
            " -302.63129524 -275.67122546 -255.23708454 -239.73545468 -224.31638113\n",
            " -208.54080944 -195.48765619 -183.63467942 -170.28386556 -156.47207428\n",
            " -142.94940254 -130.27412357 -120.09908341 -113.6149624  -109.70997543\n",
            " -105.56185995 -114.9328278  -112.64070552 -103.35169473  -95.6145711\n",
            "  -88.75553838  -82.55222371  -78.58561549  -75.35294101  -72.56361183\n",
            "  -69.94022628  -73.83418335  -69.77059219  -68.19693928  -72.8421958\n",
            "  -70.01414341  -69.97699575  -65.34972941  -58.7265454   -53.46372905\n",
            "  -49.96994343  -48.24193841  -32.5538853   -17.13814263   -9.6386523\n",
            "  -10.42555418   -6.26636897    5.56874183   26.18146191   48.90672238\n",
            "   68.54668965   83.76164386   93.96745836  107.83272207  120.02036664\n",
            "  133.16155771  135.65329741  146.35175533  153.46775153  160.51685693\n",
            "  169.12458997  164.54023098  172.07184886  177.02312118  183.7999692\n",
            "  188.77343104  180.9399578   187.60532759  193.70727905  199.92725396\n",
            "  207.1434412   212.51337724  215.04249343  219.78807263  222.35124072\n",
            "  219.49919509  223.61356672  224.63004053  226.96804602  231.78165042\n",
            "  231.77761163  228.86011597  233.082074    236.87197616  240.18829427]\n",
            "[59.38467171 59.38467171 59.38467171 59.38467171 59.38467171 59.38467171\n",
            " 59.38467171 59.38467171 59.38467171 59.38467171 59.38467171 57.37361355\n",
            " 57.82146971 54.44723442 50.40289562 48.92995623 49.58452134 47.84530242\n",
            " 45.6499317  41.88249523 41.89670362 38.18407941 35.52523651 33.31037722\n",
            " 32.07864751 29.43807679 27.41438451 26.26319157 24.2030383  22.42867277\n",
            " 21.14926985 19.93384575 18.76177571 18.44031022 19.51434271 19.38825953\n",
            " 21.20181558 20.12386074 20.59681628 19.22462784 18.02204983 16.71225127\n",
            " 17.13234939 24.09568103 23.53846898 23.2332288  25.6419066  25.92687184\n",
            " 25.05645658 30.98525877 30.83850171 30.73566791 32.41240706 30.22907317\n",
            " 28.12067635 26.53947961 25.19987867 26.3999468  30.48278171 34.77241844\n",
            " 32.48383564 34.82916778 36.89902996 35.04386031 32.53456311 31.95550767\n",
            " 33.39944335 32.9528081  32.61535786 33.11494419 32.21061752 37.77159749\n",
            " 36.37964365 37.79692356 36.12714383 34.57374254 37.22553423 36.31582446\n",
            " 37.28485931 36.16187853 34.73001619 41.0141847  39.3046143  36.79154794\n",
            " 34.1634086  31.83084868 30.06819937 28.24123841 26.89677569 25.90701462\n",
            " 27.41296217 26.4047061  26.63451177 25.45478403 24.0186606  26.21903452\n",
            " 30.84904578 29.07031462 27.42145086 25.05331966]\n",
            "[    0  1000  2000  3000  4000  5000  6000  7000  8000  9000 10000 11000\n",
            " 12000 13000 14000 15000 16000 17000 18000 19000 20000 21000 22000 23000\n",
            " 24000 25000 26000 27000 28000 29000 30000 31000 32000 33000 34000 35000\n",
            " 36000 37000 38000 39000 40000 41000 42000 43000 44000 45000 46000 47000\n",
            " 48000 49000 50000 51000 52000 53000 54000 55000 56000 57000 58000 59000\n",
            " 60000 61000 62000 63000 64000 65000 66000 67000 68000 69000 70000 71000\n",
            " 72000 73000 74000 75000 76000 77000 78000 79000 80000 81000 82000 83000\n",
            " 84000 85000 86000 87000 88000 89000 90000 91000 92000 93000 94000 95000\n",
            " 96000 97000 98000 99000]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwQAAAGdCAYAAACsDbRAAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYtNJREFUeJzt3Xd4VFX+BvD33jt3ajKTQiqEKkUQBUEhotiQoOiKbVllFVwsKKgIi4qooLuCP6zY267srgVEF3cVRBHFBsKCqCBFkF6SUJKZJFPvvef3x5iBIZNGeub9PE8ezdwzM2duQua+c873HEkIIUBERERERHFJbuoOEBERERFR02EgICIiIiKKYwwERERERERxjIGAiIiIiCiOMRAQEREREcUxBgIiIiIiojjGQEBEREREFMcYCIiIiIiI4pipqTvQGAzDwP79+5GYmAhJkpq6O0RERFQDQgiUlJQgOzsbsszPMIkaSlwEgv379yMnJ6epu0FEREQnYM+ePWjXrl1Td4Oo1YqLQJCYmAgg/AfF6XQ2cW+IiIioJjweD3JyciLv40TUMOIiEJRPE3I6nQwERERELQyn+xI1LE7IIyIiIiKKYwwERERERERxjIGAiIiIiCiOxUUNAREREVFN6LqOUCjU1N0gqhNFUWAymWpcf8NAQERERASgtLQUe/fuhRCiqbtCVGd2ux1ZWVkwm83VtmUgICIiorin6zr27t0Lu92OtLQ0rmxELZYQAsFgEAcPHsSOHTvQtWvXajf2YyAgIiKiuBcKhSCEQFpaGmw2W1N3h6hObDYbVFXFrl27EAwGYbVaq2zPomIiIiKi33BkgFqL6kYFoto2YD+IiIiIiKiZYyAgIiIiIopjrCEgIiIiqsT6ve5Gfb7e7VyN+nyNacyYMSguLsYHH3xQr487d+5cTJw4EcXFxfX6uM2FJElYuHAhRowY0WDPwRECIiIiIqo3O3fuhCRJ+OGHH5q6K1RDDAREREREFJeCwWBTdwFA0/eDgYCIiIhqRAgBf0hHaUCD2xvC4dIACkv8COlGU3ctrr333nvo3bs3bDYbUlNTMWTIEJSVlWHMmDEYMWIEZs6ciYyMDCQlJeGRRx6BpmmYMmUKUlJS0K5dO7zxxhtRj7d+/XpccMEFkce75ZZbUFpaGjluGAYeeeQRtGvXDhaLBX369MGSJUsixzt16gQA6Nu3LyRJwnnnnRf1+E888QSysrKQmpqK8ePHR+0MHQgE8Oc//xlt27aFw+HAgAEDsHz58qj7z507F+3bt4fdbscVV1yBw4cP1/hczZgxA3369MHrr7+OTp06RZbjLC4uxk033YS0tDQ4nU5ccMEF+PHHHwEAbrcbiqJgzZo1kdefkpKCgQMHRh73zTffRE5OTuT7e++9F926dYPdbkfnzp3x4IMPRr3OyvqxdetWDB48GFarFT179sTSpUuj+h8MBjFhwgRkZWXBarWiQ4cOmDVrVo1ff2VYQ0BEREQV+EM6AiEDfk0P/79mIKgZiLWJr9OqQlUav48EHDhwANdeey1mz56NK664AiUlJfj6668juy1//vnnaNeuHb766it8++23GDt2LFasWIHBgwdj1apVmD9/Pm699VZcdNFFaNeuHcrKypCXl4fc3Fz873//Q2FhIW666SZMmDABc+fOBQDMmTMHTz75JF555RX07dsXf//73/G73/0OP//8M7p27YrVq1fjzDPPxGeffYZevXpF7ZT7xRdfICsrC1988QW2bduGkSNHok+fPrj55psBABMmTMDGjRsxb948ZGdnY+HChRg2bBjWr1+Prl27YtWqVRg7dixmzZqFESNGYMmSJZg+fXqtztm2bdvw/vvv49///jcUJfyLe80118Bms+Hjjz+Gy+XCK6+8ggsvvBC//PILUlJS0KdPHyxfvhz9+/fH+vXrIUkS1q1bh9LSUiQkJODLL7/EueeeG3mOxMREzJ07F9nZ2Vi/fj1uvvlmJCYm4p577qm0H4Zh4Morr0RGRgZWrVoFt9uNiRMnRvX92WefxX//+1+8++67aN++Pfbs2YM9e/bU6vXHJOKA2+0WAITb7W7qrhARETUbIU0X3oAmisuCosDjE3uOlImtBSVi/d5i8dOemn/5glqD9K8x3799Pp/YuHGj8Pl8UbfX5jzUx1dtrV27VgAQO3furHBs9OjRokOHDkLX9cht3bt3F+ecc07ke03ThMPhEO+8844QQohXX31VJCcni9LS0kibRYsWCVmWRX5+vhBCiOzsbPHoo49GPdcZZ5whbr/9diGEEDt27BAAxLp162L2R9OO/r5cc801YuTIkUIIIXbt2iUURRH79u2Lut+FF14opk6dKoQQ4tprrxWXXHJJ1PGRI0cKl8tV+Uk6xvTp04WqqqKwsDBy29dffy2cTqfw+/1Rbbt06SJeeeUVIYQQkyZNEsOHDxdCCPHMM8+IkSNHitNOO018/PHHQgghTjrpJPHqq69W+ryPP/646NevX5X9+OSTT4TJZIp6/R9//LEAIBYuXCiEEOKOO+4QF1xwgTAMo9rXWtnvdCwcISAiImrlDEPAFwp/0u/XjMin/7oR4+N+alFOO+00XHjhhejduzfy8vIwdOhQXH311UhOTgYA9OrVK2qDqoyMDJxyyimR7xVFQWpqKgoLCwEAmzZtwmmnnQaHwxFpM2jQIBiGgS1btsBms2H//v0YNGhQVD8GDRoUmWJTlV69ekU+lQeArKwsrF+/HkB4qpKu6+jWrVvUfQKBAFJTUyP9u+KKK6KO5+bmRk1Zqk6HDh2QlpYW+f7HH39EaWlp5DnK+Xw+/PrrrwCAc889F3/729+g6zq+/PJLDB06FJmZmVi+fDlOPfVUbNu2LWpq1Pz58/Hss8/i119/RWlpKTRNg9PprLIfmzZtQk5ODrKzs6Ne27HGjBmDiy66CN27d8ewYcNw6aWXYujQoTV+7ZVhICAiImplhBDwBnWUBTSUBjR4g3rMqT7U8imKgqVLl2LFihX49NNP8dxzz2HatGlYtWoVAEBV1aj2kiTFvM0wGqcOpKrnLi0thaIoWLt2bVRoAICEhIR668OxYaf8ebOysirUKgBAUlISAGDw4MEoKSnB999/j6+++gozZ85EZmYmHnvsMZx22mnIzs5G165dAQArV67EqFGj8PDDDyMvLw8ulwvz5s3Dk08+WWU/auL000/Hjh078PHHH+Ozzz7D73//ewwZMgTvvfderR/rWAwERERELYg/pCOoG9B0AU03EDIEdF0gZIQ/8Q/pBhrp2o6aCUmSMGjQIAwaNAgPPfQQOnTogIULF57QY5188smYO3cuysrKIhes3377LWRZRvfu3eF0OpGdnY1vv/02as78t99+izPPPBMAIjUDuq7X6rn79u0LXddRWFiIc845p9L+lYedct99912tnud4p59+OvLz82EymdCxY8eYbZKSknDqqafi+eefh6qq6NGjB9LT0zFy5Eh89NFHUedixYoV6NChA6ZNmxa5bdeuXdX24+STT8aePXtw4MABZGVlVfranE4nRo4ciZEjR+Lqq6/GsGHDcOTIEaSkpNTylR/FQEBERNREQnq4UDekG5GLfEWWYJIlmBQZqiIBAMoCOrxBDWUBndN8KMqqVauwbNkyDB06FOnp6Vi1ahUOHjyIk08+GT/99FOtH2/UqFGYPn06Ro8ejRkzZuDgwYO44447cP311yMjIwMAMGXKFEyfPh1dunRBnz598MYbb+CHH37AW2+9BQBIT0+HzWbDkiVL0K5dO1itVrhc1W+41q1bN4waNQo33HADnnzySfTt2xcHDx7EsmXLcOqpp2L48OG48847MWjQIDzxxBO4/PLL8cknn9RqulAsQ4YMQW5uLkaMGIHZs2ejW7du2L9/PxYtWoQrrrgC/fv3BwCcd955eO6553D11VcDAFJSUnDyySdj/vz5eOGFFyKP17VrV+zevRvz5s3DGWecgUWLFtUooA0ZMgTdunXD6NGj8fjjj8Pj8USFCgB46qmnkJWVhb59+0KWZSxYsACZmZmRkYwTxUBARETUSIKagdKAFpnKo+mt4+K+NY9INPedg51OJ7766is888wz8Hg86NChA5588klcfPHFmD9/fq0fz26345NPPsFdd92FM844A3a7HVdddRWeeuqpSJs777wTbrcbkydPRmFhIXr27In//ve/kSkzJpMJzz77LB555BE89NBDOOecc2JOx4nljTfewF//+ldMnjwZ+/btQ5s2bTBw4EBceumlAICBAwfitddew/Tp0/HQQw9hyJAheOCBB/CXv/yl1q+1nCRJWLx4MaZNm4Ybb7wRBw8eRGZmJgYPHhwJQUC4juCZZ56JqhU477zz8OOPP0bd9rvf/Q533303JkyYgEAggOHDh+PBBx/EjBkzquyHLMtYuHAhxo4dizPPPBMdO3bEs88+i2HDhkXaJCYmYvbs2di6dSsURcEZZ5yBxYsXR9WJnNA5EKL1zyr0eDxwuVxwu90VCjqIiIjqixDh4t1SvwZ/yIAhBHQhYBgCmiFaTQDQdWDLRhlrVpqweqUJP60xYetWCW3a1O/zNOb7t9/vx44dO6LWhCdqyWrzO80RAiIiojrQDQG3L4RSv4aSQKjVflqev1/C15+r+Ha5CWu+U+BxR38i+dVXwJVXNlHniKhOGAiIiIhqSQiBkoCG4rIQPP5Qq1zBxzCAH9cq+PIzE77+XMXWzdGrvjgSBE4/U8MZuRquusyMAf25Mxk1vV69elVawPvKK69g1KhRjdyjloGBgIiIqAYMQ6A0qKHUr8HtC7WI6T+6Dqz6xoQP31fxvxUm6MeNXqSlC/Tuq+G0fjpO66cju52Btd8p+OxjFZ9/ouJQ4dFRAFkWOPV0HWefp2HgYA09e+sw/XYV0TXDDIV5gJqBxYsXIxQKxTx2bD0ARWMgICIiqoQvqKMkEJ4O1FLW8g8GgK2bFXzykYpF/1ZxsLDyYsPDB4HNPytY8Gb4e5NJQNOkyPFEp8A5F4RwzgUaBp2nISm5BZwAimsdOnRo6i60SAwEREREv9F0AyX+8ApAJX6tWS7xGfADhw9JKD4ioeiIjOIiCQf2ydi6WcYvmxTs2i5HXdS7kgxcfHkIQ4eH4Ew6+nqEAHbvlPHjGhN+/F7BxvUKQkEJySkGzs/TMOTiEAYM0qCam+JVNp04WGuF4kRtfpcZCIiIKK4JIeDxaygqC6I0oDX6KIDXC/yyUcGmDQq2b5XRNsdA7746ep6qw2YLtynMl/DFpyq++MSE1StMURf8sSS6BM4YqOGyq4IYfGHlF/Xdexq46BINQHhkYf8+Ge3aG5GpQPGkfGfcYDAIW/mJJ2rBvF4vgIq7Q8cSh//kiYgoXgS08BKgZQEdpQENsgyoigyzIkNVZBhCoNgbatSRACHCxbqLFqpY850JO7bJMIyKF/iKItCtpwGTSWD9uui3a7NFIClZIDlFIClFoE2agZO6G+h2so6uPXRkZAlIVWeGCswWoGPnVrpEUg2YTCbY7XYcPHgQqqrWeV13oqYihIDX60VhYSGSkpIiYbcqDARERNSqaLqBI2VBFHlDCGrRF7i6AYQ0HV7ojd6v3TtkfLQwPK9/z67oN+i0dAMn99bRuauBPbtk/LRWwcFCGZvWH2136ukaLsgL4fw8DR07G7W+4KeqSZKErKws7Nixo9JVaohakqSkJGRmZtaoLQMBERG1Cr6gjkOlAbh9Tb8M6OGDEn5YE54GtPlnBZvWK1HFvTa7wIUXh3DRJSGccpqOtIzoDgsBFByQ8NP3CnxeCbmDNaRncm57QzObzejatSuCwWBTd4WoTlRVrdHIQDkGAiIiatHcvhAOlQbgDTT+p/7HMgxg9bcK5v/LguWfmqDr0R/hy7LAwLM1XHpVCBcMC8Fur/yxJAnIzBbIzNYauNcnTpIAp1VFaoIZVrX1rDkqyzJ3Kqa406AT5GbNmoUzzjgDiYmJSE9Px4gRI7Bly5aoNn6/H+PHj0dqaioSEhJw1VVXoaCgIKrN7t27MXz4cNjtdqSnp2PKlCnQtOb7R5KIiBqWYQgcLg3gl4IS7D7sbdIwUFoC/PNVMy4/LwG3XJeAZR+r0HUJ3XvquGJkEPf/xYd/LizFio0evPyWF5deWXUYaO4UWUJaogXdMhLRPtUOh4WfLRK1dA36r/jLL7/E+PHjccYZZ0DTNNx///0YOnQoNm7cCIfDAQC4++67sWjRIixYsAAulwsTJkzAlVdeiW+//RYAoOs6hg8fjszMTKxYsQIHDhzADTfcAFVVMXPmzIbsPhERNTOGIXCoLIBDJcEmXxI0FALef8uMl56xoOhw+PM1R4LA764O4po/BnFS9+ZToGtSJLhsKkK6AX/IqFBbURM2s4xUhwUumwpZZgEDUWsiiUZccPfgwYNIT0/Hl19+icGDB8PtdiMtLQ1vv/02rr76agDA5s2bcfLJJ2PlypUYOHAgPv74Y1x66aXYv39/ZIe5l19+Gffeey8OHjwIs7n6BZI9Hg9cLhfcbjecTmeDvkYiIjpxQghIMaplm1MQEAL44hMTnp5lxa7t4akyHTrrGH1LAJeMCMHuaNLuRVFNEtISLEhxmKPOq2EIBDQDR7xBFJUFK625kCTAZQtPC7KbG38kgO/fRI2jUf91u91uAEBKSgoAYO3atQiFQhgyZEikTY8ePdC+fftIIFi5ciV69+4dtd10Xl4ebrvtNvz888/o27dvhecJBAIIBAKR7z0eT0O9JCIiqifF3iAKPAGEdANmkwyLSYbZJEOWJBwubR5BYOVXJrwyx4J1/wu/fSanGrh9UgBXXhtEDZb6bhSSBFhVBakOM5LsasyAJcsSbGYFbc02pDrM2F/sQ9kx065kGUh1WJCaYIaqcPlNotau0QKBYRiYOHEiBg0ahFNOOQUAkJ+fD7PZjKSkpKi2GRkZyM/Pj7Q5NgyUHy8/FsusWbPw8MMP1/MrICKihlAa0JDv9sEXPDqNJRAyEAg1jyk3hgEsW2LC3563YOP68NumxSJwwy0B3HhbAAmJTds/SQLMJhkOiwkJv30ptZjSY1UVdE5LiBRnO60qUhzmWj0GEbVsjRYIxo8fjw0bNuCbb75p8OeaOnUqJk2aFPne4/EgJyenwZ+XiIhqzuMP4XBpEKX+5rlIRCgILP5Axd9fsmDHtvDUIKtN4Orrghh9awAZWfU3YiFJgM2swGE2wRvU4A3qFabxlK/qk+RQYTHJUCQJiizFHAE4ES6bCpetmQxzEFGjapRAMGHCBHz00Uf46quv0K5du8jtmZmZCAaDKC4ujholKCgoiGykkJmZidWrV0c9XvkqRJVttmCxWGCxWOr5VRARUV1pevm89YqbhjUX3jLg/bfN+OdrFhQcCE+XSXQJXDcmgOv+FERySv0EAUWWkGRXkWA1IcFsiirU1XQDbl8Ibl94F+UkuxnJdhUmTt8hogbQoIFACIE77rgDCxcuxPLly9GpU6eo4/369YOqqli2bBmuuuoqAMCWLVuwe/du5ObmAgByc3Px6KOPorCwEOnp6QCApUuXwul0omfPng3ZfSIiqieGIZDv8eNIFQWsDWXLRhkfvGvG/1aY0G+AhvGT/XAmVWznLpLw5t/MeGeuGR53+MI7Ld3AqJsC+P0fg/U2NchsktEmwYxku7nS1XpMiozUBAtSE/jhFhE1vAZdZej222/H22+/jf/85z/o3r175HaXywWbzQYAuO2227B48WLMnTsXTqcTd9xxBwBgxYoVAMLLjvbp0wfZ2dmYPXs28vPzcf311+Omm26q8bKjXKWAiKjplPhD2FfsQ0hrvCTgKQYWf2DGwnfN2LQ+etOs5BQDE6f6cfnvQ5BloMQD/Ot1C9583YLSkvAFeofOOsaMC+CyK0Mw19M1uc0so01CeNnO+prm09rx/ZuocTRoIKjsD94bb7yBMWPGAAhvTDZ58mS88847CAQCyMvLw4svvhg1HWjXrl247bbbsHz5cjgcDowePRqPPfYYTKaaDXDwDwoRUePTDYH9xT4Ue0ON9pzlF/f/es2CstLwe5BJFTh/qIbcwSG8+boF27eGA8Kpp2vIPUfD23MtKHGH23Y7Wcctd/lx4TANSj1svmtV5fDcfLsKi6n17ObbWPj+TdQ4GnUfgqbCPyhERI2rxB/C3iIfNL1x3mK8XmDeXDPeeMkCd3F4uk+XbjquHhXEJSNCkXn/oRDw1t/MePkZK7xlRz+06txVx+2T/BhyiQa5jtP0JQlIdpjRJsHMEFBHfP8mahzcb5yIiOqNEAIH3H4cLg02yvPt2SnjPwtUvP+OGYcPhq/kO52kY/zk2Bf3qgqMGRfExZeHMOcxK3Zsk/HHm4IY9rtQvYwIuGwqMlwWBgEialEYCIiIqF74Qzr2HPHC38D7B3jLgKWLVHzwrhlrVx19G2vb3sBtd/sx/IrqL+4zsgRmzvHVW5/sFgVZLmuT7OZLRFRX/MtFRER1IoTAodIgCjz+ellBSIjwtJvjaRrw3ltmvPDE0WlBkiSQO1jD5deEMOTiEFRz3Z+/NiQJSHdakJ5obdwnJiKqRwwERER0wrxBDfuLo3cZPhFCAB/MV/HsbCskCci7LIRLLg/hlD46JAn47hsFs2fYsG1L+KP/nA46RowM4bKrg8isxw3CakM1SWifYueoABG1eCwqJiKiWtPL9xWoh1qB/XslPHKvDSu+qrhLbk4HHW3bG/ju6/AxV5KB8X8O4OpRQdRwobkG4bKpaJtsg1LJPgJUP/j+TdQ4+LEGERHVijeoYddhb51XEDIMYMGbZjw9M7zij8UiMP7PfnQ6ycDH/1Hx+Scq9uxSsGeXAkURGHlDELfdHYAruek+x5JlINtlQ7KjkecmERE1IAYCIiKqsdKAhp2HyupcK7DmOwVPz7Ri/brw21DfMzQ8/IQPHTuHpx6dO0SD1+vDl0tVbN8qY9jvQujSrWGLlauTYDWhbZINZlMd1yUlImpmGAiIiKhG3L4Q9hzx1ikM/LJJxrP/Z8VXy8JTgGx2gTvv9ePaMcEKS4Ta7cDFlzfepmaVkSQgy2VFakI9bVlMRNTMMBAQEVG1isqC2FfsO+EwcGCfhBeesOLD91UIIUFRBK66LohxEwNok958S9kcFgVtk23cV4CIWjUGAiIiqtKh0gAOFPtP6L6eYuD1F6x4+w0zgoFwAe7QS4OYMCUQmR7UGGxmBSkOMw64fTBq8LSyDGQ6OSpARPGBgYCIiCp1sCSAfHftw0DAD8z7hxmvPWeBxx2eC9R/oIa77/ejd1+9vrtZKbtFQXqiBYnW8BQlqypj+8GqayBYK0BE8YaBgIiIYir0+FHgCdT6fnt3SbjrJge2bg5Ps+nSTcfd9/txzgVazA3HGoLNLCPTZUOCJfptzm42oUOqHbsOV6yFUGQJWS4rVxAiorjDQEBERBUUePwoPIEwsHqFgsm32uEulpGaZuCue/247OoQlEaagl+TqT6JVhU5yXbsPuKN3OayqchKskJVOCpARPGHgYCIiKIccPtwqKR2G44JAcz/hxn/N8MKXZdwymkann7Ni4xG3EU4ya4iy2WFqQYX9S67imzDioOlAWQn2eC0VtwUjYgoXjAQEBFRRG3DgM8HbN2s4P23zVg4LzzVZvgVQUz/Px+stobq5VFWVUaiVYXLpsJmrt0wRGqCBSkOM6TGmsdERNRMMRAQERGA8DShmoSBrz83YfEHKjb/rGDHNhmGEb6gliSBu6b6ceO4YIPWCphNMlITzEi0muq8HCjDABERAwEREQEoLKlZzcC/56mYMcUedVtKGwMnn6Lj+puCOOtc7YT7IMtAu2Q7DEOgoMSPkBY93UiSgNQEMzISrZBlXsgTEdUXBgIiojh3qDSAAnf1YWDhPBUP3xOeB3TZ1UEMuyyEHr10pGXUvU7Aqspon2qPfOLvsqk4VBbAwZIADCN8vF2yvdbTgoiIqHoMBEREcaymm459MF/FjHtsEELCdTcGcO/D/nqbFpRkV9E2yRb1qb8sS0hPtCLFbkaJX0OSXeX0HiKiBsJAQEQUhwxDYF+xD8XeULVt//OuiulTwmHg2jH1FwYkCchOsiGlinX/TYrMfQGIiBoYAwERUZzxh3TsPuJFIGRU2/bfv00TEkLCH0YHcN8j9RMG7BYF7ZJtdS4KJiKiumMgICKKI0fKgthf7KuwS28sc18246lHwzUDI28IYOpf6h4GJAnIdFnRpoqNw4iIqHExEBARxYmDJQHku6uvFxACeG62Ba8/bwUA3HhbABOn1j0MJFpNyEqyclSAiKiZYSAgIooDpQENBZ7qw4BhALMetGL+P8Of4N91nx9jx1e/AlFlJAlIcZiRmmBmECAiaqYYCIiIWrmgZmD3YW+104R0HXjgbhsWLTRDkgQemOnHNX+s+a7Fx5IkIMNpRYrDDIV7BhARNWsMBERErZgQAruPeKEbVacBwwAeuTccBkwmgUef8eHiy6tfgSgWWQY6pDqQYOFbDBFRS8C/1kRErdi+Yh98Qb3KNkIATzxixcL5ZsiywOwXvRhy8YntOKzIEjq1cXADMSKiFkRu6g4QEVHDOFIWRFFZ9Z/yv/S0BW/+LVwz8PATvmrDgCSFdw4+nmqS0DmNYYCIqKXhCAERUSsU0HTsL/ZV2+6fr5rx8tPh1YSm/sWHy6+pPkC0TbIh2WGGbgiUBTV4AzoCmo4slw1mEz9nIiJqaRgIiIhaGSEE9hypeq8BIYB/vHJ0n4EJU/y4dkz1BcRZSdbIzsGKLMFpVeG0qvXSbyIiahoMBERErczBkkCVdQNlpcD0KTZ8+lH4wn7MuABuvqP6pUXTnRZuKEZE1AoxEBARtSK+oI7Cksov7ndsk3H3LXZs36rAZBK4Z7ofI0cHq910LDXBjAyntZ57S0REzQEDARFRKyGEwN6iyvcbWLrYhAcn2eEtk5CeYeCJl73o07/qFYgAIMmuIjvJVs+9JSKi5oKBgIiolSjwBOAPGTGPfbrIhD+PcwAA+g/U8PiLXqSmVbNTGYA2iWZkuRgGiIhaMy4HQUTUCpQFNBysZKrQj98rmHaXHQBw1XVBvPpOWY3CQFaSlWGAiCgOcISAiKiFE0JgXyVLjO7dLeHOP9kRCEgYPCSEB2b6oFSzTYAkATnJdrjsXD2IiCgeMBAQEbVwhSUBBGJMFfIUA+NHO1B0WEaPU3TMft5bozDQsY0DCRa+PRARxQtOGSIiasH8IT3mVKFQEJg0zoEd2xSkZxp47u9lsDuqfiyGASKi+MRAQETUQlW1qtDjj1ix+lsT7A6BF/5Rhoys6msGcpLtDANERHGIgYCIqIU6VBqEL1hxqtB33yiY94/wBmKzX/Cie8/YKw8dq22yjTUDRERxioGAiKgFCmg6Cjz+CreXlQIzpoRXFBp5QwCDL9SqfawMlwUpDnO995GIiFoGBgIiohZoX5Ev5lShpx61Yv9eGdk5Bu6+v2JgOF5aogXpidyBmIgonnGyKBFRC3OwJICyQMUdhr/7RsGCN8NThR5+3FtlEbEkAdlJNo4MEBERAwERUUviD1U/Vej31wcwYFDFwFDOpEhon2KHgwXEREQEBgIiohZDCIE9R2KvKvT0zKNThSZNq3yqkM0so32KA2YTZ4wSEVEYAwERUQtR4AnAH2MDsu9XK3j3X9VPFUq0mtA+xQ5Zlhqym0RE1MLwIyIiohagLKDF3IBM14HHptsAAFdeG6x0qpDDojAMEBFRTAwERETNnG4I7Cnyxjz2nwUqNm9QkJAocMc9sacK2cwKOqY6GAaIiCgmBgIiomasvG4gpFUsHCgtAZ79v/CSoeMm+pHapmIbqyqjUxuGASIiqhwDARFRM7a3yIcSf+zNxV57zoojh2R06Kzj2jHBCsctv4UBhWGAiIiqwEBARNRM7S3yotgbinls9w4Z/3o9vIfAnx/0Qz1uOwFJAjqk2mFS+GeeiIiqxncKIqJm6IDbh6Ky2GEAAJ78qxVaSMJZ54Yw+MKKIwgZTissJqUhu0hERK0EAwERUTNT6PHjUEnFKUDlvvtawRefqlAUgSkP+SEdNyPIZlaQlmhp4F4SEVFrwX0IiIiaidKAhgKPH95A5bsMh4LA/80ILzM68oYgunSL3pdAkoB2ybYG7ScREbUuDARERI3kcGkAbl8IDosJdrMCh9kEWZZQ4g+hsCRQZRAo9/cXLfj1FwXJqQZuu7vivgRpiRZYVU4VIiKimmMgICJqBPluf2RjsbLfLvwlCTApUswlRWPZ8auMV58LTwW6d4YfruTo+1lUGemcKkRERLXEQEBE1ICEENhXHLtAWAjUOAwYBvDIvTaEghIGnRfCxZdXfLx2yTZIxxcUEBERVYOBgIiogRiGwO4j3kr3EaiNhfNVrF1lgtUm8MBMX4VC4mSHCruZf9KJiKj2+O5BRNRAdh3xorQewsChQglPPRouFJ7wZz/a5kSPKkgSkJ5orfPzEBFRfGoxy46+8MIL6NixI6xWKwYMGIDVq1c3dZeIiCp1uDRQL2EAAGbPsKLELaFnbw3X/anicqQpDjPMphbz55yIiJqZFvEOMn/+fEyaNAnTp0/H999/j9NOOw15eXkoLCxs6q4REVUQ1AwccPvr5bHm/cOMJR+aoSgC02f7YDpuXFeSwD0HiIioTlpEIHjqqadw880348Ybb0TPnj3x8ssvw2634+9//3tTd42IqIK9RV6ImtUKV0oI4IUnLZj5QHiq0NjxAZx8ilGhXZsEC1SlRfwpJyKiZqrZv4sEg0GsXbsWQ4YMidwmyzKGDBmClStXxrxPIBCAx+OJ+iIiagyHSwORZUVPlK4Df5lqxSvPhOsCxt3tx/g/V9xzQJaBNgnmOj0XERFRsw8Ehw4dgq7ryMjIiLo9IyMD+fn5Me8za9YsuFyuyFdOTk5jdJWI4lxA0+s8VSjgB/48zo733rJAksIrCt0+KVBhVSEASEuwwMTRASIiqqNW+U4ydepUuN3uyNeePXuauktEFAf2FflOaKqQEMDmn2W88IQFV+clYNkSFapZ4ImXvfj99RWLiAFAkSWkJrB2gIiI6q7ZLzvapk0bKIqCgoKCqNsLCgqQmZkZ8z4WiwUWC98oiajxFJb4q5wqtHe3hFeesWL3ThmJToFEp0BCooAQwDfLVezfc/TzmUSXwDOvleGM3MofLy3RAkXmJmRERFR3zT4QmM1m9OvXD8uWLcOIESMAAIZhYNmyZZgwYULTdo6ICEBpQEOhp+IcfwAoKwVef96Cf71uQTBQ+QW81Spw1rkaLhgWwnlDQnAmVf58qklCqoO1A0REVD+afSAAgEmTJmH06NHo378/zjzzTDzzzDMoKyvDjTfe2NRdI6I4F9IN7D5ccVUhwwA+fE/FnP+z4lBh+NP/AWdruGJkEH4/UOKWUFoiweeT0Ke/hrPO1WC31+w5s5w2yBwdICKietIiAsHIkSNx8OBBPPTQQ8jPz0efPn2wZMmSCoXGRESNSQiBXYe90A1x3O3Aw/fYsHB++FP8nA46/vygH+cN1WIWB9eGw6LAZVfr9iBERETHkISo62rZzZ/H44HL5YLb7YbT6Wzq7hBRK7G/2IfDpRWLfv/2ggVzHrNClgXuvM+PP/4pCHM9lDVJEnBSegKsqlL3ByNqAfj+TdQ4WsQIARFRcyGEgCEAjy8UMwwsXWzCnMfC+wfc97AffxgTe5WgE5HsMDMMEBFRvWMgICI6Rkg34A3qCGg6gpqBgGYgqBnQDVHtkqI//6hg2l3hQoDrbgzUaxhQZAkZiVw9jYiI6h8DARHFtaBmoCygoTSgwRsMh4ATkb9fwh1/ssPvl3D2+SH8+aG6bVB2vAwnNyEjIqKGwUBARHEnpBtw+0Io9obgC1a+1n9NecuAO2504FChjJO665j9ghemevzrajPLSOEyo0RE1EAYCIgobri9IRwqC8BbxQZitWUYwP132bFlo4KUNgaen1uGhMR6e3i4bCraJtsg1XV5IiIiokowEBBRqyaEQLE3hIOlAQRCJzYdqCrPzbbg809UmC0Cc/7mRXa7+lm4TZKALJcVqQmsGyAioobFQEBELZ4/pMMf0hHSj16MSxJgCIGistAJ1wVU58P3VfzthfCKQg8/7sNpp9fPyIPZJKN9ih02M1cUIiKihsdAQETNnmEIhAwDmi6g6eH/D+kGfEEdvpAOo2Gu96v041oFM+6xAQBumuDH8CtCtX4MSQpf/JsVOfzf374cZhMU7kRMRESNhIGAiJoNb1CD2xdCqV+DZggYQjTJxX5lDAM4WCBhx68y7rvDjlBQwoXDQpgwJVDl/SQJsJsVJFhMsKgKzIoMVZG4ahARETULDARE1GCEEAhoxm9TesL/1QwBVZGgKvJvXxJ8IR1uXwghrflsnC4EsH2rjJVfm/C/FSbs+FXG/r0ygoGjn9x376nj0We8kCu5rk9LtMBpM8GmKiwKJiKiZouBgIjqhRACJQEN/qAeCQEBzYi5mZev8btXI5oGfPWZCcs+UbHqaxMKCype6SuKQFZbA917Gbh3hg92R8XHkSQgJ8UOl01thF4TERHVDQMBEdWZphvYfcSLsnpczrMxHdgn4d/vmLFwnjkqBFgsAqefqWHAORp69tbRrr2BzGxR5R4DJkVCx1QHC4KJiKjFYCAgojrxBjXsOuyFpjef6T419eNaBa89b8E3n5tgGOEpPcmpBi67MoSzLwihb38dFmvNH8+iyuiY6oDZxNoAIiJqORgIiOiEHSoNIN/tjzktqDlbv07Bi09Z8O3yo1N6zjhLwzWjgrggLwTzCSz9bzMr6NTGwdWBiIioxWEgIKJaMQyBEr+GIm8QJX6tqbtTY0IAP6xR8LcXLPhqWTgIKIrA764JYcy4ADp1OfHljMIjA3aGASIiapEYCIioWuUhwO0LweMPNcqIgK4DhwolHNgnI3+/jMxsA6eerle6ok9lfv1FxqKFKhb/x4z9e8J3lmWBy64K4ZY7A8jpWLd1TctrBriEKBERtVQMBERUqbJAeCTA7Qud8H4AJR5g0wYFG39SsHG9grJSCQPP1jB4iIYOnY4+qNcLrPzShM8/VbFutYL8AzK0UPQn7tntDFx8eRDDrwjhpO4GfD5g408K1q9TsOFHBYcPyhACkcDicUv49Zejxb12h8DQ4SGMnRCIeu4TJctApzasGSAiopZNEqKlzf6tPY/HA5fLBbfbDafT2dTdIWrWNN3AEW8Qxd4QAqHaXTQHA8CWjQrW/6Bgww/h/+7aXvlqOx276Bh0noa9u2R897UJgUB0AFAUgYwsgfRMA1s3h8NEuay2BgrzJeh61dN0TCaBQedpGH5FCOdeFILNVquXVClJAjq2cSDBws9ViBoK37+JGgffyYgIAOAP6ThUGkCxt+ZTgrxlwLr/mbDmOwVrvjNh43oFoWDFC/TsdgZO7q2jZ28dFovAN8tNWPOdCTt/VbDz16OBoW17A+dfFMI5F2jo2EVHWsbRJT79PuDLz1QsWqjim+UmHNgX/lQ+LT08lah3Xw3t2huAFL5YBwCTCeh7ho6k5Pr73EORJTgsClIcZoYBIiJqFThCQBTnPP4QDpUEarSHgBDAlo0yli9V8fXnJmz8SanwCX1SsoHefXWc0kdH7z46ep2mIzml4p+Z0hJgxVcmrP7WhLR0gfPzQujaw0BNNvR1F0nYuF5Bp5N0ZGSJGt3nREkS4LSqSLCaYDcrsKrcX4CosfD9m6hxMBAQxSm3L4SDJX74glVPCxICWLtKwacfqVi+VEX+/uj58tk5BvoP0NB/oIbTz9SR07FmF/XNnVWVkewwI8mmsmCYqInw/ZuocXC8myjOuL0hFJb44a+mPsAwgC8/M+H15y1Yv+7onwqrVWDgORrOvSiE3HM0ZLdrXZ8pJFhNyHBaYDfzzyMREcUHvuMRtVBCCEi1+CjeMAT2FftQ7A1V2U7TgE8+VPH685bICj0Wi8AlI0K4YFgIAwZpsNZTYW5zYlFlZLqscFrV6hsTERG1IgwERC1ISDfg8YXg8WsoC2hIsqvIdFqrndLiD+nYfcRb5apBhgF8ttiE55+wRgp9HQkCfxgdwB/HBpGa1rpGAsopsoQMpwUpDnOtAhYREVFrwUBA1MxpuoFiXwjF3hB8wejC36KyENy+ENITrWiTEPuC9khZEPuLfZWuHCQE8M1yE56bbcXmDeEgkJRs4Pqbgxh5QwBOV72/pGbDZVORnVR9oCIiImrNGAiImiEhBEoCGorKgijxa1UuA2oYQL7bjyJvEEk2FZohoOkCmmEgpAsEtcpHBTb/LOP/ptuwdlX4T4EjQeCGWwK4/qYAEhLr7/VIEmA3K7CbTZAk4HBpELpR9YiDJAFmkwybqsCiyie0L0JlFFlCdpIVSXZzvTweERFRS8ZAQNSMGIbAEW8Qh0oDCGm1m6ITCBkoCAVq1NZdJOH5JyxY8KYZhiHBbBH4w+ggxo4PxFwi9Fg2s4wEiwqbWYE/pKPEH6qwUlH5Wv0OiwkOswlWVY4avUhLsOBwWfh1anr4+SQJsJkVJFpMSLCaYDUpkOWj90l1WLC3yAuPT6vpKYnJaTMhO8kGlaMCREREABgIiJoFTTdwpCyIQzX45LwudB1YOF/Fs49ZUVwUviAedlkQkx7wIzO78ue1WxSk/rYR17HTa1w2FRlOK0K6gVK/Bs0QSLCYYDNXvVa/LEtIS7Qg1WFGkTcIRZYqPPbxFFlCh1QHCjx+FHpqFnwkCbCqChyW8OiE3awwCBARER2HgYCoiR0sCaDA46/x7sAA4CkGNq5X0L2XUe0n+uX275Vw/112fL86/M/+pO46pv7FhzNyK9+QTDVJyHRWP7VGVcJr9teWLEtITbDU6j4ZTiusqoK9RV6oigy7WYHDHA4hZkWGJIHFwURERLXAQEDURIKagb1F3hrtEAwABwskfP6Jis+XmPC/lSZomoTkFAMPP+HDeRdVPY1m8Qcq/nq/DaUlEhwJAhOm+DHyhiBMlfwFkCQgPdGCNgmWqGk7zYXLpsJpdfLCn4iIqB4wEBA1gaKyIPa7fTCqqJEVAvhlk4wvP1Px1TIT1q9TIMTRC+BEl0DRERl3/smBkTcEMPkBf4X9AUo8wMwHbFi0MPzpfZ/+GmbO8aJd+8pHFZw2E7JcNphNzXtqDcMAERFR/WAgIGpEhiGwt8gHt6/yzcG2b5XxzlwzvvxMRf7+6IvyU0/XcMGwEC4cpiEr28Czs63456sWzP+nBWu+M+Ge6X64iyVs3Sxj62YFP61TcOSQDEURuHViADdNCFQ6KqCaJGQn2bgxFxERUZyRhKjNzOWWyePxwOVywe12w+l0NnV3KE5puoGdh70V9hIot22LjFfnWPDJR2pkJMBqFRhwtoZzLwph8AUa0jMr/nNd8aUJD0yy4VBh7E/027Y38NizXpzWL/bzShLQJsGC9MTmOT2IiOIX37+JGgdHCIgaQUDTsfOQN+aeAL/+IuOlpy1YuuhoELggL4Qrrw3izLO0CtOAjnfWuRre+7QUMx+w4n8rTMjpaKBrDwMnddfRtYeO007XYbHGvq9FlZGTbK92VSAiIiJqvRgIiBqYN6hh5yFvheVEhQDee8uMx6ZbEQqGg8CQS0K49S4/uves3QZcKakCT7zkq919EszIclo5KkBERBTnGAiIGpDHH8Luw94KS4r6fcBf77fhv++Fi33PPj+EiVP96HZy/ezEWxWTIqFdsg2JrBUgIiIiMBAQNZhibxB7i3wVwsCenTIm3WrHlo0KZFngzvv8uHFcELVZNMeqykiwmnC4NFir/QuS7CqyXNYqNwAjIiKi+MJAQNQADpcGsL/YX+H2775WMHmcAyUeCcmpBma/4MWAQTXbh8BmluG0qXDZVFhM4Tn/yXYzdh4uQ0irOhUosoS2STa47BwVICIiomgMBET1rLDEjwJ3oMLtXy0zYdKtdgQDEk49XcMTL3uRmRX7Ql6WAYfZBLtZgc2swG42QYkx19+qKuiSloBdh8vgC8aebuSyqchO4qgAERERxcZAQFSPDrh9OFQSrHD7so9NmDLeDi0k4cJhIfzf816YLRXvr8gS2iSa0cZR8yVAVUVG5zYJ2FPkhcenQZIAu1lBgsWEBKsJdjP/mRMREVHleKVAVA+EENhX7ENRWcUNx5b8V8XUO23QdQnDLgvi0Tk+qMfN3JHl8F4AbRIsMUcCqiPLEjqkOlAW0GBTFa4cRERERDXGQEBUR0II7D4S/nT+eP99T8VDk20wDAmXXhXEI0/4KuwUnGg1oV2yrV6m9Dgs/CdNREREtcOrB6I60A2BXYfLUBaoWBj80b9VPDjJBiEkXHltEA/O8kE5bv+vlAQzsl1WSLVZYoiIiIioHjEQEJ0gTTews5Ji3k8/MuGBu8Nh4Jo/BjDtUT/k4wYAMlwWpCdWsoUwERERUSNhICA6Af6Qjl2HvQhqFcPAF5+acN8ddhiGhCtGBiuEAUkCcpLtXAKUiIiImgUGAqJaKg1o2HW4DEaMVT6/XW7Cn2+zQ9MkXDIiiIf+z1chDHRs40AC5/oTERFRM8GrEqJaqGz3YQBYvULBxJvsCAUlDLkkhL8+HV0zIElA+1Q7wwARERE1K7wyIaqhQo8fBZ6KG44BwI/fK7jjRgcCAQmDh4Twf895K6wmlJNsh9PKaUJERETUvDAQEFXDMAT2Fvng9lXcYwAAftkk4/YbHPB5JQw4W8OTL3mhmqPbtE22sWaAiIiImiUGAqIqBDUDu4/EXkkIAHZul3HLdQ6UuCX06a9hzt/KYDlu4aBMlxUpDnPM+xMRERE1NQYCokqUBTTsOuyFbsQoGACwf6+EW6514MghGT166Xh+bhns9ug2aYkWpCVaGqG3RERERCeGgYAohqKyIPYVxy4eBoCDBeEwkL9fRqeTdLz8Vhmcrug2SXYVmS7uM0BERETNGwMB0XEOuH04VBKs9PjhgxJu+oMDu3cqyM4x8OrbZUhJjU4ODouCdsm2hu4qERERUZ0xEBD9xjAE9hR54fFplbY5cjgcBnZsU5CZbeD1eaXIyIoOA1ZVRodUByRJauguExEREdUZAwERqi8eBoDiovA0oV9/UZCeYeD1eWVo1z46DKgmCR3bOKDIDANERETUMjAQUNzzh3TsOFQGTa+kYACApxi45ToHftmkoE26gdfml6F9p+jwIMtAx1QHVEWO/SBEREREzRCvXCiu1SQMHD4o4aZrE7B5g4LkVAOvvVOGTl0qjiTkpNhhVZUYj0BERETUfHGEgOJWTcLAnp0yxv3Rjj27joaBLt0qhoFMl5W7EBMREVGL1GAjBDt37sTYsWPRqVMn2Gw2dOnSBdOnT0cwGL16y08//YRzzjkHVqsVOTk5mD17doXHWrBgAXr06AGr1YrevXtj8eLFDdVtihM1CQObNsi4/goH9uxS0La9gX8uLEO3kyuGgWSHyr0GiIiIqMVqsECwefNmGIaBV155BT///DOefvppvPzyy7j//vsjbTweD4YOHYoOHTpg7dq1ePzxxzFjxgy8+uqrkTYrVqzAtddei7Fjx2LdunUYMWIERowYgQ0bNjRU16mVC2jVh4FV3yr40zUJOHJIRveeOv61sBQdOlUMAw6LgrZJXF6UiIiIWi5JiMq2Xqp/jz/+OF566SVs374dAPDSSy9h2rRpyM/Ph9lsBgDcd999+OCDD7B582YAwMiRI1FWVoaPPvoo8jgDBw5Enz598PLLL9foeT0eD1wuF9xuN5xOZz2/KmpJgpqB7YdKEdIq/7VfvtSEyePsCAUlnJGr4ZnXy5AY49fGbJLRJc0BE4uIiYgaBN+/iRpHo17JuN1upKSkRL5fuXIlBg8eHAkDAJCXl4ctW7agqKgo0mbIkCFRj5OXl4eVK1c2Tqep1dB0AzsPl1UZBr741IRJt4bDwIUXh/DiP2OHAVkGOqTaGQaIiIioxWu0q5lt27bhueeew6233hq5LT8/HxkZGVHtyr/Pz8+vsk358VgCgQA8Hk/UF8U3wxDYediLQKjyfQa++CQ8MqCFJAy7LIjHX/TCYq3YTpKADqkOrihERERErUKtA8F9990HSZKq/Cqf7lNu3759GDZsGK655hrcfPPN9db5ysyaNQsulyvylZOT0+DPSc2XEAI7D5fBF9QrbfPFJyZMvu1oGJj5rA+mStbgyk6yIcHCBbqIiIiodaj1Vc3kyZMxZsyYKtt07tw58v/79+/H+eefj7POOiuqWBgAMjMzUVBQEHVb+feZmZlVtik/HsvUqVMxadKkyPcej4ehIE4JIbDniA9lgSrCwKc1DwNtEs1IcZhjHyQiIiJqgWodCNLS0pCWllajtvv27cP555+Pfv364Y033oAsRw9I5ObmYtq0aQiFQlDV8BruS5cuRffu3ZGcnBxps2zZMkycODFyv6VLlyI3N7fS57VYLLBYuAwkAXuLfHD7QpUeX79OwZTbaxYGnDYTslxcUYiIiIhalwarIdi3bx/OO+88tG/fHk888QQOHjyI/Pz8qLn/1113HcxmM8aOHYuff/4Z8+fPx5w5c6I+3b/rrruwZMkSPPnkk9i8eTNmzJiBNWvWYMKECQ3VdWol9hzxothbeRgoOCBh4k12BAMSBl8YqjIMJFhNyEm2N1BPiYiIiJpOg02EXrp0KbZt24Zt27ahXbt2UcfKVzp1uVz49NNPMX78ePTr1w9t2rTBQw89hFtuuSXS9qyzzsLbb7+NBx54APfffz+6du2KDz74AKecckpDdZ1agb1FVYcBnw+YeJMdBwtldOmm47HnvFWGgQ4pdsiy1EC9JSIiImo6jboPQVPhOsbxZV+xD0dKg5UeFwK4d7wNSz40IynZwNsflqJdh9j/DBgGiIiaDt+/iRoHF1GnVuWAu+owAACvPWvBkg/NMJkEnnrFyzBAREREcY2BgFoNty+EQyVVh4Gli014/onw5gL3P+pD/9zYqw8xDBAREVG8YCCgViGoGdhX5KuyzYYfFEy7K1wYfN2fArj6utg1BlZVRnuGASIiIooTDATU4gkhsKfIC92ovBwmf7+EO8fa4fdLOPv8EP78oD9mO5MioUOqAwrDABEREcUJBgJq8QpLAvBWsfGYtwy440YHDhXKOKm7jtkvxF5RSJKAjqkOmE38Z0FERETxg1c+1KKVBjQUegKVHtd14J4JdmzZqCA1zcDzc8uQkFixnSQB7VPtsJmVBuwtERERUfPDQEAtlqYb2HPEW2Wbp/5qxVefqbBYBOb8zYvsdrGnFWW5rHBa1YboJhEREVGzxkBALVZhSQCaXnndwII3zfjX6xYAwF+f9uHUvrGnFSXZVaQmWBqkj0RERETNHQMBtUj+kI4jZZUvMfrd1wpmPhBeXnTCn/3Iuyz2ikKqSUJ2kq1B+khERETUEjAQUItU4PGjsj22d2yTMXmcA7ou4dIrg7j5ztg1BpIE5CTbuaIQERERxTUGAmpxSgMaPD4t5rHiIgkTxthR4pHQ9wwNM2b7IFVyvZ+WaIHDEmO5ISIiIqI4wkBALU6+O/YGZKEgcPfNduzZpSA7x8DTr3lhrqQ0wGZWkJ7IugEiIiIiBgJqUYrKgvAFjZjH5jxmxdpVJjgSBJ5/owwpqbHnFEkSkJNig1TZ0AERERFRHGEgoBbDMATyPbF3GF6/TsGbfzMDAGY968VJ3WOHBgBom2SDxcT9BoiIiIgABgJqQQ6Wxl5mNBQCZtxjg2GEi4jPuyh2fQEApCSYkewwN2Q3iYiIiFoUBgJqETTdwKHS2KsFzX3Zgq2bFSSnGJgyPfYIAhCuG8h2WRuqi0REREQtEgMBtQiHSoMwYswC2rldxitzwsXB98zwIzkldt2ASZHQIdXOugEiIiKi4zAQULOn6QYOl1UcHTAM4JF7bQgGJAw6L4RLRsTefEySgPYpdqgKf92JiIiIjscrJGr2Khsd+Pc8FWu+M8FqE3hgZuX7DWQ4rdxvgIiIiKgSDATUrFVWO1B0RMLTj9oAAHfc40fbnNhThZw2E9K43wARERFRpRgIqFk7VBqEiHGt/9bfzCjxSOjeU8d1NwZj3lc1SWiXbG/gHhIRERG1bAwE1GxVNjrgcQNvvxH+1P/WiX4oMbYUKK8bUGQWERMRERFVhYGAmq3KRgfm/cOC0hIJXbrpuCAv9p4D6U4L7GbWDRARERFVh4GAmqXKRge8ZcCbr4c3Frv5jgDkGL/BCVYT0hO53wARERFRTTAQULOj6QZ2Hi6LOTrw7r/MKC6S0aGTjrzLKi4zalIk5CTbGqGXRERERK0D51RQs6LpBnYcKoM/VHGdUb8P+Mer4dqBseMDMWsHspNsMHG/ASIiIqIa45UTNRtVhQEAWDjfjMMHZWS1NTD8yoqjAw6LApdNbehuEhEREbUqDATULFQXBkJB4O8vhkcH/nR7AGqM6/7sJE4VIiIiIqotThmiJucP6dh9xItAJWEAAP77voqCAzLS0g2M+H3FfQeSHSqsaow5RERERERUJQYCalJFZUHsK/bFLCAuFwoBrz0XXjVozLgALMctICTLQIaTqwoRERERnQgGAmoShiGwr9iHYm/FWoDjffi+iv17ZKSmGbj6jxVHB9ISLVBZSExERER0QhgIqNEFNB27D3srrRc4VigIvPps+NP/P90WgO24MgHVJCEtwdIQ3SQiIiKKC/xYlRrd3iJfjcIAEK4dqGp0IMtpgyRJ9d1FIiIiorjBQECNqtgbhDeg16htKHi0duBPt1ccHbCZZbjsXGaUiIiIqC4YCKjRGIbAAbe/xu3/8154dKBNuoFrRlUcHUh1cKoQERERUV0xEFCjKSwJQNOrWE7oGKEg8PpvowM33haA9bjRAUWWuAkZERERUT1gIKBGEdB0HCoN1Lj9fxao2L+38tGBFIcZsszaASIiIqK6YiCgRnGg2F/lXgPHCgaiaweOHx2QpHAgICIiIqK6YyCgBufxh1Di12rc/vFHrDiwLzw6cPV1FUcHEq0mmE381SUiIiKqD7yqogalGwIHimteSPzf91TM/2e4WHjGbF+F0QEASOW+A0RERET1hoGAGtT+Yh+CWs32HNi0QcZf7gsngHF3+zH4woqjClZVRoKF++kRERER1RcGAmowh0sDKPaGatTWXSRh0q0OBAISzrkghHETYxcgc3SAiIiIqH4xEFCD8AX1Gu85oOvAfXfasG+3jHbtdcya44Uc4zdTloEkLjVKREREVK8YCKje6YbA7iPeGq0qJATwzCwrvl2uwmoVePo1L5xJsdtyqVEiIiKi+sfJ2FTv9hXVrG5A14FZD1rx7r/C04AefMyH7j1j30+SgDacLkRERERU7xgIqF4VlQXh9lVfNxAKAtMm2rDkQzMkSeD+v/px2VWV3y/FYYaqcECLiIiIqL4xEFC9OliD3Yi9ZcDdN9ux8msVJlVg1hwf8i6rPAxIEpCWyNEBIiIioobAQED1psQfQiBU9VSh0hLglusc2PCDCTa7wNOvenHWuVVvWsbRASIiIqKGw0BA9eZwacVdhY/3yhwrNvxggivJwAv/9OLUvnqV7Tk6QERERNSw+LEr1Qt/SEeJv+pP+vftkfD2G2YAwMxnfdWGAYCjA0REREQNjVdaVC+OlFU/OvD841aEghIGnK3h7POqDg8ARweIiIiIGgMDAdWZbohqA8HG9TIWLQyPDtx9vw9SDbYT4OgAERERUcPj1RbV2ZGyYJWbkAkBPPWoDQAw/Iogevaufo8Cjg4QERERNQ4GAqqz6kYHvl1uwupvTVDNAhOm+Gv0mOmJFo4OEBERETUCXnFRnbh9oSp3JdZ14OmZVgDAdTcG0TaniqGE31hVmaMDRERERI2EgYDq5HA1G5F9+J6KrZsVOF0Gbp5Qs9GBtsk2SDUpMiAiIiKiOmMgoBMW1AyUBSpfOrTggIRnHguPDtx8RwDOpOofMzXBDLuZ22MQERERNRYGAjphxb7KawdCQWDK7XYcOSSjaw8dfxhd/bKkqklCptNan10kIiIiomowENAJ8/hClR578q9W/LDGhESnwNOvemGpwXV+dpINssypQkRERESNqVECQSAQQJ8+fSBJEn744YeoYz/99BPOOeccWK1W5OTkYPbs2RXuv2DBAvTo0QNWqxW9e/fG4sWLG6PbVIWApsMXjF1MvGihirffCBcFP/qMF+07Vb/MaJJdhdOq1msfiYiIiKh6jRII7rnnHmRnZ1e43ePxYOjQoejQoQPWrl2Lxx9/HDNmzMCrr74aabNixQpce+21GDt2LNatW4cRI0ZgxIgR2LBhQ2N0nSrhrmR04JdNMh6+J7znwC13+nHeRdXvSGxRZWS5OFWIiIiIqClIQlS1pVTdffzxx5g0aRLef/999OrVC+vWrUOfPn0AAC+99BKmTZuG/Px8mM3hXWzvu+8+fPDBB9i8eTMAYOTIkSgrK8NHH30UecyBAweiT58+ePnll2vUB4/HA5fLBbfbDafTWb8vME5tKyypMEJQ4gGuHZ6A3TsVnDU4hBf+6YWiVP04qklC5zYJMJs4e42IiKLx/ZuocTToVVhBQQFuvvlm/Otf/4Ldbq9wfOXKlRg8eHAkDABAXl4etmzZgqKiokibIUOGRN0vLy8PK1eurPR5A4EAPB5P1BfVn8qmC8192YLdOxVktTUw6zlftWFAkSV0THUwDBARERE1oQa7EhNCYMyYMRg3bhz69+8fs01+fj4yMjKibiv/Pj8/v8o25cdjmTVrFlwuV+QrJyenLi+FjhNrulAoCLz/TjjYTX7Qh+SUqgeeZBno1MYBq1pNaiAiIiKiBlXrQHDfffdBkqQqvzZv3oznnnsOJSUlmDp1akP0u0pTp06F2+2OfO3Zs6fR+9CaxVpd6LOPVRw5JCM9w8D5Q6uuG5AkoEOqAzYzwwARERFRU6v1DlCTJ0/GmDFjqmzTuXNnfP7551i5ciUsFkvUsf79+2PUqFH4xz/+gczMTBQUFEQdL/8+MzMz8t9YbcqPx2KxWCo8L9WPyqYLzf9neHTgyuuCUKtZLCg90YIECzcfIyIiImoOan1VlpaWhrS0tGrbPfvss/jrX/8a+X7//v3Iy8vD/PnzMWDAAABAbm4upk2bhlAoBPW3q8ilS5eie/fuSE5OjrRZtmwZJk6cGHmspUuXIjc3t7Zdp3oQa7rQ1s0yvl9tgqIIXHVt1RuQKbKENgkMa0RERETNRYN9TNu+ffuo7xMSEgAAXbp0Qbt27QAA1113HR5++GGMHTsW9957LzZs2IA5c+bg6aefjtzvrrvuwrnnnosnn3wSw4cPx7x587BmzZqopUmp8cSaLvTuv8KjA+fnacjIqrp2IC3Rws3HiIiIiJqRJl3exeVy4dNPP8WOHTvQr18/TJ48GQ899BBuueWWSJuzzjoLb7/9Nl599VWcdtppeO+99/DBBx/glFNOacKex6dY04XKSoEP3w8Hgt9fH6jy/iZFQqrDXGUbIiIiImpcDb4PQXPAdYzrx8GSAPLd/qjb3v2XGX+934aOXXT854tSSFV8+J+VZOV0ISIiqjG+fxM1Di4ATzV2fP2AEEeLiX9/fbDKMGBSJKTYOTpARERE1NwwEFCNhHQDvqAeddu6/ynYulmB1Srwu6urLiZOZ+0AERERUbPEQEA1UuKvuLdAeTHxxSNCcLoqv69qkpDC2gEiIiKiZomBgGrk+NWFSkuApYvDS8WOrKaYOD3RCqmq+URERERE1GQYCKhahiFQGogeIVjxpQmhoIQOnXX0PLXiRmXlEqwmJNur2amMiIiIiJoMAwFVqySg4fi1qJYvDV/kn3dRxalE5cwmGe1T7BwdICIiImrGGAioWsdPF9I04OvPw3vanTuk4kZlACDLQIdUOxQWEhMRERE1awwEVCUhRIWC4h/XKnAXy3C6DPTpr8e8X06KHVZVaYwuEhEREVEdMBBQlbxBHboRPV+ofLrQ4As1mEwV75PhtMBpZd0AERERUUvAQEBV8vgrTgn68rPy6UIV6wcSrSakO60N3i8iIiIiqh8MBFQljy/6on/XDhk7f1VgUgXOOrdiWEhLtDRW14iIiIioHjAQUKX8IR1BLXpJ0S+XhkcH+g/UkOiMbm9RZTgsMeYQEREREVGzxUBAlYo1Xai8fiDWdKFkO3cjJiIiImppGAioUsdPF/IUA+v+F1456PjlRiUJ3ICMiIiIqAViIKCYNN2ALxi9pOjXX6jQdQknddfRrn30ykMumwqTwl8nIiIiopaGV3AUU1mg4v4C5fUDsTYjS3ZwuhARERFRS8RAQDGVBaOnC4VCwLdfhqcEnTc0+pjZJCOBxcRERERELRIDAcVUFoi+6P9+tYISj4SUNgZ694kePUh2sHaAiIiIqKViIKAKdEPAHzp+udHfdie+QIN8zG9NuJiY04WIiIiIWioGAqrg+OlCAPDN8vCUoHMujK4fSLSaoLKYmIiIiKjF4pUcVXD8dKG9u6Xw7sQmgYFnRx9jMTERERFRy8ZAQBUcv8LQN1+Epwv16a9H7U6syBKcVtYPEBEREbVkDAQUxTAE/KHjA0F4utDZ50dPF+LKQkREREQtHwMBRSkLahDH7DkW8AOrvy0PBNHThRKtDARERERELR0DAUXxHrc78dpVJvj9EtIzDXTtEb3yUAIDAREREVGLx0BAUUqPKyguny406DwNknT0dqsqc3UhIiIiolaAV3QUIYSA77gRgvLlRivUD3B0gIiIiKhVYCCgCG9Qj6ofqGq5URYUExEREbUODAQUcfz+A5UtNypJgMPMQEBERETUGjAQUETZ8dOFKllu1GExQZYlEBEREVHLx0BAAML1A8eOEFS13CinCxERERG1HgwEBADwhaLrB6pabpT7DxARERG1HgwEBAAoC8SeLnT8cqOqSYJVVRqza0RERETUgBgICADgDR5XUFzJcqMsJiYiIiJqXRgICEB4ylC5/XvDy40qSsXlRp1WtbG7RkREREQNiIGAoOkGQtrRAoI134VHAXqdFr3cKAA4LJwuRERERNSaMBBQ1OgAAKz9LRD0Hxg9OmAzKzAp/JUhIiIiak14dUfwHbf/wNpV4VGAfgOib+fqQkREREStDwMBRY0QFOZL2L1TgSwL9OkfPULg4P4DRERERK0OAwFFBYK1q8IX/d17GVH1A5IEOMysHyAiIiJqbRgI4lzFguLwRX//ARV3J5aO3ZCAiIiIiFoFBoI4V6Gg+LcRgn4DOF2IiIiIKB4wEMS5YwPB4UMStm8NjxCczoJiIiIiorjAQBDnjl1h6PvV4TBwUncdSclHpxGZFAlWlfUDRERERK0RA0Gci1VQfPz+AwmcLkRERETUajEQxLHjC4or25CM9QNERERErRcDQRw7dnTAUwz8sin863D6mdH1AxwhICIiImq9GAji2LGB4Pv/mSCEhI5ddLRJPzpqYDbJMJv4a0JERETUWvFKL475g0bk/9d8V77c6HGjA1xdiIiIiKhVYyCIY97Q0VqB71f9tiEZC4qJiIiI4goDQZw6tqC4rBTYtCEcCI7dkEySGAiIiIiIWjsGgjh1bP3AD2tM0HUJbdsbyMw+Wj9gVRUostQU3SMiIiKiRsJAEKeODQRrvvttdOBMThciIiIiijcMBHHq2ILin9aFL/xPH3BcIGBBMREREVGrx0AQp8oLioUANv8cHiHo2fvoqIEkAQ6z0iR9IyIiIqLGw0AQh44tKN63R0KJW4JqFujS9eiogd2sQJJYP0BERETU2nFOSB3tPuxFWVCrvmEzIo7WDUdWFzqpuwHVfPR21g8QERERxQde9dWRLgQ0XVTfsJna/FsgOPmU6A3JHAwERERERHGBU4biXPkIQY9e0fUDdtYPEBEREcWFBg0EixYtwoABA2Cz2ZCcnIwRI0ZEHd+9ezeGDx8Ou92O9PR0TJkyBZoWPf1m+fLlOP3002GxWHDSSSdh7ty5DdnluFMeCE4+pqCY9QNERERE8aPB5oW8//77uPnmmzFz5kxccMEF0DQNGzZsiBzXdR3Dhw9HZmYmVqxYgQMHDuCGG26AqqqYOXMmAGDHjh0YPnw4xo0bh7feegvLli3DTTfdhKysLOTl5TVU1+PGwQIJhw/KkGWBbicfDQScLkREREQUPyQhRL1PgNc0DR07dsTDDz+MsWPHxmzz8ccf49JLL8X+/fuRkZEBAHj55Zdx77334uDBgzCbzbj33nuxaNGiqCDxhz/8AcXFxViyZEmN++PxeOByueB2u+F0Ouv24o6z41AZSv0tq6i43FfLTJgwxoEu3XQsXFYaub1TmoNFxURE1OQa8v2biI5qkClD33//Pfbt2wdZltG3b19kZWXh4osvjrqwX7lyJXr37h0JAwCQl5cHj8eDn3/+OdJmyJAhUY+dl5eHlStXVvn8gUAAHo8n6osqilVQLEmAXWX9ABEREVG8aJBAsH37dgDAjBkz8MADD+Cjjz5CcnIyzjvvPBw5cgQAkJ+fHxUGAES+z8/Pr7KNx+OBz+er9PlnzZoFl8sV+crJyam319aaxCootpkVyDLrB4iIiIjiRa0CwX333QdJkqr82rx5MwwjvMHVtGnTcNVVV6Ffv3544403IEkSFixY0CAv5FhTp06F2+2OfO3Zs6fBn7Ml2vRzxYJih5lThYiIiIjiSa2u/iZPnowxY8ZU2aZz5844cOAAAKBnz56R2y0WCzp37ozdu3cDADIzM7F69eqo+xYUFESOlf+3/LZj2zidTthstkr7YLFYYLFYavai4pS7SML+PeE82L3nsQXFnC5EREREFE9qFQjS0tKQlpZWbbt+/frBYrFgy5YtOPvsswEAoVAIO3fuRIcOHQAAubm5ePTRR1FYWIj09HQAwNKlS+F0OiNBIjc3F4sXL4567KVLlyI3N7c23aYYNm8Mh4F27XU4XeHbJIkjBERERETxpkFqCJxOJ8aNG4fp06fj008/xZYtW3DbbbcBAK655hoAwNChQ9GzZ09cf/31+PHHH/HJJ5/ggQcewPjx4yOf7o8bNw7bt2/HPffcg82bN+PFF1/Eu+++i7vvvrshuh1XNq3/rX7gFCNym1Vl/QARERFRvGmwj4Mff/xxmEwmXH/99fD5fBgwYAA+//xzJCcnAwAURcFHH32E2267Dbm5uXA4HBg9ejQeeeSRyGN06tQJixYtwt133405c+agXbt2eP3117kHQT3YFGOFIS41SkRERBR/GmQfguaG+xBUdPn5CdixTcEL/yzDOeeH+9+hjR1Oq9rEPSMiIgrjPgREjaNBpgxR8+YtA3b+Gv7R9/xthID1A0RERETxiYEgDv2ySYEQEtIzDKSmhQeIrKoMhfUDRERERHGHgSAORTYkO+XY5UY5OkBEREQUjxgI4tDmGAXFdk4XIiIiIopLDARxKDJC0OtoILCq/FUgIiIiikf8WLgO1q4FtuyR4Qu2nN19DQPYtiV88X9y73AgkGXAYmo5r4GIiIiI6g8DQR3ccQewcqWtqbtxQpwuA1ltywuKGQaIiIiI4hUDQR107gwcLjKgGy1rKwdJAq4eFYT026JCNgYCIiIiorjFQFAHb74J7Djka5Ebkx2LgYCIiIgofrGSlDhliIiIiCiOMRDEOUniCkNERERE8YxXgnHOYpIhSdyhmIiIiCheMRDEOU4XIiIiIopvDARxzmZmICAiIiKKZwwEcY4jBERERETxjYEgznHJUSIiIqL4xkAQx1STBEVmQTERERFRPGMgiGMcHSAiIiIiBoI4xkBARERERAwEcczCQEBEREQU9xgI4hhHCIiIiIiIgSBOyTJgNvHHT0RERBTveEUYpzg6QEREREQAA0Hc4oZkRERERAQwEMQtjhAQEREREcBAELdsZgYCIiIiImIgiEuSBFhYUExEREREAExN3YGWLtmuwmFpWZ+2K5IESZKauhtERERE1AwwENRRkt3c1F0gIiIiIjphnDdCRERERBTHGAiIiIiIiOIYAwERERERURxjICAiIiIiimMMBEREREREcYyBgIiIiIgojjEQEBERERHFMQYCIiIiIqI4xkBARERERBTHGAiIiIiIiOIYAwERERERURxjICAiIiIiimMMBEREREREcYyBgIiIiIgojpmaugONQQgBAPB4PE3cEyIiIqqp8vft8vdxImoYcREISkpKAAA5OTlN3BMiIiKqrZKSErhcrqbuBlGrJYk4iN2GYWD//v1ITEyEJEn19rgejwc5OTnYs2cPnE5nvT0uVcRz3Xh4rhsXz3fj4bluPPV1roUQKCkpQXZ2NmSZs5yJGkpcjBDIsox27do12OM7nU6+uTQSnuvGw3PduHi+Gw/PdeOpj3PNkQGihse4TUREREQUxxgIiIiIiIjiGANBHVgsFkyfPh0Wi6Wpu9Lq8Vw3Hp7rxsXz3Xh4rhsPzzVRyxIXRcVERERERBQbRwiIiIiIiOIYAwERERERURxjICAiIiIiimMMBEREREREcYyBoA5eeOEFdOzYEVarFQMGDMDq1aubukvNxqxZs3DGGWcgMTER6enpGDFiBLZs2RLVxu/3Y/z48UhNTUVCQgKuuuoqFBQURLXZvXs3hg8fDrvdjvT0dEyZMgWapkW1Wb58OU4//XRYLBacdNJJmDt3boX+xNPP6rHHHoMkSZg4cWLkNp7r+rVv3z788Y9/RGpqKmw2G3r37o01a9ZEjgsh8NBDDyErKws2mw1DhgzB1q1box7jyJEjGDVqFJxOJ5KSkjB27FiUlpZGtfnpp59wzjnnwGq1IicnB7Nnz67QlwULFqBHjx6wWq3o3bs3Fi9e3DAvugnouo4HH3wQnTp1gs1mQ5cuXfCXv/wFx66FwXN9Yr766itcdtllyM7OhiRJ+OCDD6KON6fzWpO+EFEdCToh8+bNE2azWfz9738XP//8s7j55ptFUlKSKCgoaOquNQt5eXnijTfeEBs2bBA//PCDuOSSS0T79u1FaWlppM24ceNETk6OWLZsmVizZo0YOHCgOOussyLHNU0Tp5xyihgyZIhYt26dWLx4sWjTpo2YOnVqpM327duF3W4XkyZNEhs3bhTPPfecUBRFLFmyJNImnn5Wq1evFh07dhSnnnqquOuuuyK381zXnyNHjogOHTqIMWPGiFWrVont27eLTz75RGzbti3S5rHHHhMul0t88MEH4scffxS/+93vRKdOnYTP54u0GTZsmDjttNPEd999J77++mtx0kkniWuvvTZy3O12i4yMDDFq1CixYcMG8c477wibzSZeeeWVSJtvv/1WKIoiZs+eLTZu3CgeeOABoaqqWL9+feOcjAb26KOPitTUVPHRRx+JHTt2iAULFoiEhAQxZ86cSBue6xOzePFiMW3aNPHvf/9bABALFy6MOt6czmtN+kJEdcNAcILOPPNMMX78+Mj3uq6L7OxsMWvWrCbsVfNVWFgoAIgvv/xSCCFEcXGxUFVVLFiwINJm06ZNAoBYuXKlECL8hiXLssjPz4+0eemll4TT6RSBQEAIIcQ999wjevXqFfVcI0eOFHl5eZHv4+VnVVJSIrp27SqWLl0qzj333Egg4LmuX/fee684++yzKz1uGIbIzMwUjz/+eOS24uJiYbFYxDvvvCOEEGLjxo0CgPjf//4XafPxxx8LSZLEvn37hBBCvPjiiyI5OTly/sufu3v37pHvf//734vhw4dHPf+AAQPErbfeWrcX2UwMHz5c/OlPf4q67corrxSjRo0SQvBc15fjA0FzOq816QsR1R2nDJ2AYDCItWvXYsiQIZHbZFnGkCFDsHLlyibsWfPldrsBACkpKQCAtWvXIhQKRZ3DHj16oH379pFzuHLlSvTu3RsZGRmRNnl5efB4PPj5558jbY59jPI25Y8RTz+r8ePHY/jw4RXOB891/frvf/+L/v3745prrkF6ejr69u2L1157LXJ8x44dyM/PjzoPLpcLAwYMiDrfSUlJ6N+/f6TNkCFDIMsyVq1aFWkzePBgmM3mSJu8vDxs2bIFRUVFkTZV/UxaurPOOgvLli3DL7/8AgD48ccf8c033+Diiy8GwHPdUJrTea1JX4io7hgITsChQ4eg63rUxRMAZGRkID8/v4l61XwZhoGJEydi0KBBOOWUUwAA+fn5MJvNSEpKimp77DnMz8+PeY7Lj1XVxuPxwOfzxc3Pat68efj+++8xa9asCsd4ruvX9u3b8dJLL6Fr16745JNPcNttt+HOO+/EP/7xDwBHz1dV5yE/Px/p6elRx00mE1JSUurlZ9Jazvd9992HP/zhD+jRowdUVUXfvn0xceJEjBo1CgDPdUNpTue1Jn0horozNXUHqPUbP348NmzYgG+++aapu9Iq7dmzB3fddReWLl0Kq9Xa1N1p9QzDQP/+/TFz5kwAQN++fbFhwwa8/PLLGD16dBP3rnV599138dZbb+Htt99Gr1698MMPP2DixInIzs7muSYiqkccITgBbdq0gaIoFVZpKSgoQGZmZhP1qnmaMGECPvroI3zxxRdo165d5PbMzEwEg0EUFxdHtT/2HGZmZsY8x+XHqmrjdDphs9ni4me1du1aFBYW4vTTT4fJZILJZMKXX36JZ599FiaTCRkZGTzX9SgrKws9e/aMuu3kk0/G7t27ARw9X1Wdh8zMTBQWFkYd1zQNR44cqZefSWs531OmTImMEvTu3RvXX3897r777shIGM91w2hO57UmfSGiumMgOAFmsxn9+vXDsmXLIrcZhoFly5YhNze3CXvWfAghMGHCBCxcuBCff/45OnXqFHW8X79+UFU16hxu2bIFu3fvjpzD3NxcrF+/PupNZ+nSpXA6nZELstzc3KjHKG9T/hjx8LO68MILsX79evzwww+Rr/79+2PUqFGR/+e5rj+DBg2qsITuL7/8gg4dOgAAOnXqhMzMzKjz4PF4sGrVqqjzXVxcjLVr10bafP755zAMAwMGDIi0+eqrrxAKhSJtli5diu7duyM5OTnSpqqfSUvn9Xohy9FvU4qiwDAMADzXDaU5ndea9IWI6kFTVzW3VPPmzRMWi0XMnTtXbNy4Udxyyy0iKSkpapWWeHbbbbcJl8slli9fLg4cOBD58nq9kTbjxo0T7du3F59//rlYs2aNyM3NFbm5uZHj5UthDh06VPzwww9iyZIlIi0tLeZSmFOmTBGbNm0SL7zwQsylMOPtZ3XsKkNC8FzXp9WrVwuTySQeffRRsXXrVvHWW28Ju90u3nzzzUibxx57TCQlJYn//Oc/4qeffhKXX355zCUb+/btK1atWiW++eYb0bVr16glG4uLi0VGRoa4/vrrxYYNG8S8efOE3W6vsGSjyWQSTzzxhNi0aZOYPn16i14K83ijR48Wbdu2jSw7+u9//1u0adNG3HPPPZE2PNcnpqSkRKxbt06sW7dOABBPPfWUWLdundi1a5cQonmd15r0hYjqhoGgDp577jnRvn17YTabxZlnnim+++67pu5SswEg5tcbb7wRaePz+cTtt98ukpOThd1uF1dccYU4cOBA1OPs3LlTXHzxxcJms4k2bdqIyZMni1AoFNXmiy++EH369BFms1l07tw56jnKxdvP6vhAwHNdvz788ENxyimnCIvFInr06CFeffXVqOOGYYgHH3xQZGRkCIvFIi688EKxZcuWqDaHDx8W1157rUhISBBOp1PceOONoqSkJKrNjz/+KM4++2xhsVhE27ZtxWOPPVahL++++67o1q2bMJvNolevXmLRokX1/4KbiMfjEXfddZdo3769sFqtonPnzmLatGlRy1jyXJ+YL774Iubf6NGjRwshmtd5rUlfiKhuJCGO2fKRiIiIiIjiCmsIiIiIiIjiGAMBEREREVEcYyAgIiIiIopjDARERERERHGMgYCIiIiIKI4xEBARERERxTEGAiIiIiKiOMZAQEREREQUxxgIiIiIiIjiGAMBEREREVEcYyAgIiIiIopjDARERERERHHs/wGWqzt8/k0S5gAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we add to the epsilon-greedy strategy epsilon annealing. We change linearly epsilon from 1.0 to the value final_epsilon during first anneal_steps steps and then it remains on the final_epsilon level.\n",
        "Such an approach aims to increase the exploration level at the beginning of the training, when the Q-value estimate is poor and thus choosing greedily according to Q is not improving the performance."
      ],
      "metadata": {
        "id": "1iKU0YllgL5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EpsilonGreedyWithAnnealingDQN(EpsilonGreedyDQN):\n",
        "  def __init__(self, args):\n",
        "    self.start_epsilon = 1.0\n",
        "    super(EpsilonGreedyWithAnnealingDQN, self).__init__(args)\n",
        "    self.epsilon = self.start_epsilon\n",
        "    self.final_epsilon = 0.1 # investigate sensitivity\n",
        "    self.annealing = True\n",
        "    self.anneal_steps = 30000\n",
        "\n",
        "  def anneal(self, step):\n",
        "    # TODO\n",
        "    ####################################\n",
        "    ####################################\n",
        "\n",
        "  def reset(self):\n",
        "    super(EpsilonGreedyWithAnnealingDQN, self).reset()\n",
        "    self.epsilon = self.start_epsilon"
      ],
      "metadata": {
        "id": "4VRBq0D-_Ug7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon_greedy_with_annealing_dqn = EpsilonGreedyWithAnnealingDQN(args)\n",
        "result_means_epsilon_greedy_with_annealing_dqn, result_stds_epsilon_greedy_with_annealing_dqn = train_dqn(epsilon_greedy_with_annealing_dqn)\n",
        "plot_results(result_means_epsilon_greedy_with_annealing_dqn, result_stds_epsilon_greedy_with_annealing_dqn)"
      ],
      "metadata": {
        "id": "ZY1C0OjtA8fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternative approach to the epsilon-greedy strategy is to use so-called boltzmann exploration strategy.\n",
        "The idea behind this approach is to perform softmax on the Q-values coming from the main critic and then sample from the obtained distribution.\n",
        "In this approach we use softmax with a temperature, i.e. before applying softmax, we scale all the Q-values by the temperature coefficient (in the literature we usually divide by the temperature, but this is equivallent to scaling by the inverse of the temperature). Large scaling values make the distribution close to the greedy choice, while low scaling values make the distribution close to the uniform one."
      ],
      "metadata": {
        "id": "2VJ4wifPiE55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BoltzmannDQN(DQN):\n",
        "  def __init__(self, args):\n",
        "    super(BoltzmannDQN, self).__init__(args)\n",
        "    self.temperature = 1.0 # investigate sensitivity\n",
        "\n",
        "  def explore(self, states):\n",
        "    action = None\n",
        "    with torch.no_grad():\n",
        "      # TODO\n",
        "      ####################################\n",
        "      ####################################\n",
        "\n",
        "    return action"
      ],
      "metadata": {
        "id": "_0wB5TcYRGAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boltzmann_dqn = BoltzmannDQN(args)\n",
        "result_means_boltzmann_dqn, result_stds_boltzmann_dqn = train_dqn(boltzmann_dqn)\n",
        "plot_results(result_means_boltzmann_dqn, result_stds_boltzmann_dqn)"
      ],
      "metadata": {
        "id": "0wcy8QOyijxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the compromises between epsilon-greedy and boltzmann exploration strategy is so-calles max-boltzmann strategy. In this strategy with probability 1-epsilon we choose action greedily, but with probability epsilon we perform the boltzmann choice instead of the uniform random choice."
      ],
      "metadata": {
        "id": "oLyezLVijx3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxBoltzmannDQN(EpsilonGreedyWithAnnealingDQN):\n",
        "  def __init__(self, args):\n",
        "    super(MaxBoltzmannDQN, self).__init__(args)\n",
        "    self.temperature = 0.1 # investigate sensitivity\n",
        "\n",
        "  def explore(self, states):\n",
        "    action = None\n",
        "    with torch.no_grad():\n",
        "      # TODO\n",
        "      ####################################\n",
        "      ####################################\n",
        "    return action"
      ],
      "metadata": {
        "id": "5uaDREL-hIkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_boltzmann_dqn = MaxBoltzmannDQN(args)\n",
        "result_means_max_boltzmann_dqn, result_stds_max_boltzmann_dqn = train_dqn(max_boltzmann_dqn)\n",
        "plot_results(result_means_max_boltzmann_dqn, result_stds_max_boltzmann_dqn)"
      ],
      "metadata": {
        "id": "QjR01lGcw1jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly to adjusting the value of epsilon in epsilon-greedy strategy, we can adjust the temperature in the max-boltzmann and boltzmann strategies: we start we the value start_temperature and linearly increase the value to the final_temperature during temperature_anneal_steps, then the temperature is on the constant level.\n"
      ],
      "metadata": {
        "id": "rq_pxa8KkbIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxBoltzmannWithTemperatureAnnealingDQN(MaxBoltzmannDQN):\n",
        "  def __init__(self, args):\n",
        "    self.start_temparature = 0.025 # investigate sensitivity\n",
        "    super(MaxBoltzmannWithTemperatureAnnealingDQN, self).__init__(args)\n",
        "    self.temperature = self.start_temparature\n",
        "    self.final_temperature = 0.3 # investigate sensitivity\n",
        "    self.temperature_anneal_steps = 30000\n",
        "    self.annealing = True\n",
        "\n",
        "  def anneal(self, step):\n",
        "    super(MaxBoltzmannWithTemperatureAnnealingDQN, self).anneal(step)\n",
        "    # TODO\n",
        "    ####################################\n",
        "    ####################################\n",
        "\n",
        "  def reset(self):\n",
        "    super(MaxBoltzmannWithTemperatureAnnealingDQN, self).reset()\n",
        "    self.temperature = self.start_temparature"
      ],
      "metadata": {
        "id": "3naKqfLVDwP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_boltzmann_temp_anneal_dqn = MaxBoltzmannWithTemperatureAnnealingDQN(args)\n",
        "result_means_max_boltzmann_temp_anneal_dqn, result_stds_max_boltzmann_temp_anneal_dqn = train_dqn(max_boltzmann_temp_anneal_dqn)\n",
        "plot_results(result_means_max_boltzmann_temp_anneal_dqn, result_stds_max_boltzmann_temp_anneal_dqn)"
      ],
      "metadata": {
        "id": "HidAoBNCFV6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BoltzmannWithTemperatureAnnealingDQN(BoltzmannDQN):\n",
        "  def __init__(self, args):\n",
        "    self.start_temparature = 0.25 # investigate sensitivity\n",
        "    super(BoltzmannWithTemperatureAnnealingDQN, self).__init__(args)\n",
        "    self.temperature = self.start_temparature\n",
        "    self.final_temperature = 3.0 # investigate sensitivity\n",
        "    self.temperature_anneal_steps = 30000\n",
        "    self.annealing = True\n",
        "\n",
        "  def anneal(self, step):\n",
        "    # TODO\n",
        "    ####################################\n",
        "    ####################################\n",
        "\n",
        "  def reset(self):\n",
        "    super(BoltzmannWithTemperatureAnnealingDQN, self).reset()\n",
        "    self.temperature = self.start_temparature"
      ],
      "metadata": {
        "id": "ylINCOiLb09P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boltzmann_temp_anneal_dqn = BoltzmannWithTemperatureAnnealingDQN(args)\n",
        "result_means_boltzmann_temp_anneal_dqn, result_stds_boltzmann_temp_anneal_dqn = train_dqn(boltzmann_temp_anneal_dqn)\n",
        "plot_results(result_means_boltzmann_temp_anneal_dqn, result_stds_boltzmann_temp_anneal_dqn)"
      ],
      "metadata": {
        "id": "R--aoCSzjEjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last exploration idea we want to implement is a combintation of the epsilon-greedy strategy (with epsilon annealing) and the boltzmann strategy.\n",
        "We could think that at the beginning of the training the boltzmann strategy struggles because the Q-function (the main critic) is not yet well-trained. However, the more critic is trained, the more sense it makes to start using the boltzmann strategy. We would like to verif y this hypoothesis by using in the first half of the training epsilon-greedy strategy (with epsilon annealing) and in the second half of the training switch the exploration strategy to the boltzmann one."
      ],
      "metadata": {
        "id": "-jcSRBHXldKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_two_halfs_dqn(dqn_1, dqn_2):\n",
        "  set_seed(TRAIN_SEED)\n",
        "  # TODO\n",
        "  ####################################\n",
        "  ####################################\n",
        "\n",
        "  return result_mean, result_std\n"
      ],
      "metadata": {
        "id": "AjaSq-vC1PTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon_greedy_with_annealing_half_dqn = EpsilonGreedyWithAnnealingDQN(first_half_training_args) # investigate sensitivity of epsilon\n",
        "epsilon_greedy_boltzmann_half_dqn = BoltzmannDQN(second_half_training_args) # investigate sensitivity of temperature\n",
        "result_means_epsilon_greedy_with_annealing_half_epsilon_greedy_boltzmann_half_dqn, result_stds_epsilon_greedy_with_annealing_half_epsilon_greedy_boltzmann_half_dqn = train_two_halfs_dqn(epsilon_greedy_with_annealing_half_dqn, epsilon_greedy_boltzmann_half_dqn)\n",
        "plot_results(result_means_epsilon_greedy_with_annealing_half_epsilon_greedy_boltzmann_half_dqn, result_stds_epsilon_greedy_with_annealing_half_epsilon_greedy_boltzmann_half_dqn)"
      ],
      "metadata": {
        "id": "YwVivxWM1pXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we plot the results of all exploration methods on one plot. However, for drawing conclusions, it might be reasonable to plot some subsets of methods together, for example to compare variants with and without annealing, max-boltzmann with boltzmann, epsilon-greedy, boltzmann and half-epsilon-greedy, half-boltzmann."
      ],
      "metadata": {
        "id": "EM7aIGQuQ8Rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_means_list = [result_means_dqn, result_means_epsilon_greedy_dqn, result_means_epsilon_greedy_with_annealing_dqn,\n",
        "                result_means_boltzmann_dqn, result_means_boltzmann_temp_anneal_dqn,\n",
        "                result_means_max_boltzmann_dqn, result_means_max_boltzmann_temp_anneal_dqn,\n",
        "                result_means_epsilon_greedy_with_annealing_half_epsilon_greedy_boltzmann_half_dqn]\n",
        "result_stds_list = [result_stds_dqn, result_stds_epsilon_greedy_dqn, result_stds_epsilon_greedy_with_annealing_dqn,\n",
        "                result_stds_boltzmann_dqn, result_stds_boltzmann_temp_anneal_dqn,\n",
        "                result_stds_max_boltzmann_dqn, result_stds_max_boltzmann_temp_anneal_dqn,\n",
        "                result_stds_epsilon_greedy_with_annealing_half_epsilon_greedy_boltzmann_half_dqn]\n",
        "names_list = [\"random\", \"epsilon-greedy\", \"epsilon-greedy-with-annealing\",\n",
        "             \"boltzmann\", \"boltzmann-with-annealing\",\n",
        "             \"max-boltzmann\", \"max-boltzmann-with-annealing\",\n",
        "             \"half-epsilon-greedy-with-annealing_half-boltzmann\"]\n",
        "colours_list = [\"red\", \"green\", \"blue\",\n",
        "           \"yellow\", \"magenta\",\n",
        "           \"cyan\", \"black\",\n",
        "           \"orange\"]\n",
        "\n",
        "plot_results_many(result_means_list, result_stds_list, names_list, colours_list)"
      ],
      "metadata": {
        "id": "yDgWDm0IM4OS",
        "outputId": "9f198fc9-a931-40e3-ac1f-bed30076426d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'result_means_epsilon_greedy_with_annealing_dqn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-832443868.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m result_means_list = [result_means_dqn, result_means_epsilon_greedy_dqn, result_means_epsilon_greedy_with_annealing_dqn,\n\u001b[0m\u001b[1;32m      2\u001b[0m                 \u001b[0mresult_means_boltzmann_dqn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_means_boltzmann_temp_anneal_dqn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 \u001b[0mresult_means_max_boltzmann_dqn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_means_max_boltzmann_temp_anneal_dqn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 result_means_epsilon_greedy_with_annealing_half_epsilon_greedy_boltzmann_half_dqn]\n\u001b[1;32m      5\u001b[0m result_stds_list = [result_stds_dqn, result_stds_epsilon_greedy_dqn, result_stds_epsilon_greedy_with_annealing_dqn,\n",
            "\u001b[0;31mNameError\u001b[0m: name 'result_means_epsilon_greedy_with_annealing_dqn' is not defined"
          ]
        }
      ]
    }
  ]
}