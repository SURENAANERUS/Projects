{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exploration strategies for DQN algorithm\n",
        "\n",
        "In this assignment we are interested in exploration strategies that can be combined with Q-learning.\n",
        "Q-learning is an off-policy algorithm, which means that the data for the algorithm can be collected by a different policy (called behavioural policy) that the one the algorithm learns.\n",
        "\n",
        "Here we come across a classical trade-off in reinforcement learning, called exploration-exploitation trade-off. On the one hand, our behavioural policy should try out new state-action pairs to gain knowledge about their returns. On the other hand, when our estimate of returns is good enough, we would like to follow the state-action pairs with the highest estimated returns.\n",
        "\n",
        "We will be operating on DQN [(Mnih 2014)](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf) algorithm and analyzing epsilon-greedy strategy, boltzmann and max-boltzmann strategy and combination of epsilon-greedy and boltzmann.\n",
        "We evaluate performance of DQN variants on the Lunar Lander environment.\n",
        "\n",
        "We provide an implementation of the DQN algorithm with random exploration strategy.\n",
        "Your goal is to implement the exploration variants by overriding appropriate methods of the provided class.\n"
      ],
      "metadata": {
        "id": "OCcuj7kCPowC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grading\n",
        "\n",
        "To obtain the points for the assignment You need to provide the implementation of exploration techniques AND report with plots and conclusions.\n",
        "Measuring sensitivity means that You should at least examine one reasonably lower and one reasonably greater value of the considered hyperparameter (or the pair of hyperparameters).\n",
        "\n",
        "\n",
        "1. Implement epsilon-greedy strategy and investigate hyperparameter sensitivity (1 point).\n",
        "2. Implement epsilon-greedy strategy with epsilon annealing and investigate hyperparameter sensitivity (1 point).\n",
        "3. Implement boltzmann strategy and investigate hyperparameter sensitivity (1 point).\n",
        "4. Implement boltzmann strategy with temperature annealing and investigate hyperparameter sensitivity (1 point).\n",
        "5. Implement max-boltzmann strategy and investigate hyperparameter sensitivity (1 point).\n",
        "6. Implement max-boltzmann strategy with temperature annealing and investigate hyperparameter sensitivity (1 point).\n",
        "7. Implement combination of epsilon-greedy with epsilon annealing and boltzmann strategy and investigate hyperparameter sensitivity (1 point)\n",
        "8. (*) Bonus: propose another reasonable approach to combine epsilon-greedy with epsilon annealing strategy and boltzmann strategy and/or another reasonable strategy of temperature annealing for the boltzmann strategy (2 points).\n",
        "9. Compare methods, present plots and conclusions in a clear manner (3 points).\n",
        "\n",
        "You can obtain max 10 points, bonus points increase Your score, if You lose points in some other tasks."
      ],
      "metadata": {
        "id": "MdeRz_jnUBmO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we import necessary libraries."
      ],
      "metadata": {
        "id": "WugRYf0FYsxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install swig\n",
        "!pip install gymnasium[box2d]"
      ],
      "metadata": {
        "id": "P3Ynynd4GGKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b475dff9-99e9-41a2-dc0c-465384dd4291"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "swig is already the newest version (4.0.2-1ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.12/dist-packages (1.2.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Requirement already satisfied: box2d==2.3.10 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.3.10)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (4.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "KKd6_LiXdh3D"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we set hyperparameters of the training, set seeds for reproducibility and set weights initialization.\n",
        "Although for debugging it might be useful to operate on a smaller number of training_steps, seeds etc., in the final evaluation DO NOT CHANGE these parameters."
      ],
      "metadata": {
        "id": "kgtGd69HY7PB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class parse_args:\n",
        "  def __init__(self):\n",
        "    self.n_seeds = 6\n",
        "    self.n_evaluate_episodes = 5\n",
        "    self.n_training_steps = 100000\n",
        "    self.buffer_size = 10000\n",
        "    self.init_steps = 10000\n",
        "    self.target_update_freq = 50\n",
        "    self.eval_freq = 1000\n",
        "    self.gym_id = \"LunarLander-v3\"\n",
        "    env = gym.make(self.gym_id)\n",
        "    self.state_dim = env.observation_space.shape[0]\n",
        "    self.batch_size = 128\n",
        "    self.hidden_dim = 128\n",
        "    self.action_dim = env.action_space.n\n",
        "    self.discount = 0.99\n",
        "    self.lr = 7e-4\n",
        "    self.cuda = True\n",
        "    self.device = torch.device(\"cuda\" if torch.cuda.is_available() and self.cuda else \"cpu\")\n",
        "\n",
        "args = parse_args()\n",
        "first_half_training_args = parse_args()\n",
        "first_half_training_args.n_training_steps = first_half_training_args.n_training_steps // 2\n",
        "second_half_training_args = parse_args()\n",
        "second_half_training_args.n_training_steps = second_half_training_args.n_training_steps // 2\n",
        "second_half_training_args.init_steps = 1"
      ],
      "metadata": {
        "id": "AbD6x1GJFgqr"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "  np.random.seed(seed)\n",
        "\n",
        "def weight_init(model):\n",
        "  torch.nn.init.orthogonal_(model.weight.data)\n",
        "  model.bias.data.fill_(0.0)"
      ],
      "metadata": {
        "id": "wJ4x_6u9fQXA"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we implement the replay buffer.\n",
        "It has two methods: add one transition to the buffer and sample batch of transitions from the buffer."
      ],
      "metadata": {
        "id": "4nk9OsHCaPZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer:\n",
        "  def __init__(self, args):\n",
        "    self.states = np.zeros((args.buffer_size, args.n_seeds, args.state_dim), dtype = np.float32)\n",
        "    self.actions = np.zeros((args.buffer_size, args.n_seeds), dtype = np.int64)\n",
        "    self.rewards = np.zeros((args.buffer_size, args.n_seeds), dtype = np.float32)\n",
        "    self.next_states = np.zeros((args.buffer_size, args.n_seeds, args.state_dim), dtype = np.float32)\n",
        "    self.terminals = np.zeros((args.buffer_size, args.n_seeds), dtype = np.int64)\n",
        "    self.idx = 0\n",
        "    self.current_size = 0\n",
        "    self.args = args\n",
        "\n",
        "  def add(self, state, action, reward, next_state, terminal):\n",
        "    if self.current_size < self.args.buffer_size:\n",
        "      self.current_size += 1\n",
        "    self.states[self.idx, :, :] = state\n",
        "    self.actions[self.idx, :] = action\n",
        "    self.rewards[self.idx, :] = reward\n",
        "    self.next_states[self.idx, :, :] = next_state\n",
        "    self.terminals[self.idx, :] = terminal\n",
        "    self.idx = (self.idx + 1) % self.args.buffer_size\n",
        "\n",
        "  def sample(self):\n",
        "    sample_idxs = np.random.permutation(self.current_size)[:self.args.batch_size]\n",
        "    states = torch.from_numpy(self.states[sample_idxs]).to(self.args.device)\n",
        "    actions = torch.from_numpy(self.actions[sample_idxs]).to(self.args.device)\n",
        "    rewards = torch.from_numpy(self.rewards[sample_idxs]).to(self.args.device)\n",
        "    next_states = torch.from_numpy(self.next_states[sample_idxs]).to(self.args.device)\n",
        "    terminals = torch.from_numpy(self.terminals[sample_idxs]).to(self.args.device)\n",
        "\n",
        "    return states, actions, rewards, next_states, terminals\n"
      ],
      "metadata": {
        "id": "8kswZi26I9_t"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we implement a simple Q network architecture with three layers and ReLU activations."
      ],
      "metadata": {
        "id": "WI1MmteualVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QNetwork(torch.nn.Module):\n",
        "  def __init__(self, args):\n",
        "    super(QNetwork, self).__init__()\n",
        "    self.layer_1 = torch.nn.Linear(args.state_dim, args.hidden_dim)\n",
        "    self.layer_2 = torch.nn.Linear(args.hidden_dim, args.hidden_dim)\n",
        "    self.layer_3 = torch.nn.Linear(args.hidden_dim, args.action_dim)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "\n",
        "    self.layer_1.apply(weight_init)\n",
        "    self.layer_2.apply(weight_init)\n",
        "    self.layer_3.apply(weight_init)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.relu(self.layer_1(x))\n",
        "    x = self.relu(self.layer_2(x))\n",
        "    x = self.layer_3(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "jXq66twrc2Mh"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we provide code for DQN with random exploration."
      ],
      "metadata": {
        "id": "NB2SjjLldglT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "myEn1aKdaURQ"
      },
      "outputs": [],
      "source": [
        "TRAIN_SEED = 0\n",
        "EVAL_SEED = 1\n",
        "\n",
        "class DQN:\n",
        "  def __init__(self, args):\n",
        "    self.args = args\n",
        "    self.discount = self.args.discount\n",
        "    self.reset()\n",
        "    self.annealing = False\n",
        "\n",
        "  # Copying parameters of other DQN class by reference (for half epsion-greedy, half boltzmann task)\n",
        "  def copy_reference(self, other):\n",
        "    self.buffer = other.buffer\n",
        "    self.q_net = other.q_net\n",
        "    self.q_target = other.q_target\n",
        "    self.optimizer = other.optimizer\n",
        "\n",
        "  # Annealing of epsilon and/or temperature\n",
        "  def anneal(self, step):\n",
        "    pass\n",
        "\n",
        "  # Greedy action\n",
        "  def get_greedy_action(self, states):\n",
        "    with torch.no_grad():\n",
        "      action = torch.argmax(self.q_net(states), dim = -1).detach().cpu().numpy()\n",
        "      return action\n",
        "\n",
        "  # Exploration action choice\n",
        "  def explore(self, states):\n",
        "    # Random action choice\n",
        "    action = np.random.randint(self.args.action_dim, size = self.args.n_seeds)\n",
        "    return action\n",
        "\n",
        "  # Update of the main critic\n",
        "  def update(self):\n",
        "    states, actions, rewards, next_states, terminals = self.buffer.sample()\n",
        "    with torch.no_grad():\n",
        "      q_next_states = torch.max(self.q_target(next_states), dim = -1)[0]\n",
        "    ones_tensor = torch.ones_like(terminals).to(self.args.device)\n",
        "    targets = rewards + (ones_tensor - terminals) * self.discount * q_next_states\n",
        "\n",
        "    self.optimizer.zero_grad()\n",
        "    q_values = self.q_net(states).gather(-1, actions.unsqueeze(-1)).squeeze(-1)\n",
        "    loss = torch.mean((q_values - targets) ** 2)\n",
        "    loss.backward()\n",
        "    self.optimizer.step()\n",
        "\n",
        "  # Update of the targer critic\n",
        "  def update_target(self):\n",
        "    self.q_target.load_state_dict(self.q_net.state_dict())\n",
        "\n",
        "  # Evaluation of the performance on test environments.\n",
        "  def evaluate(self):\n",
        "    eval_results = np.zeros(self.args.n_seeds)\n",
        "    with torch.no_grad():\n",
        "      eval_env = gym.make_vec(self.args.gym_id, num_envs = self.args.n_seeds, vectorization_mode=\"sync\")\n",
        "      eval_env.reset(seed = EVAL_SEED)\n",
        "      for _ in range(self.args.n_evaluate_episodes):\n",
        "        state, info = eval_env.reset()\n",
        "        episode_reward = np.zeros(self.args.n_seeds)\n",
        "        mask = np.ones(self.args.n_seeds)\n",
        "        while np.sum(mask) > 0:\n",
        "          action = self.get_greedy_action(torch.tensor(state).to(self.args.device))\n",
        "          next_state, reward, terminal, truncated, _ = eval_env.step(action)\n",
        "          episode_reward += mask * reward\n",
        "          state = next_state\n",
        "          mask *= (np.ones(self.args.n_seeds) - terminal) * (np.ones(self.args.n_seeds) - truncated)\n",
        "        eval_results += episode_reward / self.args.n_evaluate_episodes\n",
        "    return np.mean(eval_results), np.std(eval_results)\n",
        "\n",
        "\n",
        "  # Resetting the algorithm\n",
        "  def reset(self):\n",
        "    self.buffer = ReplayBuffer(self.args)\n",
        "    self.q_net = QNetwork(self.args).to(self.args.device) # main critic\n",
        "    self.optimizer = torch.optim.Adam(self.q_net.parameters(), lr = self.args.lr, eps = 1e-5)\n",
        "    self.q_target = QNetwork(self.args).to(self.args.device) # target critic\n",
        "    self.update_target()\n",
        "\n",
        "  # Training loop\n",
        "  def train(self):\n",
        "    eval_results_means = np.array([])\n",
        "    eval_results_stds = np.array([])\n",
        "    train_env = gym.make_vec(self.args.gym_id, num_envs = self.args.n_seeds, vectorization_mode=\"sync\")\n",
        "    state, info = train_env.reset(seed = TRAIN_SEED)\n",
        "    mask = np.ones(self.args.n_seeds)\n",
        "    for step in range(self.args.n_training_steps):\n",
        "      action = self.explore(torch.tensor(state).unsqueeze(0).to(self.args.device))\n",
        "      if self.annealing:\n",
        "        self.anneal(step)\n",
        "      next_state, reward, terminal, truncated, _ = train_env.step(action)\n",
        "      self.buffer.add(state, action, reward, next_state, terminal)\n",
        "      state = next_state\n",
        "      if step % self.args.eval_freq == 0:\n",
        "          print(f\"Training step: {step}\")\n",
        "          eval_mean, eval_std = self.evaluate()\n",
        "          print(f\"Eval mean: {eval_mean}; eval_std: {eval_std}\")\n",
        "          eval_results_means = np.append(eval_results_means, eval_mean)\n",
        "          eval_results_stds = np.append(eval_results_stds, eval_std)\n",
        "      if step >= self.args.init_steps:\n",
        "        self.update()\n",
        "        if step % self.args.target_update_freq == 0:\n",
        "          self.update_target()\n",
        "      mask *= (np.ones(self.args.n_seeds) - terminal) * (np.ones(self.args.n_seeds) - truncated)\n",
        "      if np.sum(mask) == 0:\n",
        "        state, info = train_env.reset()\n",
        "        mask = np.ones(self.args.n_seeds)\n",
        "\n",
        "    return eval_results_means, eval_results_stds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we implement functions for plotting."
      ],
      "metadata": {
        "id": "2JDGKsz8chmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth(data, weigth = 0.9):\n",
        "  smooth_data = np.copy(data)\n",
        "  for index in range(1, len(data)):\n",
        "    smooth_data[index] = smooth_data[index - 1] * weigth + data[index] * (1.0 - weigth)\n",
        "\n",
        "  return smooth_data\n",
        "\n",
        "def plot_smooth(args, result_means, result_stds):\n",
        "  smooth_result_means = smooth(result_means)\n",
        "  smooth_result_stds = smooth(result_stds)\n",
        "  print(smooth_result_means)\n",
        "  print(smooth_result_stds)\n",
        "  xs = np.arange(len(result_means)) * args.eval_freq\n",
        "  print(xs)\n",
        "  plt.plot(xs, smooth_result_means, color = \"blue\")\n",
        "  plt.fill_between(xs, smooth_result_means - smooth_result_stds, smooth_result_means + smooth_result_stds, alpha = 0.2, label = \"smoothed_rewards\")\n",
        "  plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
        "  plt.show()\n",
        "  plt.clf()\n",
        "\n",
        "def plot_smooth_many(args, result_means_list, result_stds_list, names_list, colours_list):\n",
        "  plt.figure(figsize=(12.8, 9.6))\n",
        "  for result_means, result_stds, name, colour in zip(result_means_list, result_stds_list, names_list, colours_list):\n",
        "    smooth_result_means = smooth(result_means)\n",
        "    smooth_result_stds = smooth(result_stds)\n",
        "    print(smooth_result_means)\n",
        "    print(smooth_result_stds)\n",
        "    xs = np.arange(len(result_means)) * args.eval_freq\n",
        "    print(xs)\n",
        "    plt.plot(xs, smooth_result_means, color = colour)\n",
        "    plt.fill_between(xs, smooth_result_means - smooth_result_stds, smooth_result_means + smooth_result_stds, alpha = 0.2, color = colour, label = f\"smoothed_rewards_{name}\")\n",
        "    plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
        "  plt.show()\n",
        "  plt.clf()\n",
        "\n",
        "def plot_results(result_mean, result_std):\n",
        "  plot_smooth(args, result_mean, result_std)\n",
        "\n",
        "def plot_results_many(result_means_list, result_stds_list, name_list, colours_list):\n",
        "  plot_smooth_many(args, result_means_list, result_stds_list, name_list, colours_list)"
      ],
      "metadata": {
        "id": "P_zLGVqHpvQz"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we provide code for training across different random seeds."
      ],
      "metadata": {
        "id": "hoiLn1y1cshT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_dqn(dqn):\n",
        "  set_seed(TRAIN_SEED)\n",
        "  dqn.reset()\n",
        "  result_mean, result_std = dqn.train()\n",
        "  print(result_mean)\n",
        "  return result_mean, result_std\n"
      ],
      "metadata": {
        "id": "XLG6xzJ-o7oN"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dqn = DQN(args)\n",
        "result_means_dqn, result_stds_dqn = train_dqn(dqn)\n",
        "plot_results(result_means_dqn, result_stds_dqn)"
      ],
      "metadata": {
        "id": "R2PyyNFdq50-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "19e5fd14-8bed-43b1-c665-87b26b5e7773"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training step: 0\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 1000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 2000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 3000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 4000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 5000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 6000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 7000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 8000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 9000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 10000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 11000\n",
            "Eval mean: -91.47844743831462; eval_std: 8.630728694108207\n",
            "Training step: 12000\n",
            "Eval mean: -132.55935990054934; eval_std: 19.65501482155529\n",
            "Training step: 13000\n",
            "Eval mean: -154.9056704644178; eval_std: 21.862972836648428\n",
            "Training step: 14000\n",
            "Eval mean: -176.16798876038013; eval_std: 16.378972258567046\n",
            "Training step: 15000\n",
            "Eval mean: -215.06103993659542; eval_std: 12.389259030300313\n",
            "Training step: 16000\n",
            "Eval mean: -209.9748502183695; eval_std: 20.471719013820433\n",
            "Training step: 17000\n",
            "Eval mean: -185.85202208873525; eval_std: 59.832409241538954\n",
            "Training step: 18000\n",
            "Eval mean: -162.0263417921316; eval_std: 32.325943037839075\n",
            "Training step: 19000\n",
            "Eval mean: -173.2690009005112; eval_std: 30.209237481750105\n",
            "Training step: 20000\n",
            "Eval mean: -131.6000747328384; eval_std: 37.02139523965248\n",
            "Training step: 21000\n",
            "Eval mean: -123.95804117670917; eval_std: 48.202181065536664\n",
            "Training step: 22000\n",
            "Eval mean: -110.53913555741859; eval_std: 38.199224025215564\n",
            "Training step: 23000\n",
            "Eval mean: -136.40936843246806; eval_std: 13.539262617349738\n",
            "Training step: 24000\n",
            "Eval mean: -104.41997273420615; eval_std: 18.250639363309002\n",
            "Training step: 25000\n",
            "Eval mean: -72.64361568584991; eval_std: 41.5220056334155\n",
            "Training step: 26000\n",
            "Eval mean: -138.5811246130602; eval_std: 6.950046242550084\n",
            "Training step: 27000\n",
            "Eval mean: -141.0976299075013; eval_std: 20.891462828477515\n",
            "Training step: 28000\n",
            "Eval mean: -154.81170926381674; eval_std: 15.886420127348925\n",
            "Training step: 29000\n",
            "Eval mean: -121.96067023963184; eval_std: 11.21243824850259\n",
            "Training step: 30000\n",
            "Eval mean: -114.63358219127326; eval_std: 17.198588075858112\n",
            "Training step: 31000\n",
            "Eval mean: -95.45717450267512; eval_std: 12.874691190367589\n",
            "Training step: 32000\n",
            "Eval mean: -114.4286658077998; eval_std: 9.661102191366489\n",
            "Training step: 33000\n",
            "Eval mean: -178.67819503587774; eval_std: 17.94299424987409\n",
            "Training step: 34000\n",
            "Eval mean: -205.8523679786698; eval_std: 9.484738407127288\n",
            "Training step: 35000\n",
            "Eval mean: -187.64285328467335; eval_std: 23.041049459892534\n",
            "Training step: 36000\n",
            "Eval mean: -225.88506862791317; eval_std: 22.33931565341804\n",
            "Training step: 37000\n",
            "Eval mean: -171.00296618187312; eval_std: 31.830922893401546\n",
            "Training step: 38000\n",
            "Eval mean: -229.1181046180392; eval_std: 20.85216777536109\n",
            "Training step: 39000\n",
            "Eval mean: -373.4359865418105; eval_std: 26.49915279783614\n",
            "Training step: 40000\n",
            "Eval mean: -339.81717496109485; eval_std: 20.14405182453167\n",
            "Training step: 41000\n",
            "Eval mean: -256.9695773113392; eval_std: 30.777149065314298\n",
            "Training step: 42000\n",
            "Eval mean: -378.1615536922963; eval_std: 50.357742621485734\n",
            "Training step: 43000\n",
            "Eval mean: -339.0887560137216; eval_std: 49.75184609926443\n",
            "Training step: 44000\n",
            "Eval mean: -441.98509006343335; eval_std: 21.451282702545413\n",
            "Training step: 45000\n",
            "Eval mean: -465.40957387459065; eval_std: 47.7702414685452\n",
            "Training step: 46000\n",
            "Eval mean: -377.047802265239; eval_std: 50.79686749030583\n",
            "Training step: 47000\n",
            "Eval mean: -425.87379154618594; eval_std: 20.571034509687408\n",
            "Training step: 48000\n",
            "Eval mean: -390.051486519467; eval_std: 37.30818195467473\n",
            "Training step: 49000\n",
            "Eval mean: -368.01624941137425; eval_std: 35.529448413378994\n",
            "Training step: 50000\n",
            "Eval mean: -378.5668883177863; eval_std: 36.716538502530156\n",
            "Training step: 51000\n",
            "Eval mean: -372.0110876885362; eval_std: 33.727696460065914\n",
            "Training step: 52000\n",
            "Eval mean: -381.72294918979264; eval_std: 9.206478417447691\n",
            "Training step: 53000\n",
            "Eval mean: -335.0338770928068; eval_std: 33.78905191845449\n",
            "Training step: 54000\n",
            "Eval mean: -317.01668110472167; eval_std: 22.132088051647518\n",
            "Training step: 55000\n",
            "Eval mean: -296.4594326069283; eval_std: 47.482616134738045\n",
            "Training step: 56000\n",
            "Eval mean: -365.20982408672717; eval_std: 55.55074909279121\n",
            "Training step: 57000\n",
            "Eval mean: -306.516120001003; eval_std: 37.70632547640554\n",
            "Training step: 58000\n",
            "Eval mean: -346.429213291721; eval_std: 36.755195682947715\n",
            "Training step: 59000\n",
            "Eval mean: -343.09701058967977; eval_std: 39.30016952599992\n",
            "Training step: 60000\n",
            "Eval mean: -367.44878587075937; eval_std: 30.218475329458727\n",
            "Training step: 61000\n",
            "Eval mean: -372.71540672728844; eval_std: 35.09567885777271\n",
            "Training step: 62000\n",
            "Eval mean: -301.48613384282663; eval_std: 21.590458704208864\n",
            "Training step: 63000\n",
            "Eval mean: -285.12648660671357; eval_std: 45.79978553488714\n",
            "Training step: 64000\n",
            "Eval mean: -335.65068663960477; eval_std: 30.301616128874926\n",
            "Training step: 65000\n",
            "Eval mean: -340.6342365356996; eval_std: 20.453030690769747\n",
            "Training step: 66000\n",
            "Eval mean: -330.5284078789225; eval_std: 22.51087735945482\n",
            "Training step: 67000\n",
            "Eval mean: -241.09747586193214; eval_std: 15.02952582684867\n",
            "Training step: 68000\n",
            "Eval mean: -312.8674305976463; eval_std: 8.951135573632179\n",
            "Training step: 69000\n",
            "Eval mean: -268.6225426233369; eval_std: 19.43675173659488\n",
            "Training step: 70000\n",
            "Eval mean: -231.46137083795364; eval_std: 22.174263827822976\n",
            "Training step: 71000\n",
            "Eval mean: -288.78202772586855; eval_std: 37.58306188957366\n",
            "Training step: 72000\n",
            "Eval mean: -212.47190756449413; eval_std: 33.15241325261153\n",
            "Training step: 73000\n",
            "Eval mean: -133.17406326517406; eval_std: 35.81977858299839\n",
            "Training step: 74000\n",
            "Eval mean: -139.06065796600387; eval_std: 34.433308831457104\n",
            "Training step: 75000\n",
            "Eval mean: -136.23543344582376; eval_std: 16.20438811718947\n",
            "Training step: 76000\n",
            "Eval mean: -138.44037614857913; eval_std: 22.14152768385195\n",
            "Training step: 77000\n",
            "Eval mean: -109.06339104719954; eval_std: 19.86670791243593\n",
            "Training step: 78000\n",
            "Eval mean: -100.35557554510565; eval_std: 13.816030932762954\n",
            "Training step: 79000\n",
            "Eval mean: -138.8965620082435; eval_std: 27.62013459593763\n",
            "Training step: 80000\n",
            "Eval mean: -128.39987199150482; eval_std: 19.03683822476165\n",
            "Training step: 81000\n",
            "Eval mean: -169.26844553108637; eval_std: 24.58656181595119\n",
            "Training step: 82000\n",
            "Eval mean: -199.29752848072928; eval_std: 16.948374824181865\n",
            "Training step: 83000\n",
            "Eval mean: -197.17211097459312; eval_std: 22.444711493400504\n",
            "Training step: 84000\n",
            "Eval mean: -137.082903324649; eval_std: 7.575027083835006\n",
            "Training step: 85000\n",
            "Eval mean: -200.68649592535473; eval_std: 28.41130157165442\n",
            "Training step: 86000\n",
            "Eval mean: -117.13355414224962; eval_std: 15.916315461099169\n",
            "Training step: 87000\n",
            "Eval mean: -113.85118378684052; eval_std: 8.423233046382569\n",
            "Training step: 88000\n",
            "Eval mean: -104.62528928705142; eval_std: 12.063366231030722\n",
            "Training step: 89000\n",
            "Eval mean: -153.29014824319677; eval_std: 27.832729312626252\n",
            "Training step: 90000\n",
            "Eval mean: -163.8933881694338; eval_std: 16.57070492042199\n",
            "Training step: 91000\n",
            "Eval mean: -209.74283730937654; eval_std: 21.493680995318282\n",
            "Training step: 92000\n",
            "Eval mean: -205.8060845365014; eval_std: 18.722164778823142\n",
            "Training step: 93000\n",
            "Eval mean: -187.60835867070932; eval_std: 15.170438847898447\n",
            "Training step: 94000\n",
            "Eval mean: -148.2594134212608; eval_std: 23.495258057895562\n",
            "Training step: 95000\n",
            "Eval mean: -237.97352421386503; eval_std: 28.73587165956887\n",
            "Training step: 96000\n",
            "Eval mean: -247.83827571757354; eval_std: 23.066509488843792\n",
            "Training step: 97000\n",
            "Eval mean: -199.44103806609397; eval_std: 12.694914219603492\n",
            "Training step: 98000\n",
            "Eval mean: -138.07806788251193; eval_std: 14.709071977427293\n",
            "Training step: 99000\n",
            "Eval mean: -238.84024281308862; eval_std: 30.73763100378063\n",
            "[-639.69034775 -639.69034775 -639.69034775 -639.69034775 -639.69034775\n",
            " -639.69034775 -639.69034775 -639.69034775 -639.69034775 -639.69034775\n",
            " -639.69034775  -91.47844744 -132.5593599  -154.90567046 -176.16798876\n",
            " -215.06103994 -209.97485022 -185.85202209 -162.02634179 -173.2690009\n",
            " -131.60007473 -123.95804118 -110.53913556 -136.40936843 -104.41997273\n",
            "  -72.64361569 -138.58112461 -141.09762991 -154.81170926 -121.96067024\n",
            " -114.63358219  -95.4571745  -114.42866581 -178.67819504 -205.85236798\n",
            " -187.64285328 -225.88506863 -171.00296618 -229.11810462 -373.43598654\n",
            " -339.81717496 -256.96957731 -378.16155369 -339.08875601 -441.98509006\n",
            " -465.40957387 -377.04780227 -425.87379155 -390.05148652 -368.01624941\n",
            " -378.56688832 -372.01108769 -381.72294919 -335.03387709 -317.0166811\n",
            " -296.45943261 -365.20982409 -306.51612    -346.42921329 -343.09701059\n",
            " -367.44878587 -372.71540673 -301.48613384 -285.12648661 -335.65068664\n",
            " -340.63423654 -330.52840788 -241.09747586 -312.8674306  -268.62254262\n",
            " -231.46137084 -288.78202773 -212.47190756 -133.17406327 -139.06065797\n",
            " -136.23543345 -138.44037615 -109.06339105 -100.35557555 -138.89656201\n",
            " -128.39987199 -169.26844553 -199.29752848 -197.17211097 -137.08290332\n",
            " -200.68649593 -117.13355414 -113.85118379 -104.62528929 -153.29014824\n",
            " -163.89338817 -209.74283731 -205.80608454 -187.60835867 -148.25941342\n",
            " -237.97352421 -247.83827572 -199.44103807 -138.07806788 -238.84024281]\n",
            "[-639.69034775 -639.69034775 -639.69034775 -639.69034775 -639.69034775\n",
            " -639.69034775 -639.69034775 -639.69034775 -639.69034775 -639.69034775\n",
            " -639.69034775 -584.86915772 -539.63817794 -501.16492719 -468.66523335\n",
            " -443.30481401 -419.97181763 -396.55983807 -373.10648845 -353.12273969\n",
            " -330.9704732  -310.26922999 -290.29622055 -274.90753534 -257.85877908\n",
            " -239.33726274 -229.26164893 -220.44524702 -213.88189325 -204.68977095\n",
            " -195.68415207 -185.66145431 -178.53817546 -178.55217742 -181.28219648\n",
            " -181.91826216 -186.3149428  -184.78374514 -189.21718109 -207.63906164\n",
            " -220.85687297 -224.4681434  -239.83748443 -249.76261159 -268.98485944\n",
            " -288.62733088 -297.46937802 -310.30981937 -318.28398609 -323.25721242\n",
            " -328.78818001 -333.11047078 -337.97171862 -337.67793447 -335.61180913\n",
            " -331.69657148 -335.04789674 -332.19471906 -333.61816849 -334.5660527\n",
            " -337.85432601 -341.34043409 -337.35500406 -332.13215232 -332.48400575\n",
            " -333.29902883 -333.02196673 -323.82951765 -322.73330894 -317.32223231\n",
            " -308.73614616 -306.74073432 -297.31385164 -280.89987281 -266.71595132\n",
            " -253.66789953 -242.1451472  -228.83697158 -215.98883198 -208.27960498\n",
            " -200.29163168 -197.18931307 -197.40013461 -197.37733224 -191.34788935\n",
            " -192.28175001 -184.76693042 -177.67535576 -170.37034911 -168.66232903\n",
            " -168.18543494 -172.34117518 -175.68766611 -176.87973537 -174.01770317\n",
            " -180.41328528 -187.15578432 -188.3843097  -183.35368551 -188.90234124]\n",
            "[59.38467171 59.38467171 59.38467171 59.38467171 59.38467171 59.38467171\n",
            " 59.38467171 59.38467171 59.38467171 59.38467171 59.38467171 54.30927741\n",
            " 50.84385115 47.94576332 44.78908421 41.54910169 39.44136343 41.48046801\n",
            " 40.56501551 39.52943771 39.27863346 40.17098822 39.9738118  37.33035688\n",
            " 35.42238513 36.03234718 33.12411709 31.90085166 30.29940851 28.39071148\n",
            " 27.27149914 25.83181835 24.21474673 23.58757148 22.17728818 22.2636643\n",
            " 22.27122944 23.22719878 22.98969568 23.34064139 23.02098244 23.7965991\n",
            " 26.45271345 28.78262672 28.04949232 30.02156723 32.09909726 30.94629098\n",
            " 31.58248008 31.97717691 32.45111307 32.57877141 30.24154211 30.59629309\n",
            " 29.74987259 31.52314694 33.92590716 34.30394899 34.54907366 35.02418325\n",
            " 34.54361245 34.59881909 33.29798306 34.5481633  34.12350859 32.7564608\n",
            " 31.73190245 30.06166479 27.95061187 27.09922586 26.60672965 27.70436288\n",
            " 28.24916791 29.00622898 29.54893697 28.21448208 27.60718664 26.83313877\n",
            " 25.53142798 25.74029865 25.0699526  25.02161353 24.21428965 24.03733184\n",
            " 22.39110136 22.99312138 22.28544079 20.89922002 20.01563464 20.79734411\n",
            " 20.37468019 20.48658027 20.31013872 19.79616873 20.16607766 21.02305706\n",
            " 21.22740231 20.3741535  19.80764535 20.90064391]\n",
            "[    0  1000  2000  3000  4000  5000  6000  7000  8000  9000 10000 11000\n",
            " 12000 13000 14000 15000 16000 17000 18000 19000 20000 21000 22000 23000\n",
            " 24000 25000 26000 27000 28000 29000 30000 31000 32000 33000 34000 35000\n",
            " 36000 37000 38000 39000 40000 41000 42000 43000 44000 45000 46000 47000\n",
            " 48000 49000 50000 51000 52000 53000 54000 55000 56000 57000 58000 59000\n",
            " 60000 61000 62000 63000 64000 65000 66000 67000 68000 69000 70000 71000\n",
            " 72000 73000 74000 75000 76000 77000 78000 79000 80000 81000 82000 83000\n",
            " 84000 85000 86000 87000 88000 89000 90000 91000 92000 93000 94000 95000\n",
            " 96000 97000 98000 99000]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the goal is to implement the epsilon-gredy strategy. With probability epsilon we choose uniformly a random action and with probability 1-epsilon we take the action with the highest Q-value according to the main critic."
      ],
      "metadata": {
        "id": "8BHzDjEUfYn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import random\n",
        "class EpsilonGreedyDQN(DQN):\n",
        "  def __init__(self, args):\n",
        "    super(EpsilonGreedyDQN, self).__init__(args)\n",
        "    self.epsilon = 0.1 # investigate sensitivity\n",
        "\n",
        "  def explore(self, states):\n",
        "    action = None\n",
        "    # TODO\n",
        "    ran = random.random()\n",
        "    if ran < self.epsilon:\n",
        "      action = np.random.randint(self.args.action_dim, size = self.args.n_seeds)\n",
        "\n",
        "    else:\n",
        "      action = self.get_greedy_action(states).squeeze()\n",
        "\n",
        "    return action\n",
        "\n"
      ],
      "metadata": {
        "id": "v6lj71xe7c77"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon_greedy_dqn = EpsilonGreedyDQN(args)\n",
        "result_means_epsilon_greedy_dqn, result_stds_epsilon_greedy_dqn = train_dqn(epsilon_greedy_dqn)\n",
        "plot_results(result_means_epsilon_greedy_dqn, result_stds_epsilon_greedy_dqn)"
      ],
      "metadata": {
        "id": "JefbwjjR9AU-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b8316c-2186-49ea-be50-8f6e2fa44a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training step: 0\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 1000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 2000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 3000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 4000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 5000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 6000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 7000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 8000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 9000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 10000\n",
            "Eval mean: -639.6903477514232; eval_std: 59.38467170955477\n",
            "Training step: 11000\n",
            "Eval mean: -120.44437826827027; eval_std: 59.7060118860235\n",
            "Training step: 12000\n",
            "Eval mean: 80.4220514157028; eval_std: 43.56996015345598\n",
            "Training step: 13000\n",
            "Eval mean: 7.401688968918383; eval_std: 10.809415897010178\n",
            "Training step: 14000\n",
            "Eval mean: -26.36360787141642; eval_std: 7.511846680911968\n",
            "Training step: 15000\n",
            "Eval mean: -0.5409537882684337; eval_std: 27.178385389624115\n",
            "Training step: 16000\n",
            "Eval mean: -98.17722145882131; eval_std: 15.659488705046057\n",
            "Training step: 17000\n",
            "Eval mean: -109.36339769221752; eval_std: 22.54410124717694\n",
            "Training step: 18000\n",
            "Eval mean: -204.3569916530238; eval_std: 12.271808679742376\n",
            "Training step: 19000\n",
            "Eval mean: -163.68399215204727; eval_std: 27.861024567061907\n",
            "Training step: 20000\n",
            "Eval mean: -29.221943368336255; eval_std: 28.80146178970097\n",
            "Training step: 21000\n",
            "Eval mean: -64.06067772395379; eval_std: 9.084515896932826\n",
            "Training step: 22000\n",
            "Eval mean: 19.86812700560563; eval_std: 25.327765660853455\n",
            "Training step: 23000\n",
            "Eval mean: -44.93515601868157; eval_std: 39.77623494896526\n",
            "Training step: 24000\n",
            "Eval mean: 9.569266525079327; eval_std: 24.989476946270855\n",
            "Training step: 25000\n",
            "Eval mean: -43.26204613958803; eval_std: 43.31699559898703\n",
            "Training step: 26000\n",
            "Eval mean: -23.660364355075796; eval_std: 38.295743716779896\n",
            "Training step: 27000\n",
            "Eval mean: 47.37578439178628; eval_std: 83.97914334621764\n",
            "Training step: 28000\n",
            "Eval mean: -123.03683790173022; eval_std: 92.67662118394739\n",
            "Training step: 29000\n",
            "Eval mean: -102.02664458529932; eval_std: 63.30614281538718\n",
            "Training step: 30000\n",
            "Eval mean: -24.59150896525408; eval_std: 19.889996166606366\n",
            "Training step: 31000\n",
            "Eval mean: 24.607206552465115; eval_std: 38.881057808964016\n",
            "Training step: 32000\n",
            "Eval mean: -8.429398224909493; eval_std: 33.09120698580318\n",
            "Training step: 33000\n",
            "Eval mean: -42.45554589000408; eval_std: 34.68302265476162\n",
            "Training step: 34000\n",
            "Eval mean: -7.455423049419747; eval_std: 41.32611662931299\n",
            "Training step: 35000\n",
            "Eval mean: -7.677791473882603; eval_std: 16.126247170158184\n",
            "Training step: 36000\n",
            "Eval mean: 10.067516659494347; eval_std: 11.324985268482667\n",
            "Training step: 37000\n",
            "Eval mean: 63.363651011678144; eval_std: 81.44466182905288\n",
            "Training step: 38000\n",
            "Eval mean: -77.34681200051736; eval_std: 62.701972059125275\n",
            "Training step: 39000\n",
            "Eval mean: 17.146532668131446; eval_std: 25.13714123188717\n",
            "Training step: 40000\n",
            "Eval mean: 14.498298278486631; eval_std: 30.64154126348687\n",
            "Training step: 41000\n",
            "Eval mean: 80.06948627483071; eval_std: 31.183148816885073\n",
            "Training step: 42000\n",
            "Eval mean: 167.9636827864875; eval_std: 35.442458022937736\n",
            "Training step: 43000\n",
            "Eval mean: 102.76129297276236; eval_std: 52.473276031506785\n",
            "Training step: 44000\n",
            "Eval mean: 78.82508060098002; eval_std: 34.49987018824727\n",
            "Training step: 45000\n",
            "Eval mean: 68.21271160779916; eval_std: 49.49900478548337\n",
            "Training step: 46000\n",
            "Eval mean: 187.01889346045823; eval_std: 32.98077957433279\n",
            "Training step: 47000\n",
            "Eval mean: 166.5902149609329; eval_std: 31.232403092241054\n",
            "Training step: 48000\n",
            "Eval mean: 132.88346219768292; eval_std: 60.05659659052935\n",
            "Training step: 49000\n",
            "Eval mean: 116.54768625644772; eval_std: 61.94448581706046\n",
            "Training step: 50000\n",
            "Eval mean: 134.66113066181777; eval_std: 43.99621030824892\n",
            "Training step: 51000\n",
            "Eval mean: 183.79009474350315; eval_std: 50.47419483144132\n",
            "Training step: 52000\n",
            "Eval mean: 215.3365139313826; eval_std: 26.081672978060073\n",
            "Training step: 53000\n",
            "Eval mean: 221.86515545507004; eval_std: 16.20983405527905\n",
            "Training step: 54000\n",
            "Eval mean: 160.05934512946274; eval_std: 31.078698583325657\n",
            "Training step: 55000\n",
            "Eval mean: 122.64175951905584; eval_std: 43.123488093728014\n",
            "Training step: 56000\n",
            "Eval mean: 175.11549302227908; eval_std: 40.62531050500203\n",
            "Training step: 57000\n",
            "Eval mean: 205.41784276153064; eval_std: 32.34231171731506\n",
            "Training step: 58000\n",
            "Eval mean: 241.67456370448522; eval_std: 11.967072977543907\n",
            "Training step: 59000\n",
            "Eval mean: 229.91056673434971; eval_std: 30.574738923184682\n",
            "Training step: 60000\n",
            "Eval mean: 230.1945251012701; eval_std: 16.782204239794954\n",
            "Training step: 61000\n",
            "Eval mean: 40.10568269590819; eval_std: 52.19255281284714\n",
            "Training step: 62000\n",
            "Eval mean: 238.88418765276387; eval_std: 10.963114636911353\n",
            "Training step: 63000\n",
            "Eval mean: 204.2295177852093; eval_std: 35.90817987660916\n",
            "Training step: 64000\n",
            "Eval mean: 102.68550646504245; eval_std: 61.51652887647904\n",
            "Training step: 65000\n",
            "Eval mean: 195.41441458149097; eval_std: 42.888286531315046\n",
            "Training step: 66000\n",
            "Eval mean: 178.0777090237606; eval_std: 31.982205891260094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we add to the epsilon-greedy strategy epsilon annealing. We change linearly epsilon from 1.0 to the value final_epsilon during first anneal_steps steps and then it remains on the final_epsilon level.\n",
        "Such an approach aims to increase the exploration level at the beginning of the training, when the Q-value estimate is poor and thus choosing greedily according to Q is not improving the performance."
      ],
      "metadata": {
        "id": "1iKU0YllgL5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class EpsilonGreedyWithAnnealingDQN(EpsilonGreedyDQN):\n",
        "  def __init__(self, args):\n",
        "    self.start_epsilon = 1.0\n",
        "    super(EpsilonGreedyWithAnnealingDQN, self).__init__(args)\n",
        "    self.epsilon = self.start_epsilon\n",
        "    self.final_epsilon = 0.1 # investigate sensitivity\n",
        "    self.annealing = True\n",
        "    self.anneal_steps = 30000\n",
        "\n",
        "  def anneal(self, step):\n",
        "    # TODO\n",
        "    annealRate = (self.start_epsilon - self.final_epsilon) / self.anneal_steps\n",
        "    if(step <= self.anneal_steps):\n",
        "      self.epsilon -= annealRate\n",
        "    ####################################\n",
        "    ####################################\n",
        "\n",
        "  def reset(self):\n",
        "    super(EpsilonGreedyWithAnnealingDQN, self).reset()\n",
        "    self.epsilon = self.start_epsilon\n",
        "\n"
      ],
      "metadata": {
        "id": "4VRBq0D-_Ug7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon_greedy_with_annealing_dqn = EpsilonGreedyWithAnnealingDQN(args)\n",
        "result_means_epsilon_greedy_with_annealing_dqn, result_stds_epsilon_greedy_with_annealing_dqn = train_dqn(epsilon_greedy_with_annealing_dqn)\n",
        "plot_results(result_means_epsilon_greedy_with_annealing_dqn, result_stds_epsilon_greedy_with_annealing_dqn)"
      ],
      "metadata": {
        "id": "ZY1C0OjtA8fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternative approach to the epsilon-greedy strategy is to use so-called boltzmann exploration strategy.\n",
        "The idea behind this approach is to perform softmax on the Q-values coming from the main critic and then sample from the obtained distribution.\n",
        "In this approach we use softmax with a temperature, i.e. before applying softmax, we scale all the Q-values by the temperature coefficient (in the literature we usually divide by the temperature, but this is equivallent to scaling by the inverse of the temperature). Large scaling values make the distribution close to the greedy choice, while low scaling values make the distribution close to the uniform one."
      ],
      "metadata": {
        "id": "2VJ4wifPiE55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class BoltzmannDQN(DQN):\n",
        "  def __init__(self, args):\n",
        "    super(BoltzmannDQN, self).__init__(args)\n",
        "    self.temperature = 1# investigate sensitivity\n",
        "\n",
        "  def explore(self, states):\n",
        "    action = None\n",
        "    with torch.no_grad():\n",
        "      # TODO\n",
        "      qValues = self.q_net(states) # this should give us raw qValues\n",
        "\n",
        "      qValues /= self.temperature\n",
        "\n",
        "      sm = torch.nn.Softmax(dim=-1)\n",
        "      qValues = sm(qValues)\n",
        "\n",
        "      action = torch.stack([torch.multinomial(qValues[dim0, dim1],1) for dim0 in range(qValues.shape[0]) for dim1 in range(qValues.shape[1])])\n",
        "      action = action.squeeze(-1)\n",
        "      action = torch.Tensor.tolist(action)\n",
        "\n",
        "    return action\n",
        "\n"
      ],
      "metadata": {
        "id": "_0wB5TcYRGAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boltzmann_dqn = BoltzmannDQN(args)\n",
        "result_means_boltzmann_dqn, result_stds_boltzmann_dqn = train_dqn(boltzmann_dqn)\n",
        "plot_results(result_means_boltzmann_dqn, result_stds_boltzmann_dqn)"
      ],
      "metadata": {
        "id": "0wcy8QOyijxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the compromises between epsilon-greedy and boltzmann exploration strategy is so-calles max-boltzmann strategy. In this strategy with probability 1-epsilon we choose action greedily, but with probability epsilon we perform the boltzmann choice instead of the uniform random choice."
      ],
      "metadata": {
        "id": "oLyezLVijx3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxBoltzmannDQN(EpsilonGreedyWithAnnealingDQN):\n",
        "  def __init__(self, args):\n",
        "    super(MaxBoltzmannDQN, self).__init__(args)\n",
        "    self.temperature = 0.1 # investigate sensitivity\n",
        "\n",
        "  def explore(self, states):\n",
        "    action = None\n",
        "    with torch.no_grad():\n",
        "      # TODO\n",
        "      ####################################\n",
        "\n",
        "      ran = random.random()\n",
        "      if ran < self.epsilon:\n",
        "\n",
        "        qValues = self.q_net(states) # this should give us raw qValues\n",
        "\n",
        "        qValues /= self.temperature\n",
        "\n",
        "        sm = torch.nn.Softmax(dim=-1)\n",
        "        qValues = sm(qValues)\n",
        "\n",
        "        action = torch.stack([torch.multinomial(qValues[dim0, dim1],1) for dim0 in range(qValues.shape[0]) for dim1 in range(qValues.shape[1])])\n",
        "        action = action.squeeze(-1)\n",
        "        action = torch.Tensor.tolist(action)\n",
        "      else:\n",
        "\n",
        "\n",
        "        action = self.get_greedy_action(states).squeeze()\n",
        "        ####################################\n",
        "    return action"
      ],
      "metadata": {
        "id": "5uaDREL-hIkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_boltzmann_dqn = MaxBoltzmannDQN(args)\n",
        "result_means_max_boltzmann_dqn, result_stds_max_boltzmann_dqn = train_dqn(max_boltzmann_dqn)\n",
        "plot_results(result_means_max_boltzmann_dqn, result_stds_max_boltzmann_dqn)"
      ],
      "metadata": {
        "id": "QjR01lGcw1jG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly to adjusting the value of epsilon in epsilon-greedy strategy, we can adjust the temperature in the max-boltzmann and boltzmann strategies: we start we the value start_temperature and linearly increase the value to the final_temperature during temperature_anneal_steps, then the temperature is on the constant level.\n"
      ],
      "metadata": {
        "id": "rq_pxa8KkbIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxBoltzmannWithTemperatureAnnealingDQN(MaxBoltzmannDQN):\n",
        "  def __init__(self, args):\n",
        "    self.start_temparature = 0.025 # investigate sensitivity\n",
        "    super(MaxBoltzmannWithTemperatureAnnealingDQN, self).__init__(args)\n",
        "    self.temperature = self.start_temparature\n",
        "    self.final_temperature = 0.3 # investigate sensitivity\n",
        "    self.temperature_anneal_steps = 30000\n",
        "    self.annealing = True\n",
        "\n",
        "  def anneal(self, step):\n",
        "    super(MaxBoltzmannWithTemperatureAnnealingDQN, self).anneal(step)\n",
        "    # TODO\n",
        "    ####################################\n",
        "    annealRate = (self.start_temparature - self.final_temperature) / self.temperature_anneal_steps\n",
        "    if(step <= self.temperature_anneal_steps):\n",
        "      self.temperature -= annealRate\n",
        "\n",
        "    ####################################\n",
        "\n",
        "  def reset(self):\n",
        "    super(MaxBoltzmannWithTemperatureAnnealingDQN, self).reset()\n",
        "    self.temperature = self.start_temparature"
      ],
      "metadata": {
        "id": "3naKqfLVDwP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_boltzmann_temp_anneal_dqn = MaxBoltzmannWithTemperatureAnnealingDQN(args)\n",
        "result_means_max_boltzmann_temp_anneal_dqn, result_stds_max_boltzmann_temp_anneal_dqn = train_dqn(max_boltzmann_temp_anneal_dqn)\n",
        "plot_results(result_means_max_boltzmann_temp_anneal_dqn, result_stds_max_boltzmann_temp_anneal_dqn)"
      ],
      "metadata": {
        "id": "HidAoBNCFV6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BoltzmannWithTemperatureAnnealingDQN(BoltzmannDQN):\n",
        "  def __init__(self, args):\n",
        "    self.start_temparature = 0.25 # investigate sensitivity\n",
        "    super(BoltzmannWithTemperatureAnnealingDQN, self).__init__(args)\n",
        "    self.temperature = self.start_temparature\n",
        "    self.final_temperature = 5.0 # investigate sensitivity HIGHER THIS\n",
        "\n",
        "\n",
        "    self.temperature_anneal_steps = 30000\n",
        "    self.annealing = True\n",
        "\n",
        "  def anneal(self, step):\n",
        "    # TODO\n",
        "    annealRate = (self.start_temparature - self.final_temperature) / self.temperature_anneal_steps\n",
        "    if(step <= self.temperature_anneal_steps):\n",
        "      self.temperature -= annealRate\n",
        "    ####################################\n",
        "    ####################################\n",
        "\n",
        "  def reset(self):\n",
        "    super(BoltzmannWithTemperatureAnnealingDQN, self).reset()\n",
        "    self.temperature = self.start_temparature"
      ],
      "metadata": {
        "id": "ylINCOiLb09P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boltzmann_temp_anneal_dqn = BoltzmannWithTemperatureAnnealingDQN(args)\n",
        "result_means_boltzmann_temp_anneal_dqn, result_stds_boltzmann_temp_anneal_dqn = train_dqn(boltzmann_temp_anneal_dqn)\n",
        "plot_results(result_means_boltzmann_temp_anneal_dqn, result_stds_boltzmann_temp_anneal_dqn)"
      ],
      "metadata": {
        "id": "R--aoCSzjEjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last exploration idea we want to implement is a combintation of the epsilon-greedy strategy (with epsilon annealing) and the boltzmann strategy.\n",
        "We could think that at the beginning of the training the boltzmann strategy struggles because the Q-function (the main critic) is not yet well-trained. However, the more critic is trained, the more sense it makes to start using the boltzmann strategy. We would like to verif y this hypoothesis by using in the first half of the training epsilon-greedy strategy (with epsilon annealing) and in the second half of the training switch the exploration strategy to the boltzmann one."
      ],
      "metadata": {
        "id": "-jcSRBHXldKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_two_halfs_dqn(dqn_1, dqn_2):\n",
        "  set_seed(TRAIN_SEED)\n",
        "\n",
        "  mean1, std1 = dqn_1.train()\n",
        "  print(\"typ: \", type(mean1), type(std1))\n",
        "\n",
        "  dqn_2.copy_reference(dqn_1)\n",
        "  print(\"drug apolowa\")\n",
        "  mean2, std2 = dqn_2.train()\n",
        "\n",
        "  result_mean = np.concatenate([mean1, mean2])\n",
        "  result_std = np.concatenate([std1, std2])\n",
        "  return result_mean, result_std\n"
      ],
      "metadata": {
        "id": "AjaSq-vC1PTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon_greedy_with_annealing_half_dqn = EpsilonGreedyWithAnnealingDQN(first_half_training_args) # investigate sensitivity of epsilon\n",
        "epsilon_greedy_boltzmann_half_dqn = BoltzmannDQN(second_half_training_args) # investigate sensitivity of temperature\n",
        "result_means_epsilon_greedy_with_annealing_half_epsilon_greedy_boltzmann_half_dqn, result_stds_epsilon_greedy_with_annealing_half_epsilon_greedy_boltzmann_half_dqn = train_two_halfs_dqn(epsilon_greedy_with_annealing_half_dqn, epsilon_greedy_boltzmann_half_dqn)\n",
        "plot_results(result_means_epsilon_greedy_with_annealing_half_epsilon_greedy_boltzmann_half_dqn, result_stds_epsilon_greedy_with_annealing_half_epsilon_greedy_boltzmann_half_dqn)"
      ],
      "metadata": {
        "id": "YwVivxWM1pXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we plot the results of all exploration methods on one plot. However, for drawing conclusions, it might be reasonable to plot some subsets of methods together, for example to compare variants with and without annealing, max-boltzmann with boltzmann, epsilon-greedy, boltzmann and half-epsilon-greedy, half-boltzmann."
      ],
      "metadata": {
        "id": "EM7aIGQuQ8Rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_means_list = [result_means_dqn, result_means_epsilon_greedy_dqn, result_means_epsilon_greedy_with_annealing_dqn,\n",
        "                result_means_boltzmann_dqn, result_means_boltzmann_temp_anneal_dqn,\n",
        "                result_means_max_boltzmann_dqn, result_means_max_boltzmann_temp_anneal_dqn,\n",
        "                result_means_epsilon_greedy_with_annealing_half_epsilon_greedy_boltzmann_half_dqn]\n",
        "result_stds_list = [result_stds_dqn, result_stds_epsilon_greedy_dqn, result_stds_epsilon_greedy_with_annealing_dqn,\n",
        "                result_stds_boltzmann_dqn, result_stds_boltzmann_temp_anneal_dqn,\n",
        "                result_stds_max_boltzmann_dqn, result_stds_max_boltzmann_temp_anneal_dqn,\n",
        "                result_stds_epsilon_greedy_with_annealing_half_epsilon_greedy_boltzmann_half_dqn]\n",
        "names_list = [\"random\", \"epsilon-greedy\", \"epsilon-greedy-with-annealing\",\n",
        "             \"boltzmann\", \"boltzmann-with-annealing\",\n",
        "             \"max-boltzmann\", \"max-boltzmann-with-annealing\",\n",
        "             \"half-epsilon-greedy-with-annealing_half-boltzmann\"]\n",
        "colours_list = [\"red\", \"green\", \"blue\",\n",
        "           \"yellow\", \"magenta\",\n",
        "           \"cyan\", \"black\",\n",
        "           \"orange\"]\n",
        "\n",
        "plot_results_many(result_means_list, result_stds_list, names_list, colours_list)\n",
        "\n"
      ],
      "metadata": {
        "id": "yDgWDm0IM4OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusions\n",
        "\n",
        "When it comes to the standard, non modified hyperparameter approaches, it's pleasing to see that most methods, beside the purely random one, present acceptable results. Some reach equilibrium faster than others, and some maintain their good performance better. The last approach, combining boltzman and epsilong, managed to display both fast convergence, due to epsilon, and nice performance late, due to boltzman. This is also observable when it comes to the approaches with only boltzman or only epsilon. Only greedy had a slow start, due to low exploration, epsilon greedy imptoved it , but still due to chance suffered from the greedines, hence its non linear growth.\n"
      ],
      "metadata": {
        "id": "Pkv7w0JimXBR"
      }
    }
  ]
}